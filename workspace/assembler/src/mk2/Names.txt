	/// Add with carry imm8 to AL.
	fn adc(&mut self, arg0: Al, arg1: Imm8);

	/// Add with carry imm16 to AX.
	fn adc(&mut self, arg0: Ax, arg1: Imm16);

	/// Add with carry imm32 to EAX.
	fn adc(&mut self, arg0: Eax, arg1: Imm32);

	/// Add with carry imm16 to r/m16.
	fn adc(&mut self, arg0: M16, arg1: Imm16);

	/// Add with CF sign-extended imm8 to r/m16.
	fn adc(&mut self, arg0: M16, arg1: Imm8);

	/// Add with carry r16 to r/m16.
	fn adc(&mut self, arg0: M16, arg1: R16);

	/// Add with CF imm32 to r/m32.
	fn adc(&mut self, arg0: M32, arg1: Imm32);

	/// Add with CF sign-extended imm8 into r/m32.
	fn adc(&mut self, arg0: M32, arg1: Imm8);

	/// Add with CF r32 to r/m32.
	fn adc(&mut self, arg0: M32, arg1: R32);

	/// Add with CF imm32 sign extended to 64-bits to r/m64.
	fn adc(&mut self, arg0: M64, arg1: Imm32);

	/// Add with CF sign-extended imm8 into r/m64.
	fn adc(&mut self, arg0: M64, arg1: Imm8);

	/// Add with CF r64 to r/m64.
	fn adc(&mut self, arg0: M64, arg1: R64);

	/// Add with carry imm8 to r/m8.
	fn adc(&mut self, arg0: M8, arg1: Imm8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: M8, arg1: R8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: M8, arg1: Rh);

	/// Add with carry imm16 to r/m16.
	fn adc(&mut self, arg0: R16, arg1: Imm16);

	/// Add with CF sign-extended imm8 to r/m16.
	fn adc(&mut self, arg0: R16, arg1: Imm8);

	/// Add with carry r/m16 to r16.
	fn adc(&mut self, arg0: R16, arg1: M16);

	/// Add with carry r16 to r/m16.
	fn adc(&mut self, arg0: R16, arg1: R16);

	/// Add with carry r/m16 to r16.
	void adc_1(const R16& arg0, arg1: R16);

	/// Add with CF imm32 to r/m32.
	fn adc(&mut self, arg0: R32, arg1: Imm32);

	/// Add with CF sign-extended imm8 into r/m32.
	fn adc(&mut self, arg0: R32, arg1: Imm8);

	/// Add with CF r/m32 to r32.
	fn adc(&mut self, arg0: R32, arg1: M32);

	/// Add with CF r32 to r/m32.
	fn adc(&mut self, arg0: R32, arg1: R32);

	/// Add with CF r/m32 to r32.
	void adc_1(const R32& arg0, arg1: R32);

	/// Add with CF imm32 sign extended to 64-bits to r/m64.
	fn adc(&mut self, arg0: R64, arg1: Imm32);

	/// Add with CF sign-extended imm8 into r/m64.
	fn adc(&mut self, arg0: R64, arg1: Imm8);

	/// Add with CF r/m64 to r64.
	fn adc(&mut self, arg0: R64, arg1: M64);

	/// Add with CF r64 to r/m64.
	fn adc(&mut self, arg0: R64, arg1: R64);

	/// Add with CF r/m64 to r64.
	void adc_1(const R64& arg0, arg1: R64);

	/// Add with carry imm8 to r/m8.
	fn adc(&mut self, arg0: R8, arg1: Imm8);

	/// Add with carry r/m8 to byte register.
	fn adc(&mut self, arg0: R8, arg1: M8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: R8, arg1: R8);

	/// Add with carry r/m8 to byte register.
	void adc_1(const R8& arg0, arg1: R8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: R8, arg1: Rh);

	/// Add with carry r/m8 to byte register.
	void adc_1(const R8& arg0, arg1: Rh);

	/// Add with carry imm32 sign extended to 64- bits to RAX.
	fn adc(&mut self, arg0: Rax, arg1: Imm32);

	/// Add with carry imm8 to r/m8.
	fn adc(&mut self, arg0: Rh, arg1: Imm8);

	/// Add with carry r/m8 to byte register.
	fn adc(&mut self, arg0: Rh, arg1: M8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: Rh, arg1: R8);

	/// Add with carry r/m8 to byte register.
	void adc_1(const Rh& arg0, arg1: R8);

	/// Add with carry byte register to r/m8.
	fn adc(&mut self, arg0: Rh, arg1: Rh);

	/// Add with carry r/m8 to byte register.
	void adc_1(const Rh& arg0, arg1: Rh);

	/// Add imm8 to AL.
	fn add(&mut self, arg0: Al, arg1: Imm8);

	/// Add imm16 to AX.
	fn add(&mut self, arg0: Ax, arg1: Imm16);

	/// Add imm32 to EAX.
	fn add(&mut self, arg0: Eax, arg1: Imm32);

	/// Add imm16 to r/m16.
	fn add(&mut self, arg0: M16, arg1: Imm16);

	/// Add sign-extended imm8 to r/m16.
	fn add(&mut self, arg0: M16, arg1: Imm8);

	/// Add r16 to r/m16.
	fn add(&mut self, arg0: M16, arg1: R16);

	/// Add imm32 to r/m32.
	fn add(&mut self, arg0: M32, arg1: Imm32);

	/// Add sign-extended imm8 to r/m32.
	fn add(&mut self, arg0: M32, arg1: Imm8);

	/// Add r32 to r/m32.
	fn add(&mut self, arg0: M32, arg1: R32);

	/// Add imm32 sign-extended to 64-bits to r/m64.
	fn add(&mut self, arg0: M64, arg1: Imm32);

	/// Add sign-extended imm8 to r/m64.
	fn add(&mut self, arg0: M64, arg1: Imm8);

	/// Add r64 to r/m64.
	fn add(&mut self, arg0: M64, arg1: R64);

	/// Add imm8 to r/m8.
	fn add(&mut self, arg0: M8, arg1: Imm8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: M8, arg1: R8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: M8, arg1: Rh);

	/// Add imm16 to r/m16.
	fn add(&mut self, arg0: R16, arg1: Imm16);

	/// Add sign-extended imm8 to r/m16.
	fn add(&mut self, arg0: R16, arg1: Imm8);

	/// Add r/m16 to r16.
	fn add(&mut self, arg0: R16, arg1: M16);

	/// Add r16 to r/m16.
	fn add(&mut self, arg0: R16, arg1: R16);

	/// Add r/m16 to r16.
	void add_1(const R16& arg0, arg1: R16);

	/// Add imm32 to r/m32.
	fn add(&mut self, arg0: R32, arg1: Imm32);

	/// Add sign-extended imm8 to r/m32.
	fn add(&mut self, arg0: R32, arg1: Imm8);

	/// Add r/m32 to r32.
	fn add(&mut self, arg0: R32, arg1: M32);

	/// Add r32 to r/m32.
	fn add(&mut self, arg0: R32, arg1: R32);

	/// Add r/m32 to r32.
	void add_1(const R32& arg0, arg1: R32);

	/// Add imm32 sign-extended to 64-bits to r/m64.
	fn add(&mut self, arg0: R64, arg1: Imm32);

	/// Add sign-extended imm8 to r/m64.
	fn add(&mut self, arg0: R64, arg1: Imm8);

	/// Add r/m64 to r64.
	fn add(&mut self, arg0: R64, arg1: M64);

	/// Add r64 to r/m64.
	fn add(&mut self, arg0: R64, arg1: R64);

	/// Add r/m64 to r64.
	void add_1(const R64& arg0, arg1: R64);

	/// Add imm8 to r/m8.
	fn add(&mut self, arg0: R8, arg1: Imm8);

	/// Add r/m8 to r8.
	fn add(&mut self, arg0: R8, arg1: M8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: R8, arg1: R8);

	/// Add r/m8 to r8.
	void add_1(const R8& arg0, arg1: R8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: R8, arg1: Rh);

	/// Add r/m8 to r8.
	void add_1(const R8& arg0, arg1: Rh);

	/// Add imm32 sign-extended to 64-bits to RAX.
	fn add(&mut self, arg0: Rax, arg1: Imm32);

	/// Add imm8 to r/m8.
	fn add(&mut self, arg0: Rh, arg1: Imm8);

	/// Add r/m8 to r8.
	fn add(&mut self, arg0: Rh, arg1: M8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: Rh, arg1: R8);

	/// Add r/m8 to r8.
	void add_1(const Rh& arg0, arg1: R8);

	/// Add r8 to r/m8.
	fn add(&mut self, arg0: Rh, arg1: Rh);

	/// Add r/m8 to r8.
	void add_1(const Rh& arg0, arg1: Rh);

	/// Add packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn addpd(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn addpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed single-precision floating-point values from xmm2/m128 to xmm1 and stores result in xmm1.
	fn addps(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed single-precision floating-point values from xmm2/m128 to xmm1 and stores result in xmm1.
	fn addps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add the low double-precision floating-point value from xmm2/m64 to xmm1.
	fn addsd(&mut self, arg0: Xmm, arg1: M64);

	/// Add the low double-precision floating-point value from xmm2/m64 to xmm1.
	fn addsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add the low single-precision floating-point value from xmm2/m32 to xmm1.
	fn addss(&mut self, arg0: Xmm, arg1: M32);

	/// Add the low single-precision floating-point value from xmm2/m32 to xmm1.
	fn addss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add/subtract double-precision floating-point values from xmm2/m128 to xmm1.
	fn addsubpd(&mut self, arg0: Xmm, arg1: M128);

	/// Add/subtract double-precision floating-point values from xmm2/m128 to xmm1.
	fn addsubpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add/subtract single-precision floating-point values from xmm2/m128 to xmm1.
	fn addsubps(&mut self, arg0: Xmm, arg1: M128);

	/// Add/subtract single-precision floating-point values from xmm2/m128 to xmm1.
	fn addsubps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesdec(&mut self, arg0: Xmm, arg1: M128);

	/// Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesdec(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesdeclast(&mut self, arg0: Xmm, arg1: M128);

	/// Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesdeclast(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesenc(&mut self, arg0: Xmm, arg1: M128);

	/// Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesenc(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesenclast(&mut self, arg0: Xmm, arg1: M128);

	/// Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.
	fn aesenclast(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.
	fn aesimc(&mut self, arg0: Xmm, arg1: M128);

	/// Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.
	fn aesimc(&mut self, arg0: Xmm, arg1: Xmm);

	/// Assist in AES round key generation using an 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.
	fn aeskeygenassist(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Assist in AES round key generation using an 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.
	fn aeskeygenassist(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// AL AND imm8.
	void and_(const Al& arg0, arg1: Imm8);

	/// AX AND imm16.
	void and_(const Ax& arg0, arg1: Imm16);

	/// EAX AND imm32.
	void and_(const Eax& arg0, arg1: Imm32);

	/// r/m16 AND imm16.
	void and_(const M16& arg0, arg1: Imm16);

	/// r/m16 AND imm8 (sign-extended).
	void and_(const M16& arg0, arg1: Imm8);

	/// r/m16 AND r16.
	void and_(const M16& arg0, arg1: R16);

	/// r/m32 AND imm32.
	void and_(const M32& arg0, arg1: Imm32);

	/// r/m32 AND imm8 (sign-extended).
	void and_(const M32& arg0, arg1: Imm8);

	/// r/m32 AND r32.
	void and_(const M32& arg0, arg1: R32);

	/// r/m64 AND imm32 sign extended to 64-bits.
	void and_(const M64& arg0, arg1: Imm32);

	/// r/m64 AND imm8 (sign-extended).
	void and_(const M64& arg0, arg1: Imm8);

	/// r/m64 AND r32.
	void and_(const M64& arg0, arg1: R64);

	/// r/m8 AND imm8.
	void and_(const M8& arg0, arg1: Imm8);

	/// r/m8 AND r8.
	void and_(const M8& arg0, arg1: R8);

	/// r/m8 AND r8.
	void and_(const M8& arg0, arg1: Rh);

	/// r/m16 AND imm16.
	void and_(const R16& arg0, arg1: Imm16);

	/// r/m16 AND imm8 (sign-extended).
	void and_(const R16& arg0, arg1: Imm8);

	/// r16 AND r/m16.
	void and_(const R16& arg0, arg1: M16);

	/// r/m16 AND r16.
	void and_(const R16& arg0, arg1: R16);

	/// r16 AND r/m16.
	void and__1(const R16& arg0, arg1: R16);

	/// r/m32 AND imm32.
	void and_(const R32& arg0, arg1: Imm32);

	/// r/m32 AND imm8 (sign-extended).
	void and_(const R32& arg0, arg1: Imm8);

	/// r32 AND r/m32.
	void and_(const R32& arg0, arg1: M32);

	/// r/m32 AND r32.
	void and_(const R32& arg0, arg1: R32);

	/// r32 AND r/m32.
	void and__1(const R32& arg0, arg1: R32);

	/// r/m64 AND imm32 sign extended to 64-bits.
	void and_(const R64& arg0, arg1: Imm32);

	/// r/m64 AND imm8 (sign-extended).
	void and_(const R64& arg0, arg1: Imm8);

	/// r64 AND r/m64.
	void and_(const R64& arg0, arg1: M64);

	/// r/m64 AND r32.
	void and_(const R64& arg0, arg1: R64);

	/// r64 AND r/m64.
	void and__1(const R64& arg0, arg1: R64);

	/// r/m8 AND imm8.
	void and_(const R8& arg0, arg1: Imm8);

	/// r8 AND r/m8.
	void and_(const R8& arg0, arg1: M8);

	/// r/m8 AND r8.
	void and_(const R8& arg0, arg1: R8);

	/// r8 AND r/m8.
	void and__1(const R8& arg0, arg1: R8);

	/// r/m8 AND r8.
	void and_(const R8& arg0, arg1: Rh);

	/// r8 AND r/m8.
	void and__1(const R8& arg0, arg1: Rh);

	/// RAX AND imm32 sign-extended to 64-bits.
	void and_(const Rax& arg0, arg1: Imm32);

	/// r/m8 AND imm8.
	void and_(const Rh& arg0, arg1: Imm8);

	/// r8 AND r/m8.
	void and_(const Rh& arg0, arg1: M8);

	/// r/m8 AND r8.
	void and_(const Rh& arg0, arg1: R8);

	/// r8 AND r/m8.
	void and__1(const Rh& arg0, arg1: R8);

	/// r/m8 AND r8.
	void and_(const Rh& arg0, arg1: Rh);

	/// r8 AND r/m8.
	void and__1(const Rh& arg0, arg1: Rh);

	/// Bitwise AND of inverted r32b with r/m32, store result in r32a.
	fn andn(&mut self, arg0: R32, arg1: R32, arg2: M32);

	/// Bitwise AND of inverted r32b with r/m32, store result in r32a.
	fn andn(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Bitwise AND of inverted r64b with r/m64, store result in r64a.
	fn andn(&mut self, arg0: R64, arg1: R64, arg2: M64);

	/// Bitwise AND of inverted r64b with r/m64, store result in r64a.
	fn andn(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Bitwise logical AND NOT of xmm2/m128 and xmm1.
	fn andnpd(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise logical AND NOT of xmm2/m128 and xmm1.
	fn andnpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Bitwise logical AND NOT of xmm2/m128 and xmm1.
	fn andnps(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise logical AND NOT of xmm2/m128 and xmm1.
	fn andnps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the bitwise logical AND of packed double-precision floating-point values in xmm1 and xmm2/m128.
	fn andpd(&mut self, arg0: Xmm, arg1: M128);

	/// Return the bitwise logical AND of packed double-precision floating-point values in xmm1 and xmm2/m128.
	fn andpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Bitwise logical AND of xmm2/m128 and xmm1.
	fn andps(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise logical AND of xmm2/m128 and xmm1.
	fn andps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.
	fn bextr(&mut self, arg0: R32, arg1: M32, arg2: R32);

	/// Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.
	fn bextr(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a.
	fn bextr(&mut self, arg0: R64, arg1: M64, arg2: R64);

	/// Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a.
	fn bextr(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Select packed DP-FP values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn blendpd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Select packed DP-FP values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn blendpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn blendps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn blendps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Select packed DP FP values from xmm1 and xmm2 from mask specified in XMM0 and store the values in xmm1.
	fn blendvpd(&mut self, arg0: Xmm, arg1: M128, arg2: Xmm0);

	/// Select packed DP FP values from xmm1 and xmm2 from mask specified in XMM0 and store the values in xmm1.
	fn blendvpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm0);

	/// Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in XMM0 and store the values into xmm1.
	fn blendvps(&mut self, arg0: Xmm, arg1: M128, arg2: Xmm0);

	/// Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in XMM0 and store the values into xmm1.
	fn blendvps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm0);

	/// Extract lowest set bit from r/m32 and set that bit in r32.
	fn blsi(&mut self, arg0: R32, arg1: M32);

	/// Extract lowest set bit from r/m32 and set that bit in r32.
	fn blsi(&mut self, arg0: R32, arg1: R32);

	/// Extract lowest set bit from r/m64, and set that bit in r64.
	fn blsi(&mut self, arg0: R64, arg1: M64);

	/// Extract lowest set bit from r/m64, and set that bit in r64.
	fn blsi(&mut self, arg0: R64, arg1: R64);

	/// Set all lower bits in r32 to "1" starting from bit 0 to lowest set bit in r/m32.
	fn blsmsk(&mut self, arg0: R32, arg1: M32);

	/// Set all lower bits in r32 to "1" starting from bit 0 to lowest set bit in r/m32.
	fn blsmsk(&mut self, arg0: R32, arg1: R32);

	/// Set all lower bits in r64 to "1" starting from bit 0 to lowest set bit in r/m64.
	fn blsmsk(&mut self, arg0: R64, arg1: M64);

	/// Set all lower bits in r64 to "1" starting from bit 0 to lowest set bit in r/m64.
	fn blsmsk(&mut self, arg0: R64, arg1: R64);

	/// Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.
	fn blsr(&mut self, arg0: R32, arg1: M32);

	/// Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.
	fn blsr(&mut self, arg0: R32, arg1: R32);

	/// Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.
	fn blsr(&mut self, arg0: R64, arg1: M64);

	/// Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.
	fn blsr(&mut self, arg0: R64, arg1: R64);

	/// Bit scan forward on r/m16.
	fn bsf(&mut self, arg0: R16, arg1: M16);

	/// Bit scan forward on r/m16.
	fn bsf(&mut self, arg0: R16, arg1: R16);

	/// Bit scan forward on r/m32.
	fn bsf(&mut self, arg0: R32, arg1: M32);

	/// Bit scan forward on r/m32.
	fn bsf(&mut self, arg0: R32, arg1: R32);

	/// Bit scan forward on r/m64.
	fn bsf(&mut self, arg0: R64, arg1: M64);

	/// Bit scan forward on r/m64.
	fn bsf(&mut self, arg0: R64, arg1: R64);

	/// Bit scan reverse on r/m16.
	fn bsr(&mut self, arg0: R16, arg1: M16);

	/// Bit scan reverse on r/m16.
	fn bsr(&mut self, arg0: R16, arg1: R16);

	/// Bit scan reverse on r/m32.
	fn bsr(&mut self, arg0: R32, arg1: M32);

	/// Bit scan reverse on r/m32.
	fn bsr(&mut self, arg0: R32, arg1: R32);

	/// Bit scan reverse on r/m64.
	fn bsr(&mut self, arg0: R64, arg1: M64);

	/// Bit scan reverse on r/m64.
	fn bsr(&mut self, arg0: R64, arg1: R64);

	/// Reverses the byte order of a 32-bit register.
	fn bswap(&mut self, arg0: R32);

	/// Reverses the byte order of a 64-bit register.
	fn bswap(&mut self, arg0: R64);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M16, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M16, arg1: R16);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M32, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M32, arg1: R32);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M64, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: M64, arg1: R64);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R16, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R16, arg1: R16);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R32, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R32, arg1: R32);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R64, arg1: Imm8);

	/// Store selected bit in CF flag.
	fn bt(&mut self, arg0: R64, arg1: R64);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M16, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M16, arg1: R16);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M32, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M32, arg1: R32);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M64, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: M64, arg1: R64);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R16, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R16, arg1: R16);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R32, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R32, arg1: R32);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R64, arg1: Imm8);

	/// Store selected bit in CF flag and complement.
	fn btc(&mut self, arg0: R64, arg1: R64);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M16, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M16, arg1: R16);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M32, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M32, arg1: R32);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M64, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: M64, arg1: R64);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R16, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R16, arg1: R16);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R32, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R32, arg1: R32);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R64, arg1: Imm8);

	/// Store selected bit in CF flag and clear.
	fn btr(&mut self, arg0: R64, arg1: R64);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M16, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M16, arg1: R16);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M32, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M32, arg1: R32);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M64, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: M64, arg1: R64);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R16, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R16, arg1: R16);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R32, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R32, arg1: R32);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R64, arg1: Imm8);

	/// Store selected bit in CF flag and set.
	fn bts(&mut self, arg0: R64, arg1: R64);

	/// Zero bits in r/m32 starting with the position in r32b, write result to r32a.
	fn bzhi(&mut self, arg0: R32, arg1: M32, arg2: R32);

	/// Zero bits in r/m32 starting with the position in r32b, write result to r32a.
	fn bzhi(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Zero bits in r/m64 starting with the position in r64b, write result to r64a.
	fn bzhi(&mut self, arg0: R64, arg1: M64, arg2: R64);

	/// Zero bits in r/m64 starting with the position in r64b, write result to r64a.
	fn bzhi(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Call far, absolute indirect address given in m16:16.
	/// In 32-bit mode: if selector points to a gate, then RIP = 32-bit zero extended displacement taken from gate; else RIP = zero extended 16- bit offset from far pointer referenced in the instruction.
	fn call(&mut self, arg0: FarPtr1616);

	/// In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = zero extended 32-bit offset from far pointer referenced in the instruction.
	fn call(&mut self, arg0: FarPtr1632);

	/// In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = 64-bit offset from far pointer referenced in the instruction.
	fn call(&mut self, arg0: FarPtr1664);

	/// Call near, relative, displacement relative to next instruction.
	/// 32-bit displacement sign extended to 64-bits in 64-bit mode.
	fn call(&mut self, arg0: Label);

	/// Call near, absolute indirect, address given in r/m64.
	fn call(&mut self, arg0: M64);

	/// Call near, absolute indirect, address given in r/m64.
	fn call(&mut self, arg0: R64);

	/// Call near, relative, displacement relative to next instruction.
	/// 32-bit displacement sign extended to 64-bits in 64-bit mode.
	fn call(&mut self, arg0: Rel32);

	/// AX = sign-extend of AL.
	fn cbw(&mut self);

	/// EDX:EAX = sign-extend of EAX.
	fn cdq(&mut self);

	/// RAX = sign-extend of EAX.
	fn cdqe(&mut self);

	/// Clear CF flag.
	fn clc(&mut self);

	/// Clear DF flag.
	fn cld(&mut self);

	/// Flushes cache line containing m8.
	fn clflush(&mut self, arg0: M8);

	/// Clear interrupt flag; interrupts disabled when interrupt flag cleared.
	fn cli(&mut self);

	/// Complement CF flag.
	fn cmc(&mut self);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R16, arg1: M16);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R16, arg1: R16);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R32, arg1: M32);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R32, arg1: R32);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R64, arg1: M64);

	/// Move if above (CF=0 and ZF=0).
	fn cmova(&mut self, arg0: R64, arg1: R64);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R16, arg1: M16);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R16, arg1: R16);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R32, arg1: M32);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R32, arg1: R32);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R64, arg1: M64);

	/// Move if above or equal (CF=0).
	fn cmovae(&mut self, arg0: R64, arg1: R64);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R16, arg1: M16);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R16, arg1: R16);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R32, arg1: M32);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R32, arg1: R32);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R64, arg1: M64);

	/// Move if below (CF=1).
	fn cmovb(&mut self, arg0: R64, arg1: R64);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R16, arg1: M16);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R16, arg1: R16);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R32, arg1: M32);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R32, arg1: R32);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R64, arg1: M64);

	/// Move if below or equal (CF=1 or ZF=1).
	fn cmovbe(&mut self, arg0: R64, arg1: R64);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R16, arg1: M16);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R16, arg1: R16);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R32, arg1: M32);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R32, arg1: R32);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R64, arg1: M64);

	/// Move if carry (CF=1).
	fn cmovc(&mut self, arg0: R64, arg1: R64);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R16, arg1: M16);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R16, arg1: R16);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R32, arg1: M32);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R32, arg1: R32);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R64, arg1: M64);

	/// Move if equal (ZF=1).
	fn cmove(&mut self, arg0: R64, arg1: R64);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R16, arg1: M16);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R16, arg1: R16);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R32, arg1: M32);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R32, arg1: R32);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R64, arg1: M64);

	/// Move if greater (ZF=0 and SF=OF).
	fn cmovg(&mut self, arg0: R64, arg1: R64);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R16, arg1: M16);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R16, arg1: R16);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R32, arg1: M32);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R32, arg1: R32);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R64, arg1: M64);

	/// Move if greater or equal (SF=OF).
	fn cmovge(&mut self, arg0: R64, arg1: R64);

	/// Move if less (SF != OF).
	fn cmovl(&mut self, arg0: R16, arg1: M16);

	/// Move if less (SF != OF).
	fn cmovl(&mut self, arg0: R16, arg1: R16);

	/// Move if less (SF!= OF).
	fn cmovl(&mut self, arg0: R32, arg1: M32);

	/// Move if less (SF!= OF).
	fn cmovl(&mut self, arg0: R32, arg1: R32);

	/// Move if less (SF!= OF).
	fn cmovl(&mut self, arg0: R64, arg1: M64);

	/// Move if less (SF!= OF).
	fn cmovl(&mut self, arg0: R64, arg1: R64);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R16, arg1: M16);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R16, arg1: R16);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R32, arg1: M32);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R32, arg1: R32);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R64, arg1: M64);

	/// Move if less or equal (ZF=1 or SF!= OF).
	fn cmovle(&mut self, arg0: R64, arg1: R64);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R16, arg1: M16);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R16, arg1: R16);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R32, arg1: M32);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R32, arg1: R32);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R64, arg1: M64);

	/// Move if not above (CF=1 or ZF=1).
	fn cmovna(&mut self, arg0: R64, arg1: R64);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R16, arg1: M16);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R16, arg1: R16);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R32, arg1: M32);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R32, arg1: R32);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R64, arg1: M64);

	/// Move if not above or equal (CF=1).
	fn cmovnae(&mut self, arg0: R64, arg1: R64);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R16, arg1: M16);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R16, arg1: R16);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R32, arg1: M32);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R32, arg1: R32);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R64, arg1: M64);

	/// Move if not below (CF=0).
	fn cmovnb(&mut self, arg0: R64, arg1: R64);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R16, arg1: M16);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R16, arg1: R16);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R32, arg1: M32);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R32, arg1: R32);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R64, arg1: M64);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn cmovnbe(&mut self, arg0: R64, arg1: R64);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R16, arg1: M16);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R16, arg1: R16);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R32, arg1: M32);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R32, arg1: R32);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R64, arg1: M64);

	/// Move if not carry (CF=0).
	fn cmovnc(&mut self, arg0: R64, arg1: R64);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R16, arg1: M16);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R16, arg1: R16);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R32, arg1: M32);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R32, arg1: R32);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R64, arg1: M64);

	/// Move if not equal (ZF=0).
	fn cmovne(&mut self, arg0: R64, arg1: R64);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R16, arg1: M16);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R16, arg1: R16);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R32, arg1: M32);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R32, arg1: R32);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R64, arg1: M64);

	/// Move if not greater (ZF=1 or SF!= OF).
	fn cmovng(&mut self, arg0: R64, arg1: R64);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R16, arg1: M16);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R16, arg1: R16);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R32, arg1: M32);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R32, arg1: R32);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R64, arg1: M64);

	/// Move if not greater or equal (SF!= OF).
	fn cmovnge(&mut self, arg0: R64, arg1: R64);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R16, arg1: M16);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R16, arg1: R16);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R32, arg1: M32);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R32, arg1: R32);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R64, arg1: M64);

	/// Move if not less (SF=OF).
	fn cmovnl(&mut self, arg0: R64, arg1: R64);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R16, arg1: M16);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R16, arg1: R16);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R32, arg1: M32);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R32, arg1: R32);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R64, arg1: M64);

	/// Move if not less or equal (ZF=0 and SF=OF).
	fn cmovnle(&mut self, arg0: R64, arg1: R64);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R16, arg1: M16);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R16, arg1: R16);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R32, arg1: M32);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R32, arg1: R32);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R64, arg1: M64);

	/// Move if not overflow (OF=0).
	fn cmovno(&mut self, arg0: R64, arg1: R64);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R16, arg1: M16);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R16, arg1: R16);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R32, arg1: M32);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R32, arg1: R32);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R64, arg1: M64);

	/// Move if not parity (PF=0).
	fn cmovnp(&mut self, arg0: R64, arg1: R64);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R16, arg1: M16);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R16, arg1: R16);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R32, arg1: M32);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R32, arg1: R32);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R64, arg1: M64);

	/// Move if not sign (SF=0).
	fn cmovns(&mut self, arg0: R64, arg1: R64);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R16, arg1: M16);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R16, arg1: R16);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R32, arg1: M32);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R32, arg1: R32);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R64, arg1: M64);

	/// Move if not zero (ZF=0).
	fn cmovnz(&mut self, arg0: R64, arg1: R64);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R16, arg1: M16);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R16, arg1: R16);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R32, arg1: M32);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R32, arg1: R32);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R64, arg1: M64);

	/// Move if overflow (OF=1).
	fn cmovo(&mut self, arg0: R64, arg1: R64);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R16, arg1: M16);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R16, arg1: R16);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R32, arg1: M32);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R32, arg1: R32);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R64, arg1: M64);

	/// Move if parity (PF=1).
	fn cmovp(&mut self, arg0: R64, arg1: R64);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R16, arg1: M16);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R16, arg1: R16);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R32, arg1: M32);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R32, arg1: R32);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R64, arg1: M64);

	/// Move if parity even (PF=1).
	fn cmovpe(&mut self, arg0: R64, arg1: R64);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R16, arg1: M16);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R16, arg1: R16);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R32, arg1: M32);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R32, arg1: R32);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R64, arg1: M64);

	/// Move if parity odd (PF=0).
	fn cmovpo(&mut self, arg0: R64, arg1: R64);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R16, arg1: M16);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R16, arg1: R16);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R32, arg1: M32);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R32, arg1: R32);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R64, arg1: M64);

	/// Move if sign (SF=1).
	fn cmovs(&mut self, arg0: R64, arg1: R64);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R16, arg1: M16);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R16, arg1: R16);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R32, arg1: M32);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R32, arg1: R32);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R64, arg1: M64);

	/// Move if zero (ZF=1).
	fn cmovz(&mut self, arg0: R64, arg1: R64);

	/// Compare imm8 with AL.
	fn cmp(&mut self, arg0: Al, arg1: Imm8);

	/// Compare imm16 with AX.
	fn cmp(&mut self, arg0: Ax, arg1: Imm16);

	/// Compare imm32 with EAX.
	fn cmp(&mut self, arg0: Eax, arg1: Imm32);

	/// Compare imm16 with r/m16.
	fn cmp(&mut self, arg0: M16, arg1: Imm16);

	/// Compare imm8 with r/m16.
	fn cmp(&mut self, arg0: M16, arg1: Imm8);

	/// Compare r16 with r/m16.
	fn cmp(&mut self, arg0: M16, arg1: R16);

	/// Compare imm32 with r/m32.
	fn cmp(&mut self, arg0: M32, arg1: Imm32);

	/// Compare imm8 with r/m32.
	fn cmp(&mut self, arg0: M32, arg1: Imm8);

	/// Compare r32 with r/m32.
	fn cmp(&mut self, arg0: M32, arg1: R32);

	/// Compare imm32 sign-extended to 64-bits with r/m64.
	fn cmp(&mut self, arg0: M64, arg1: Imm32);

	/// Compare imm8 with r/m64.
	fn cmp(&mut self, arg0: M64, arg1: Imm8);

	/// Compare r64 with r/m64.
	fn cmp(&mut self, arg0: M64, arg1: R64);

	/// Compare imm8 with r/m8.
	fn cmp(&mut self, arg0: M8, arg1: Imm8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: M8, arg1: R8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: M8, arg1: Rh);

	/// Compare imm16 with r/m16.
	fn cmp(&mut self, arg0: R16, arg1: Imm16);

	/// Compare imm8 with r/m16.
	fn cmp(&mut self, arg0: R16, arg1: Imm8);

	/// Compare r/m16 with r16.
	fn cmp(&mut self, arg0: R16, arg1: M16);

	/// Compare r16 with r/m16.
	fn cmp(&mut self, arg0: R16, arg1: R16);

	/// Compare r/m16 with r16.
	void cmp_1(const R16& arg0, arg1: R16);

	/// Compare imm32 with r/m32.
	fn cmp(&mut self, arg0: R32, arg1: Imm32);

	/// Compare imm8 with r/m32.
	fn cmp(&mut self, arg0: R32, arg1: Imm8);

	/// Compare r/m32 with r32.
	fn cmp(&mut self, arg0: R32, arg1: M32);

	/// Compare r32 with r/m32.
	fn cmp(&mut self, arg0: R32, arg1: R32);

	/// Compare r/m32 with r32.
	void cmp_1(const R32& arg0, arg1: R32);

	/// Compare imm32 sign-extended to 64-bits with r/m64.
	fn cmp(&mut self, arg0: R64, arg1: Imm32);

	/// Compare imm8 with r/m64.
	fn cmp(&mut self, arg0: R64, arg1: Imm8);

	/// Compare r/m64 with r64.
	fn cmp(&mut self, arg0: R64, arg1: M64);

	/// Compare r64 with r/m64.
	fn cmp(&mut self, arg0: R64, arg1: R64);

	/// Compare r/m64 with r64.
	void cmp_1(const R64& arg0, arg1: R64);

	/// Compare imm8 with r/m8.
	fn cmp(&mut self, arg0: R8, arg1: Imm8);

	/// Compare r/m8 with r8.
	fn cmp(&mut self, arg0: R8, arg1: M8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: R8, arg1: R8);

	/// Compare r/m8 with r8.
	void cmp_1(const R8& arg0, arg1: R8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: R8, arg1: Rh);

	/// Compare r/m8 with r8.
	void cmp_1(const R8& arg0, arg1: Rh);

	/// Compare imm32 sign-extended to 64-bits with RAX.
	fn cmp(&mut self, arg0: Rax, arg1: Imm32);

	/// Compare imm8 with r/m8.
	fn cmp(&mut self, arg0: Rh, arg1: Imm8);

	/// Compare r/m8 with r8.
	fn cmp(&mut self, arg0: Rh, arg1: M8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: Rh, arg1: R8);

	/// Compare r/m8 with r8.
	void cmp_1(const Rh& arg0, arg1: R8);

	/// Compare r8 with r/m8.
	fn cmp(&mut self, arg0: Rh, arg1: Rh);

	/// Compare r/m8 with r8.
	void cmp_1(const Rh& arg0, arg1: Rh);

	/// Compare packed double-precision floating- point values in xmm2/m128 and xmm1 using imm8 as comparison predicate.
	fn cmppd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Compare packed double-precision floating- point values in xmm2/m128 and xmm1 using imm8 as comparison predicate.
	fn cmppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Compare packed single-precision floating- point values in xmm2/mem and xmm1 using imm8 as comparison predicate.
	fn cmpps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Compare packed single-precision floating- point values in xmm2/mem and xmm1 using imm8 as comparison predicate.
	fn cmpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmps(&mut self, arg0: M16, arg1: M16);

	/// For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmps(&mut self, arg0: M32, arg1: M32);

	/// Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.
	fn cmps(&mut self, arg0: M64, arg1: M64);

	/// For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmps(&mut self, arg0: M8, arg1: M8);

	/// For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64- bit mode compare byte at address (R|E)SI with byte at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmpsb(&mut self);

	/// For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmpsd(&mut self);

	/// Compare low double-precision floating-point value in xmm2/m64 and xmm1 using imm8 as comparison predicate.
	fn cmpsd(&mut self, arg0: Xmm, arg1: M64, arg2: Imm8);

	/// Compare low double-precision floating-point value in xmm2/m64 and xmm1 using imm8 as comparison predicate.
	fn cmpsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.
	fn cmpsq(&mut self);

	/// Compare low single-precision floating-point value in xmm2/m32 and xmm1 using imm8 as comparison predicate.
	fn cmpss(&mut self, arg0: Xmm, arg1: M32, arg2: Imm8);

	/// Compare low single-precision floating-point value in xmm2/m32 and xmm1 using imm8 as comparison predicate.
	fn cmpss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64- bit mode compare word at address (R|E)SI with word at address (R|E)DI.
	/// The status flags are set accordingly.
	fn cmpsw(&mut self);

	/// Compare AX with r/m16.
	/// If equal, ZF is set and r16 is loaded into r/m16.
	/// Else, clear ZF and load r/m16 into AX.
	fn cmpxchg(&mut self, arg0: M16, arg1: R16);

	/// Compare EAX with r/m32.
	/// If equal, ZF is set and r32 is loaded into r/m32.
	/// Else, clear ZF and load r/m32 into EAX.
	fn cmpxchg(&mut self, arg0: M32, arg1: R32);

	/// Compare RAX with r/m64.
	/// If equal, ZF is set and r64 is loaded into r/m64.
	/// Else, clear ZF and load r/m64 into RAX.
	fn cmpxchg(&mut self, arg0: M64, arg1: R64);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: M8, arg1: R8);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: M8, arg1: Rh);

	/// Compare AX with r/m16.
	/// If equal, ZF is set and r16 is loaded into r/m16.
	/// Else, clear ZF and load r/m16 into AX.
	fn cmpxchg(&mut self, arg0: R16, arg1: R16);

	/// Compare EAX with r/m32.
	/// If equal, ZF is set and r32 is loaded into r/m32.
	/// Else, clear ZF and load r/m32 into EAX.
	fn cmpxchg(&mut self, arg0: R32, arg1: R32);

	/// Compare RAX with r/m64.
	/// If equal, ZF is set and r64 is loaded into r/m64.
	/// Else, clear ZF and load r/m64 into RAX.
	fn cmpxchg(&mut self, arg0: R64, arg1: R64);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: R8, arg1: R8);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: R8, arg1: Rh);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: Rh, arg1: R8);

	/// Compare AL with r/m8.
	/// If equal, ZF is set and r8 is loaded into r/m8.
	/// Else, clear ZF and load r/m8 into AL.
	fn cmpxchg(&mut self, arg0: Rh, arg1: Rh);

	/// Compare RDX:RAX with m128.
	/// If equal, set ZF and load RCX:RBX into m128.
	/// Else, clear ZF and load m128 into RDX:RAX.
	fn cmpxchg16b(&mut self, arg0: M128);

	/// Compare EDX:EAX with m64.
	/// If equal, set ZF and load ECX:EBX into m64.
	/// Else, clear ZF and load m64 into EDX:EAX.
	fn cmpxchg8b(&mut self, arg0: M64);

	/// Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn comisd(&mut self, arg0: Xmm, arg1: M64);

	/// Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn comisd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn comiss(&mut self, arg0: Xmm, arg1: M32);

	/// Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn comiss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Returns processor identification and feature information to the EAX, EBX, ECX, and EDX registers, as determined by input entered in EAX (in some cases, ECX as well).
	fn cpuid(&mut self);

	/// RDX:RAX = sign-extend of RAX.
	fn cqo(&mut self);

	/// Accumulate CRC32 on r/m16.
	fn crc32(&mut self, arg0: R32, arg1: M16);

	/// Accumulate CRC32 on r/m32.
	fn crc32(&mut self, arg0: R32, arg1: M32);

	/// Accumulate CRC32 on r/m8.
	fn crc32(&mut self, arg0: R32, arg1: M8);

	/// Accumulate CRC32 on r/m16.
	fn crc32(&mut self, arg0: R32, arg1: R16);

	/// Accumulate CRC32 on r/m32.
	fn crc32(&mut self, arg0: R32, arg1: R32);

	/// Accumulate CRC32 on r/m8.
	fn crc32(&mut self, arg0: R32, arg1: R8);

	/// Accumulate CRC32 on r/m8.
	fn crc32(&mut self, arg0: R32, arg1: Rh);

	/// Accumulate CRC32 on r/m64.
	fn crc32(&mut self, arg0: R64, arg1: M64);

	/// Accumulate CRC32 on r/m8.
	fn crc32(&mut self, arg0: R64, arg1: M8);

	/// Accumulate CRC32 on r/m64.
	fn crc32(&mut self, arg0: R64, arg1: R64);

	/// Accumulate CRC32 on r/m8.
	fn crc32(&mut self, arg0: R64, arg1: R8);

	/// Convert two packed signed doubleword integers from xmm2/m128 to two packed double-precision floating-point values in xmm1.
	fn cvtdq2pd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two packed signed doubleword integers from xmm2/m128 to two packed double-precision floating-point values in xmm1.
	fn cvtdq2pd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed signed doubleword integers from xmm2/m128 to four packed single-precision floating-point values in xmm1.
	fn cvtdq2ps(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed signed doubleword integers from xmm2/m128 to four packed single-precision floating-point values in xmm1.
	fn cvtdq2ps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed double-precision floating- point values from xmm2/m128 to two packed signed doubleword integers in xmm1.
	fn cvtpd2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert two packed double-precision floating- point values from xmm2/m128 to two packed signed doubleword integers in xmm1.
	fn cvtpd2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed double-precision floating- point values from xmm/m128 to two packed signed doubleword integers in mm.
	fn cvtpd2pi(&mut self, arg0: Mm, arg1: M128);

	/// Convert two packed double-precision floating- point values from xmm/m128 to two packed signed doubleword integers in mm.
	fn cvtpd2pi(&mut self, arg0: Mm, arg1: Xmm);

	/// Convert two packed double-precision floating- point values in xmm2/m128 to two packed single-precision floating-point values in xmm1.
	fn cvtpd2ps(&mut self, arg0: Xmm, arg1: M128);

	/// Convert two packed double-precision floating- point values in xmm2/m128 to two packed single-precision floating-point values in xmm1.
	fn cvtpd2ps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed signed doubleword integers from mm/mem64 to two packed double-precision floating-point values in xmm.
	fn cvtpi2pd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two packed signed doubleword integers from mm/mem64 to two packed double-precision floating-point values in xmm.
	fn cvtpi2pd(&mut self, arg0: Xmm, arg1: Mm);

	/// Convert two signed doubleword integers from mm/m64 to two single-precision floating-point values in xmm.
	fn cvtpi2ps(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two signed doubleword integers from mm/m64 to two single-precision floating-point values in xmm.
	fn cvtpi2ps(&mut self, arg0: Xmm, arg1: Mm);

	/// Convert four packed single-precision floating- point values from xmm2/m128 to four packed signed doubleword integers in xmm1.
	fn cvtps2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed single-precision floating- point values from xmm2/m128 to four packed signed doubleword integers in xmm1.
	fn cvtps2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed single-precision floating- point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.
	fn cvtps2pd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two packed single-precision floating- point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.
	fn cvtps2pd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed single-precision floating- point values from xmm/m64 to two packed signed doubleword integers in mm.
	fn cvtps2pi(&mut self, arg0: Mm, arg1: M64);

	/// Convert two packed single-precision floating- point values from xmm/m64 to two packed signed doubleword integers in mm.
	fn cvtps2pi(&mut self, arg0: Mm, arg1: Xmm);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed doubleword integer r32.
	fn cvtsd2si(&mut self, arg0: R32, arg1: M64);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed doubleword integer r32.
	fn cvtsd2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed quadword integer sign-extended into r64.
	fn cvtsd2si(&mut self, arg0: R64, arg1: M64);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed quadword integer sign-extended into r64.
	fn cvtsd2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert one double-precision floating-point value in xmm2/m64 to one single-precision floating-point value in xmm1.
	fn cvtsd2ss(&mut self, arg0: Xmm, arg1: M64);

	/// Convert one double-precision floating-point value in xmm2/m64 to one single-precision floating-point value in xmm1.
	fn cvtsd2ss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm.
	fn cvtsi2sd(&mut self, arg0: Xmm, arg1: M32);

	/// Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm.
	fn cvtsi2sd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm.
	fn cvtsi2sd(&mut self, arg0: Xmm, arg1: R32);

	/// Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm.
	fn cvtsi2sd(&mut self, arg0: Xmm, arg1: R64);

	/// Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm.
	fn cvtsi2ss(&mut self, arg0: Xmm, arg1: M32);

	/// Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm.
	fn cvtsi2ss(&mut self, arg0: Xmm, arg1: M64);

	/// Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm.
	fn cvtsi2ss(&mut self, arg0: Xmm, arg1: R32);

	/// Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm.
	fn cvtsi2ss(&mut self, arg0: Xmm, arg1: R64);

	/// Convert one single-precision floating-point value in xmm2/m32 to one double-precision floating-point value in xmm1.
	fn cvtss2sd(&mut self, arg0: Xmm, arg1: M32);

	/// Convert one single-precision floating-point value in xmm2/m32 to one double-precision floating-point value in xmm1.
	fn cvtss2sd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed doubleword integer in r32.
	fn cvtss2si(&mut self, arg0: R32, arg1: M32);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed doubleword integer in r32.
	fn cvtss2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed quadword integer in r64.
	fn cvtss2si(&mut self, arg0: R64, arg1: M32);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed quadword integer in r64.
	fn cvtss2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert two packed double-precision floating- point values from xmm2/m128 to two packed signed doubleword integers in xmm1 using truncation.
	fn cvttpd2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert two packed double-precision floating- point values from xmm2/m128 to two packed signed doubleword integers in xmm1 using truncation.
	fn cvttpd2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packer double-precision floating- point values from xmm/m128 to two packed signed doubleword integers in mm using truncation.
	fn cvttpd2pi(&mut self, arg0: Mm, arg1: M128);

	/// Convert two packer double-precision floating- point values from xmm/m128 to two packed signed doubleword integers in mm using truncation.
	fn cvttpd2pi(&mut self, arg0: Mm, arg1: Xmm);

	/// Convert four single-precision floating-point values from xmm2/m128 to four signed doubleword integers in xmm1 using truncation.
	fn cvttps2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four single-precision floating-point values from xmm2/m128 to four signed doubleword integers in xmm1 using truncation.
	fn cvttps2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two single-precision floating-point values from xmm/m64 to two signed doubleword signed integers in mm using truncation.
	fn cvttps2pi(&mut self, arg0: Mm, arg1: M64);

	/// Convert two single-precision floating-point values from xmm/m64 to two signed doubleword signed integers in mm using truncation.
	fn cvttps2pi(&mut self, arg0: Mm, arg1: Xmm);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed doubleword integer in r32 using truncation.
	fn cvttsd2si(&mut self, arg0: R32, arg1: M64);

	/// Convert one double-precision floating-point value from xmm/m64 to one signed doubleword integer in r32 using truncation.
	fn cvttsd2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one double precision floating-point value from xmm/m64 to one signedquadword integer in r64 using truncation.
	fn cvttsd2si(&mut self, arg0: R64, arg1: M64);

	/// Convert one double precision floating-point value from xmm/m64 to one signedquadword integer in r64 using truncation.
	fn cvttsd2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed doubleword integer in r32 using truncation.
	fn cvttss2si(&mut self, arg0: R32, arg1: M32);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed doubleword integer in r32 using truncation.
	fn cvttss2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed quadword integer in r64 using truncation.
	fn cvttss2si(&mut self, arg0: R64, arg1: M32);

	/// Convert one single-precision floating-point value from xmm/m32 to one signed quadword integer in r64 using truncation.
	fn cvttss2si(&mut self, arg0: R64, arg1: Xmm);

	/// DX:AX = sign-extend of AX.
	fn cwd(&mut self);

	/// EAX = sign-extend of AX.
	fn cwde(&mut self);

	/// Decrement r/m16 by 1.
	fn dec(&mut self, arg0: M16);

	/// Decrement r/m32 by 1.
	fn dec(&mut self, arg0: M32);

	/// Decrement r/m64 by 1.
	fn dec(&mut self, arg0: M64);

	/// Decrement r/m8 by 1.
	fn dec(&mut self, arg0: M8);

	/// Decrement r/m16 by 1.
	fn dec(&mut self, arg0: R16);

	/// Decrement r/m32 by 1.
	fn dec(&mut self, arg0: R32);

	/// Decrement r/m64 by 1.
	fn dec(&mut self, arg0: R64);

	/// Decrement r/m8 by 1.
	fn dec(&mut self, arg0: R8);

	/// Decrement r/m8 by 1.
	fn dec(&mut self, arg0: Rh);

	/// Unsigned divide DX:AX by r/m16, with result stored in AX = Quotient, DX = Remainder.
	fn div(&mut self, arg0: M16);

	/// Unsigned divide EDX:EAX by r/m32, with result stored in EAX = Quotient, EDX = Remainder.
	fn div(&mut self, arg0: M32);

	/// Unsigned divide RDX:RAX by r/m64, with result stored in RAX = Quotient, RDX = Remainder.
	fn div(&mut self, arg0: M64);

	/// Unsigned divide AX by r/m8, with result stored in AL = Quotient, AH = Remainder.
	fn div(&mut self, arg0: M8);

	/// Unsigned divide DX:AX by r/m16, with result stored in AX = Quotient, DX = Remainder.
	fn div(&mut self, arg0: R16);

	/// Unsigned divide EDX:EAX by r/m32, with result stored in EAX = Quotient, EDX = Remainder.
	fn div(&mut self, arg0: R32);

	/// Unsigned divide RDX:RAX by r/m64, with result stored in RAX = Quotient, RDX = Remainder.
	fn div(&mut self, arg0: R64);

	/// Unsigned divide AX by r/m8, with result stored in AL = Quotient, AH = Remainder.
	fn div(&mut self, arg0: R8);

	/// Unsigned divide AX by r/m8, with result stored in AL = Quotient, AH = Remainder.
	fn div(&mut self, arg0: Rh);

	/// Divide packed double-precision floating-point values in xmm1 by packed double-precision floating-point values xmm2/m128.
	fn divpd(&mut self, arg0: Xmm, arg1: M128);

	/// Divide packed double-precision floating-point values in xmm1 by packed double-precision floating-point values xmm2/m128.
	fn divpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Divide packed single-precision floating-point values in xmm1 by packed single-precision floating-point values xmm2/m128.
	fn divps(&mut self, arg0: Xmm, arg1: M128);

	/// Divide packed single-precision floating-point values in xmm1 by packed single-precision floating-point values xmm2/m128.
	fn divps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Divide low double-precision floating-point value in xmm1 by low double-precision floating-point value in xmm2/mem64.
	fn divsd(&mut self, arg0: Xmm, arg1: M64);

	/// Divide low double-precision floating-point value in xmm1 by low double-precision floating-point value in xmm2/mem64.
	fn divsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Divide low single-precision floating-point value in xmm1 by low single-precision floating-point value in xmm2/m32.
	fn divss(&mut self, arg0: Xmm, arg1: M32);

	/// Divide low single-precision floating-point value in xmm1 by low single-precision floating-point value in xmm2/m32.
	fn divss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Selectively multiply packed DP floating-point values from xmm1 with packed DP floating- point values from xmm2, add and selectively store the packed DP floating-point values to xmm1.
	fn dppd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Selectively multiply packed DP floating-point values from xmm1 with packed DP floating- point values from xmm2, add and selectively store the packed DP floating-point values to xmm1.
	fn dppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Selectively multiply packed SP floating-point values from xmm1 with packed SP floating- point values from xmm2, add and selectively store the packed SP floating-point values or zero values to xmm1.
	fn dpps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Selectively multiply packed SP floating-point values from xmm1 with packed SP floating- point values from xmm2, add and selectively store the packed SP floating-point values or zero values to xmm1.
	fn dpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Set the x87 FPU tag word to empty.
	fn emms(&mut self);

	/// Create a nested stack frame for a procedure.
	fn enter(&mut self, arg0: Imm8, arg1: Imm16);

	/// Create a nested stack frame for a procedure.
	fn enter(&mut self, arg0: One, arg1: Imm16);

	/// Create a stack frame for a procedure.
	fn enter(&mut self, arg0: Zero, arg1: Imm16);

	/// Extract a single-precision floating-point value from xmm2 at the source offset specified by imm8 and store the result to reg or m32.
	/// The upper 32 bits of r64 is zeroed if reg is r64.
	fn extractps(&mut self, arg0: M32, arg1: Xmm, arg2: Imm8);

	/// Extract a single-precision floating-point value from xmm2 at the source offset specified by imm8 and store the result to reg or m32.
	/// The upper 32 bits of r64 is zeroed if reg is r64.
	fn extractps(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a single-precision floating-point value from xmm2 at the source offset specified by imm8 and store the result to reg or m32.
	/// The upper 32 bits of r64 is zeroed if reg is r64.
	fn extractps(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Replace ST(0) with (2^(ST(0)) - 1).
	fn f2xm1(&mut self);

	/// Replace ST with its absolute value.
	fn fabs(&mut self);

	/// Add m32fp to ST(0) and store result in ST(0).
	fn fadd(&mut self, arg0: M32Fp);

	/// Add m64fp to ST(0) and store result in ST(0).
	fn fadd(&mut self, arg0: M64Fp);

	/// Add ST(i) to ST(0) and store result in ST(i).
	fn fadd(&mut self, arg0: St, arg1: St0);

	/// Add ST(0) to ST(i) and store result in ST(0).
	fn fadd(&mut self, arg0: St0, arg1: St);

	/// Add ST(0) to ST(1), store result in ST(1), and pop the register stack.
	fn faddp(&mut self);

	/// Add ST(0) to ST(i), store result in ST(i), and pop the register stack.
	fn faddp(&mut self, arg0: St, arg1: St0);

	/// Convert BCD value to floating-point and push onto the FPU stack.
	fn fbld(&mut self, arg0: M80Bcd);

	/// Store ST(0) in m80bcd and pop ST(0).
	fn fbstp(&mut self, arg0: M80Bcd);

	/// Complements sign of ST(0).
	fn fchs(&mut self);

	/// Clear floating-point exception flags after checking for pending unmasked floating-point exceptions.
	fn fclex(&mut self);

	/// Move if below (CF=1).
	fn fcmovb(&mut self, arg0: St0, arg1: St);

	/// Move if below or equal (CF=1 or ZF=1).
	fn fcmovbe(&mut self, arg0: St0, arg1: St);

	/// Move if equal (ZF=1).
	fn fcmove(&mut self, arg0: St0, arg1: St);

	/// Move if not below (CF=0).
	fn fcmovnb(&mut self, arg0: St0, arg1: St);

	/// Move if not below or equal (CF=0 and ZF=0).
	fn fcmovnbe(&mut self, arg0: St0, arg1: St);

	/// Move if not equal (ZF=0).
	fn fcmovne(&mut self, arg0: St0, arg1: St);

	/// Move if not unordered (PF=0).
	fn fcmovnu(&mut self, arg0: St0, arg1: St);

	/// Move if unordered (PF=1).
	fn fcmovu(&mut self, arg0: St0, arg1: St);

	/// Compare ST(0) with ST(1).
	fn fcom(&mut self);

	/// Compare ST(0) with m32fp.
	fn fcom(&mut self, arg0: M32Fp);

	/// Compare ST(0) with m64fp.
	fn fcom(&mut self, arg0: M64Fp);

	/// Compare ST(0) with ST(i).
	fn fcom(&mut self, arg0: St);

	/// Compare ST(0) with ST(i) and set status flags accordingly.
	fn fcomi(&mut self, arg0: St0, arg1: St);

	/// Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.
	fn fcomip(&mut self, arg0: St0, arg1: St);

	/// Compare ST(0) with ST(1) and pop register stack.
	fn fcomp(&mut self);

	/// Compare ST(0) with m32fp and pop register stack.
	fn fcomp(&mut self, arg0: M32Fp);

	/// Compare ST(0) with m64fp and pop register stack.
	fn fcomp(&mut self, arg0: M64Fp);

	/// Compare ST(0) with ST(i) and pop register stack.
	fn fcomp(&mut self, arg0: St);

	/// Compare ST(0) with ST(1) and pop register stack twice.
	fn fcompp(&mut self);

	/// Replace ST(0) with its cosine.
	fn fcos(&mut self);

	/// Decrement TOP field in FPU status word.
	fn fdecstp(&mut self);

	/// Divide ST(0) by m32fp and store result in ST(0).
	fn fdiv(&mut self, arg0: M32Fp);

	/// Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.
	fn fdiv(&mut self, arg0: M64Fp);

	/// Divide ST(i) by ST(0) and store result in ST(i).
	fn fdiv(&mut self, arg0: St, arg1: St0);

	/// Divide ST(0) by ST(i) and store result in ST(0).
	fn fdiv(&mut self, arg0: St0, arg1: St);

	/// Divide ST(1) by ST(0), store result in ST(1), and pop the register stack.
	fn fdivp(&mut self);

	/// Divide ST(i) by ST(0), store result in ST(i), and pop the register stack.
	fn fdivp(&mut self, arg0: St, arg1: St0);

	/// Divide m32fp by ST(0) and store result in ST(0).
	fn fdivr(&mut self, arg0: M32Fp);

	/// Divide m64fp by ST(0) and store result in ST(0).
	fn fdivr(&mut self, arg0: M64Fp);

	/// Divide ST(0) by ST(i) and store result in ST(i).
	fn fdivr(&mut self, arg0: St, arg1: St0);

	/// Divide ST(i) by ST(0) and store result in ST(0).
	fn fdivr(&mut self, arg0: St0, arg1: St);

	/// Divide ST(0) by ST(1), store result in ST(1), and pop the register stack.
	fn fdivrp(&mut self);

	/// Divide ST(0) by ST(i), store result in ST(i), and pop the register stack.
	fn fdivrp(&mut self, arg0: St, arg1: St0);

	/// Sets tag for ST(i) to empty.
	fn ffree(&mut self, arg0: St);

	/// Add m16int to ST(0) and store result in ST(0).
	fn fiadd(&mut self, arg0: M16Int);

	/// Add m32int to ST(0) and store result in ST(0).
	fn fiadd(&mut self, arg0: M32Int);

	/// Compare ST(0) with m16int.
	fn ficom(&mut self, arg0: M16Int);

	/// Compare ST(0) with m32int.
	fn ficom(&mut self, arg0: M32Int);

	/// Compare ST(0) with m16int and pop stack register.
	fn ficomp(&mut self, arg0: M16Int);

	/// Compare ST(0) with m32int and pop stack register.
	fn ficomp(&mut self, arg0: M32Int);

	/// Divide ST(0) by m64int and store result in ST(0).
	fn fidiv(&mut self, arg0: M16Int);

	/// Divide ST(0) by m32int and store result in ST(0).
	fn fidiv(&mut self, arg0: M32Int);

	/// Divide m16int by ST(0) and store result in ST(0).
	fn fidivr(&mut self, arg0: M16Int);

	/// Divide m32int by ST(0) and store result in ST(0).
	fn fidivr(&mut self, arg0: M32Int);

	/// Push m16int onto the FPU register stack.
	fn fild(&mut self, arg0: M16Int);

	/// Push m32int onto the FPU register stack.
	fn fild(&mut self, arg0: M32Int);

	/// Push m64int onto the FPU register stack.
	fn fild(&mut self, arg0: M64Int);

	/// Multiply ST(0) by m16int and store result in ST(0).
	fn fimul(&mut self, arg0: M16Int);

	/// Multiply ST(0) by m32int and store result in ST(0).
	fn fimul(&mut self, arg0: M32Int);

	/// Increment the TOP field in the FPU status register.
	fn fincstp(&mut self);

	/// Initialize FPU after checking for pending unmasked floating-point exceptions.
	fn finit(&mut self);

	/// Store ST(0) in m16int.
	fn fist(&mut self, arg0: M16Int);

	/// Store ST(0) in m32int.
	fn fist(&mut self, arg0: M32Int);

	/// Store ST(0) in m16int and pop register stack.
	fn fistp(&mut self, arg0: M16Int);

	/// Store ST(0) in m32int and pop register stack.
	fn fistp(&mut self, arg0: M32Int);

	/// Store ST(0) in m64int and pop register stack.
	fn fistp(&mut self, arg0: M64Int);

	/// Store ST(0) in m16int with truncation.
	fn fisttp(&mut self, arg0: M16Int);

	/// Store ST(0) in m32int with truncation.
	fn fisttp(&mut self, arg0: M32Int);

	/// Store ST(0) in m64int with truncation.
	fn fisttp(&mut self, arg0: M64Int);

	/// Subtract m16int from ST(0) and store result in ST(0).
	fn fisub(&mut self, arg0: M16Int);

	/// Subtract m32int from ST(0) and store result in ST(0).
	fn fisub(&mut self, arg0: M32Int);

	/// Subtract ST(0) from m16int and store result in ST(0).
	fn fisubr(&mut self, arg0: M16Int);

	/// Subtract ST(0) from m32int and store result in ST(0).
	fn fisubr(&mut self, arg0: M32Int);

	/// Push m32fp onto the FPU register stack.
	fn fld(&mut self, arg0: M32Fp);

	/// Push m64fp onto the FPU register stack.
	fn fld(&mut self, arg0: M64Fp);

	/// Push m80fp onto the FPU register stack.
	fn fld(&mut self, arg0: M80Fp);

	/// Push ST(i) onto the FPU register stack.
	fn fld(&mut self, arg0: St);

	/// Push +1.0 onto the FPU register stack.
	fn fld1(&mut self);

	/// Load FPU control word from m2byte.
	fn fldcw(&mut self, arg0: M2Byte);

	/// Load FPU environment from m14byte or m28byte.
	fn fldenv(&mut self, arg0: M28Byte);

	/// Push log2e onto the FPU register stack.
	fn fldl2e(&mut self);

	/// Push log210 onto the FPU register stack.
	fn fldl2t(&mut self);

	/// Push log102 onto the FPU register stack.
	fn fldlg2(&mut self);

	/// Push loge2 onto the FPU register stack.
	fn fldln2(&mut self);

	/// Push pi onto the FPU register stack.
	fn fldpi(&mut self);

	/// Push +0.0 onto the FPU register stack.
	fn fldz(&mut self);

	/// Multiply ST(0) by m32fp and store result in ST(0).
	fn fmul(&mut self, arg0: M32Fp);

	/// Multiply ST(0) by m64fp and store result in ST(0).
	fn fmul(&mut self, arg0: M64Fp);

	/// Multiply ST(i) by ST(0) and store result in ST(i).
	fn fmul(&mut self, arg0: St, arg1: St0);

	/// Multiply ST(0) by ST(i) and store result in ST(0).
	fn fmul(&mut self, arg0: St0, arg1: St);

	/// Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack.
	fn fmulp(&mut self);

	/// Multiply ST(i) by ST(0), store result in ST(i), and pop the register stack.
	fn fmulp(&mut self, arg0: St, arg1: St0);

	/// Clear floating-point exception flags without checking for pending unmasked floating-point exceptions.
	fn fnclex(&mut self);

	/// Initialize FPU without checking for pending unmasked floating-point exceptions.
	fn fninit(&mut self);

	/// No operation is performed.
	fn fnop(&mut self);

	/// Store FPU environment to m94byte or m108byte without checking for pending unmasked floating-point exceptions.
	/// Then re-initialize the FPU.
	fn fnsave(&mut self, arg0: M108Byte);

	/// Store FPU control word to m2byte without checking for pending unmasked floating-point exceptions.
	fn fnstcw(&mut self, arg0: M2Byte);

	/// Store FPU environment to m14byte or m28byte without checking for pending unmasked floating-point exceptions.
	/// Then mask all floating-point exceptions.
	fn fnstenv(&mut self, arg0: M28Byte);

	/// Store FPU status word in AX register without checking for pending unmasked floating-point exceptions.
	fn fnstsw(&mut self, arg0: Ax);

	/// Store FPU status word at m2byte without checking for pending unmasked floating-point exceptions.
	fn fnstsw(&mut self, arg0: M2Byte);

	/// Replace ST(1) with arctan(ST(1)/ST(0)) and pop the register stack.
	fn fpatan(&mut self);

	/// Replace ST(0) with the remainder obtained from dividing ST(0) by ST(1).
	fn fprem(&mut self);

	/// Replace ST(0) with the IEEE remainder obtained from dividing ST(0) by ST(1).
	fn fprem1(&mut self);

	/// Replace ST(0) with its tangent and push 1 onto the FPU stack.
	fn fptan(&mut self);

	/// Round ST(0) to an integer.
	fn frndint(&mut self);

	/// Load FPU state from m94byte or m108byte.
	fn frstor(&mut self, arg0: M108Byte);

	/// Store FPU state to m94byte or m108byte after checking for pending unmasked floating-point exceptions.
	/// Then re-initialize the FPU.
	fn fsave(&mut self, arg0: M108Byte);

	/// Scale ST(0) by ST(1).
	fn fscale(&mut self);

	/// Replace ST(0) with its sine.
	fn fsin(&mut self);

	/// Compute the sine and cosine of ST(0); replace ST(0) with the sine, and push the cosine onto the register stack.
	fn fsincos(&mut self);

	/// Computes square root of ST(0) and stores the result in ST(0).
	fn fsqrt(&mut self);

	/// Copy ST(0) to m32fp.
	fn fst(&mut self, arg0: M32Fp);

	/// Copy ST(0) to m64fp.
	fn fst(&mut self, arg0: M64Fp);

	/// Copy ST(0) to ST(i).
	fn fst(&mut self, arg0: St);

	/// Store FPU control word to m2byte after checking for pending unmasked floating-point exceptions.
	fn fstcw(&mut self, arg0: M2Byte);

	/// Store FPU environment to m14byte or m28byte after checking for pending unmasked floating-point exceptions.
	/// Then mask all floating-point exceptions.
	fn fstenv(&mut self, arg0: M28Byte);

	/// Copy ST(0) to m32fp and pop register stack.
	fn fstp(&mut self, arg0: M32Fp);

	/// Copy ST(0) to m64fp and pop register stack.
	fn fstp(&mut self, arg0: M64Fp);

	/// Copy ST(0) to m80fp and pop register stack.
	fn fstp(&mut self, arg0: M80Fp);

	/// Copy ST(0) to ST(i) and pop register stack.
	fn fstp(&mut self, arg0: St);

	/// Store FPU status word in AX register after checking for pending unmasked floating-point exceptions.
	fn fstsw(&mut self, arg0: Ax);

	/// Store FPU status word at m2byte after checking for pending unmasked floating-point exceptions.
	fn fstsw(&mut self, arg0: M2Byte);

	/// Subtract m32fp from ST(0) and store result in ST(0).
	fn fsub(&mut self, arg0: M32Fp);

	/// Subtract m64fp from ST(0) and store result in ST(0).
	fn fsub(&mut self, arg0: M64Fp);

	/// Subtract ST(0) from ST(i) and store result in ST(i).
	fn fsub(&mut self, arg0: St, arg1: St0);

	/// Subtract ST(i) from ST(0) and store result in ST(0).
	fn fsub(&mut self, arg0: St0, arg1: St);

	/// Subtract ST(0) from ST(1), store result in ST(1), and pop register stack.
	fn fsubp(&mut self);

	/// Subtract ST(0) from ST(i), store result in ST(i), and pop register stack.
	fn fsubp(&mut self, arg0: St, arg1: St0);

	/// Subtract ST(0) from m32fp and store result in ST(0).
	fn fsubr(&mut self, arg0: M32Fp);

	/// Subtract ST(0) from m64fp and store result in ST(0).
	fn fsubr(&mut self, arg0: M64Fp);

	/// Subtract ST(i) from ST(0) and store result in ST(i).
	fn fsubr(&mut self, arg0: St, arg1: St0);

	/// Subtract ST(0) from ST(i) and store result in ST(0).
	fn fsubr(&mut self, arg0: St0, arg1: St);

	/// Subtract ST(1) from ST(0), store result in ST(1), and pop register stack.
	fn fsubrp(&mut self);

	/// Subtract ST(i) from ST(0), store result in ST(i), and pop register stack.
	fn fsubrp(&mut self, arg0: St, arg1: St0);

	/// Compare ST(0) with 0.0.
	fn ftst(&mut self);

	/// Compare ST(0) with ST(1).
	fn fucom(&mut self);

	/// Compare ST(0) with ST(i).
	fn fucom(&mut self, arg0: St);

	/// Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.
	fn fucomi(&mut self, arg0: St0, arg1: St);

	/// Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.
	fn fucomip(&mut self, arg0: St0, arg1: St);

	/// Compare ST(0) with ST(1) and pop register stack.
	fn fucomp(&mut self);

	/// Compare ST(0) with ST(i) and pop register stack.
	fn fucomp(&mut self, arg0: St);

	/// Compare ST(0) with ST(1) and pop register stack twice.
	fn fucompp(&mut self);

	/// Check pending unmasked floating-point exceptions.
	fn fwait(&mut self);

	/// Classify value or number in ST(0).
	fn fxam(&mut self);

	/// Exchange the contents of ST(0) and ST(1).
	fn fxch(&mut self);

	/// Exchange the contents of ST(0) and ST(i).
	fn fxch(&mut self, arg0: St);

	/// Restore the x87 FPU, MMX, XMM, and MXCSR register state from m512byte.
	fn fxrstor(&mut self, arg0: M512Byte);

	/// Restore the x87 FPU, MMX, XMM, and MXCSR register state from m512byte.
	fn fxrstor64(&mut self, arg0: M512Byte);

	/// Save the x87 FPU, MMX, XMM, and MXCSR register state to m512byte.
	fn fxsave(&mut self, arg0: M512Byte);

	/// Save the x87 FPU, MMX, XMM, and MXCSR register state to m512byte.
	fn fxsave64(&mut self, arg0: M512Byte);

	/// Separate value in ST(0) into exponent and significand, store exponent in ST(0), and push the significand onto the register stack.
	fn fxtract(&mut self);

	/// Replace ST(1) with (ST(1) * log2ST(0)) and pop the register stack.
	fn fyl2x(&mut self);

	/// Replace ST(1) with ST(1) * log2(ST(0) + 1.0) and pop the register stack.
	fn fyl2xp1(&mut self);

	/// Horizontal add packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn haddpd(&mut self, arg0: Xmm, arg1: M128);

	/// Horizontal add packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn haddpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Horizontal add packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn haddps(&mut self, arg0: Xmm, arg1: M128);

	/// Horizontal add packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn haddps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Horizontal subtract packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn hsubpd(&mut self, arg0: Xmm, arg1: M128);

	/// Horizontal subtract packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn hsubpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Horizontal subtract packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn hsubps(&mut self, arg0: Xmm, arg1: M128);

	/// Horizontal subtract packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn hsubps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Signed divide DX:AX by r/m16, with result stored in AX = Quotient, DX = Remainder.
	fn idiv(&mut self, arg0: M16);

	/// Signed divide EDX:EAX by r/m32, with result stored in EAX = Quotient, EDX = Remainder.
	fn idiv(&mut self, arg0: M32);

	/// Signed divide RDX:RAX by r/m64, with result stored in RAX = Quotient, RDX = Remainder.
	fn idiv(&mut self, arg0: M64);

	/// Signed divide AX by r/m8, with result stored in: AL = Quotient, AH = Remainder.
	fn idiv(&mut self, arg0: M8);

	/// Signed divide DX:AX by r/m16, with result stored in AX = Quotient, DX = Remainder.
	fn idiv(&mut self, arg0: R16);

	/// Signed divide EDX:EAX by r/m32, with result stored in EAX = Quotient, EDX = Remainder.
	fn idiv(&mut self, arg0: R32);

	/// Signed divide RDX:RAX by r/m64, with result stored in RAX = Quotient, RDX = Remainder.
	fn idiv(&mut self, arg0: R64);

	/// Signed divide AX by r/m8, with result stored in: AL = Quotient, AH = Remainder.
	fn idiv(&mut self, arg0: R8);

	/// Signed divide AX by r/m8, with result stored in: AL = Quotient, AH = Remainder.
	fn idiv(&mut self, arg0: Rh);

	/// DX:AX = AX * r/m word.
	fn imul(&mut self, arg0: M16);

	/// EDX:EAX = EAX * r/m32.
	fn imul(&mut self, arg0: M32);

	/// RDX:RAX = RAX * r/m64.
	fn imul(&mut self, arg0: M64);

	/// AX= AL * r/m byte.
	fn imul(&mut self, arg0: M8);

	/// DX:AX = AX * r/m word.
	fn imul(&mut self, arg0: R16);

	/// word register = word register * r/m16.
	fn imul(&mut self, arg0: R16, arg1: M16);

	/// word register = r/m16 * immediate word.
	fn imul(&mut self, arg0: R16, arg1: M16, arg2: Imm16);

	/// word register = r/m16 * sign-extended immediate byte.
	fn imul(&mut self, arg0: R16, arg1: M16, arg2: Imm8);

	/// word register = word register * r/m16.
	fn imul(&mut self, arg0: R16, arg1: R16);

	/// word register = r/m16 * immediate word.
	fn imul(&mut self, arg0: R16, arg1: R16, arg2: Imm16);

	/// word register = r/m16 * sign-extended immediate byte.
	fn imul(&mut self, arg0: R16, arg1: R16, arg2: Imm8);

	/// EDX:EAX = EAX * r/m32.
	fn imul(&mut self, arg0: R32);

	/// doubleword register = doubleword register *  r/m32.
	fn imul(&mut self, arg0: R32, arg1: M32);

	/// doubleword register = r/m32 * immediate doubleword.
	fn imul(&mut self, arg0: R32, arg1: M32, arg2: Imm32);

	/// doubleword register = r/m32 * sign- extended immediate byte.
	fn imul(&mut self, arg0: R32, arg1: M32, arg2: Imm8);

	/// doubleword register = doubleword register *  r/m32.
	fn imul(&mut self, arg0: R32, arg1: R32);

	/// doubleword register = r/m32 * immediate doubleword.
	fn imul(&mut self, arg0: R32, arg1: R32, arg2: Imm32);

	/// doubleword register = r/m32 * sign- extended immediate byte.
	fn imul(&mut self, arg0: R32, arg1: R32, arg2: Imm8);

	/// RDX:RAX = RAX * r/m64.
	fn imul(&mut self, arg0: R64);

	/// Quadword register = Quadword register *  r/m64.
	fn imul(&mut self, arg0: R64, arg1: M64);

	/// Quadword register = r/m64 * immediate doubleword.
	fn imul(&mut self, arg0: R64, arg1: M64, arg2: Imm32);

	/// Quadword register = r/m64 * sign-extended  immediate byte.
	fn imul(&mut self, arg0: R64, arg1: M64, arg2: Imm8);

	/// Quadword register = Quadword register *  r/m64.
	fn imul(&mut self, arg0: R64, arg1: R64);

	/// Quadword register = r/m64 * immediate doubleword.
	fn imul(&mut self, arg0: R64, arg1: R64, arg2: Imm32);

	/// Quadword register = r/m64 * sign-extended  immediate byte.
	fn imul(&mut self, arg0: R64, arg1: R64, arg2: Imm8);

	/// AX= AL * r/m byte.
	fn imul(&mut self, arg0: R8);

	/// AX= AL * r/m byte.
	fn imul(&mut self, arg0: Rh);

	/// Input byte from I/O port in DX into AL.
	fn in(&mut self, arg0: Al, arg1: Dx);

	/// Input byte from imm8 I/O port address into AL.
	fn in(&mut self, arg0: Al, arg1: Imm8);

	/// Input word from I/O port in DX into AX.
	fn in(&mut self, arg0: Ax, arg1: Dx);

	/// Input word from imm8 I/O port address into AX.
	fn in(&mut self, arg0: Ax, arg1: Imm8);

	/// Input doubleword from I/O port in DX into EAX.
	fn in(&mut self, arg0: Eax, arg1: Dx);

	/// Input dword from imm8 I/O port address into EAX.
	fn in(&mut self, arg0: Eax, arg1: Imm8);

	/// Increment r/m word by 1.
	fn inc(&mut self, arg0: M16);

	/// Increment r/m doubleword by 1.
	fn inc(&mut self, arg0: M32);

	/// Increment r/m quadword by 1.
	fn inc(&mut self, arg0: M64);

	/// Increment r/m byte by 1.
	fn inc(&mut self, arg0: M8);

	/// Increment r/m word by 1.
	fn inc(&mut self, arg0: R16);

	/// Increment r/m doubleword by 1.
	fn inc(&mut self, arg0: R32);

	/// Increment r/m quadword by 1.
	fn inc(&mut self, arg0: R64);

	/// Increment r/m byte by 1.
	fn inc(&mut self, arg0: R8);

	/// Increment r/m byte by 1.
	fn inc(&mut self, arg0: Rh);

	/// Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
	fn ins(&mut self, arg0: M16, arg1: Dx);

	/// Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
	fn ins(&mut self, arg0: M32, arg1: Dx);

	/// Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
	fn ins(&mut self, arg0: M8, arg1: Dx);

	/// Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.
	fn insb(&mut self);

	/// Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
	fn insd(&mut self);

	/// Insert a single precision floating-point value selected by imm8 from xmm2/m32 into xmm1 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.
	fn insertps(&mut self, arg0: Xmm, arg1: M32, arg2: Imm8);

	/// Insert a single precision floating-point value selected by imm8 from xmm2/m32 into xmm1 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.
	fn insertps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
	fn insw(&mut self);

	/// Interrupt vector number specified by immediate byte.
	void int_(const Imm8& arg0);

	/// Interrupt 3-trap to debugger.
	void int_(const Three& arg0);

	/// Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r64 and descriptor in m128.
	fn invpcid(&mut self, arg0: R64, arg1: M128);

	/// Interrupt return (16-bit operand size).
	fn iret(&mut self);

	/// Interrupt return (32-bit operand size).
	fn iretd(&mut self);

	/// Interrupt return (64-bit operand size).
	fn iretq(&mut self);

	/// Jump short if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Label);

	/// Jump near if above (CF=0 and ZF=0).
	void ja_1(const Label& arg0);

	/// Jump short if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if above (CF=0 and ZF=0).
	void ja_1(const Label& arg0, arg1: Hint);

	/// Jump near if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Rel32);

	/// Jump near if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Rel8);

	/// Jump short if above (CF=0 and ZF=0).
	fn ja(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if above or equal (CF=0).
	fn jae(&mut self, arg0: Label);

	/// Jump near if above or equal (CF=0).
	void jae_1(const Label& arg0);

	/// Jump short if above or equal (CF=0).
	fn jae(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if above or equal (CF=0).
	void jae_1(const Label& arg0, arg1: Hint);

	/// Jump near if above or equal (CF=0).
	fn jae(&mut self, arg0: Rel32);

	/// Jump near if above or equal (CF=0).
	fn jae(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if above or equal (CF=0).
	fn jae(&mut self, arg0: Rel8);

	/// Jump short if above or equal (CF=0).
	fn jae(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if below (CF=1).
	fn jb(&mut self, arg0: Label);

	/// Jump near if below (CF=1).
	void jb_1(const Label& arg0);

	/// Jump short if below (CF=1).
	fn jb(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if below (CF=1).
	void jb_1(const Label& arg0, arg1: Hint);

	/// Jump near if below (CF=1).
	fn jb(&mut self, arg0: Rel32);

	/// Jump near if below (CF=1).
	fn jb(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if below (CF=1).
	fn jb(&mut self, arg0: Rel8);

	/// Jump short if below (CF=1).
	fn jb(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Label);

	/// Jump near if below or equal (CF=1 or ZF=1).
	void jbe_1(const Label& arg0);

	/// Jump short if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if below or equal (CF=1 or ZF=1).
	void jbe_1(const Label& arg0, arg1: Hint);

	/// Jump near if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Rel32);

	/// Jump near if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Rel8);

	/// Jump short if below or equal (CF=1 or ZF=1).
	fn jbe(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if carry (CF=1).
	fn jc(&mut self, arg0: Label);

	/// Jump near if carry (CF=1).
	void jc_1(const Label& arg0);

	/// Jump short if carry (CF=1).
	fn jc(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if carry (CF=1).
	void jc_1(const Label& arg0, arg1: Hint);

	/// Jump near if carry (CF=1).
	fn jc(&mut self, arg0: Rel32);

	/// Jump near if carry (CF=1).
	fn jc(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if carry (CF=1).
	fn jc(&mut self, arg0: Rel8);

	/// Jump short if carry (CF=1).
	fn jc(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if equal (ZF=1).
	fn je(&mut self, arg0: Label);

	/// Jump near if 0 (ZF=1).
	void je_1(const Label& arg0);

	/// Jump short if equal (ZF=1).
	fn je(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if 0 (ZF=1).
	void je_1(const Label& arg0, arg1: Hint);

	/// Jump near if 0 (ZF=1).
	fn je(&mut self, arg0: Rel32);

	/// Jump near if 0 (ZF=1).
	fn je(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if equal (ZF=1).
	fn je(&mut self, arg0: Rel8);

	/// Jump short if equal (ZF=1).
	fn je(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if ECX register is 0.
	fn jecxz(&mut self, arg0: Label);

	/// Jump short if ECX register is 0.
	fn jecxz(&mut self, arg0: Label, arg1: Hint);

	/// Jump short if ECX register is 0.
	fn jecxz(&mut self, arg0: Rel8);

	/// Jump short if ECX register is 0.
	fn jecxz(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Label);

	/// Jump near if greater (ZF=0 and SF=OF).
	void jg_1(const Label& arg0);

	/// Jump short if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if greater (ZF=0 and SF=OF).
	void jg_1(const Label& arg0, arg1: Hint);

	/// Jump near if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Rel32);

	/// Jump near if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Rel8);

	/// Jump short if greater (ZF=0 and SF=OF).
	fn jg(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Label);

	/// Jump near if greater or equal (SF=OF).
	void jge_1(const Label& arg0);

	/// Jump short if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if greater or equal (SF=OF).
	void jge_1(const Label& arg0, arg1: Hint);

	/// Jump near if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Rel32);

	/// Jump near if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Rel8);

	/// Jump short if greater or equal (SF=OF).
	fn jge(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if less (SF!= OF).
	fn jl(&mut self, arg0: Label);

	/// Jump near if less (SF!= OF).
	void jl_1(const Label& arg0);

	/// Jump short if less (SF!= OF).
	fn jl(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if less (SF!= OF).
	void jl_1(const Label& arg0, arg1: Hint);

	/// Jump near if less (SF!= OF).
	fn jl(&mut self, arg0: Rel32);

	/// Jump near if less (SF!= OF).
	fn jl(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if less (SF!= OF).
	fn jl(&mut self, arg0: Rel8);

	/// Jump short if less (SF!= OF).
	fn jl(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Label);

	/// Jump near if less or equal (ZF=1 or SF!= OF).
	void jle_1(const Label& arg0);

	/// Jump short if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if less or equal (ZF=1 or SF!= OF).
	void jle_1(const Label& arg0, arg1: Hint);

	/// Jump near if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Rel32);

	/// Jump near if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Rel8);

	/// Jump short if less or equal (ZF=1 or SF!= OF).
	fn jle(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump far, absolute indirect, address given in m16:16.
	fn jmp(&mut self, arg0: FarPtr1616);

	/// Jump far, absolute indirect, address given in m16:32.
	fn jmp(&mut self, arg0: FarPtr1632);

	/// Jump far, absolute indirect, address given in m16:64.
	fn jmp(&mut self, arg0: FarPtr1664);

	/// Jump short, RIP = RIP + 8-bit displacement sign extended to 64-bits.
	fn jmp(&mut self, arg0: Label);

	/// Jump near, relative, RIP = RIP + 32-bit displacement sign extended to 64-bits.
	void jmp_1(const Label& arg0);

	/// Jump near, absolute indirect, RIP = 64-Bit offset from register or memory.
	fn jmp(&mut self, arg0: M64);

	/// Jump near, absolute indirect, RIP = 64-Bit offset from register or memory.
	fn jmp(&mut self, arg0: R64);

	/// Jump near, relative, RIP = RIP + 32-bit displacement sign extended to 64-bits.
	fn jmp(&mut self, arg0: Rel32);

	/// Jump short, RIP = RIP + 8-bit displacement sign extended to 64-bits.
	fn jmp(&mut self, arg0: Rel8);

	/// Jump short if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Label);

	/// Jump near if not above (CF=1 or ZF=1).
	void jna_1(const Label& arg0);

	/// Jump short if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not above (CF=1 or ZF=1).
	void jna_1(const Label& arg0, arg1: Hint);

	/// Jump near if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Rel32);

	/// Jump near if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Rel8);

	/// Jump short if not above (CF=1 or ZF=1).
	fn jna(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Label);

	/// Jump near if not above or equal (CF=1).
	void jnae_1(const Label& arg0);

	/// Jump short if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not above or equal (CF=1).
	void jnae_1(const Label& arg0, arg1: Hint);

	/// Jump near if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Rel32);

	/// Jump near if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Rel8);

	/// Jump short if not above or equal (CF=1).
	fn jnae(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not below (CF=0).
	fn jnb(&mut self, arg0: Label);

	/// Jump near if not below (CF=0).
	void jnb_1(const Label& arg0);

	/// Jump short if not below (CF=0).
	fn jnb(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not below (CF=0).
	void jnb_1(const Label& arg0, arg1: Hint);

	/// Jump near if not below (CF=0).
	fn jnb(&mut self, arg0: Rel32);

	/// Jump near if not below (CF=0).
	fn jnb(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not below (CF=0).
	fn jnb(&mut self, arg0: Rel8);

	/// Jump short if not below (CF=0).
	fn jnb(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Label);

	/// Jump near if not below or equal (CF=0 and ZF=0).
	void jnbe_1(const Label& arg0);

	/// Jump short if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not below or equal (CF=0 and ZF=0).
	void jnbe_1(const Label& arg0, arg1: Hint);

	/// Jump near if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Rel32);

	/// Jump near if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Rel8);

	/// Jump short if not below or equal (CF=0 and ZF=0).
	fn jnbe(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not carry (CF=0).
	fn jnc(&mut self, arg0: Label);

	/// Jump near if not carry (CF=0).
	void jnc_1(const Label& arg0);

	/// Jump short if not carry (CF=0).
	fn jnc(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not carry (CF=0).
	void jnc_1(const Label& arg0, arg1: Hint);

	/// Jump near if not carry (CF=0).
	fn jnc(&mut self, arg0: Rel32);

	/// Jump near if not carry (CF=0).
	fn jnc(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not carry (CF=0).
	fn jnc(&mut self, arg0: Rel8);

	/// Jump short if not carry (CF=0).
	fn jnc(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not equal (ZF=0).
	fn jne(&mut self, arg0: Label);

	/// Jump near if not equal (ZF=0).
	void jne_1(const Label& arg0);

	/// Jump short if not equal (ZF=0).
	fn jne(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not equal (ZF=0).
	void jne_1(const Label& arg0, arg1: Hint);

	/// Jump near if not equal (ZF=0).
	fn jne(&mut self, arg0: Rel32);

	/// Jump near if not equal (ZF=0).
	fn jne(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not equal (ZF=0).
	fn jne(&mut self, arg0: Rel8);

	/// Jump short if not equal (ZF=0).
	fn jne(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not greater (ZF=1 or SF!= OF).
	fn jng(&mut self, arg0: Label);

	/// Jump near if not greater (ZF=1 or SF != OF).
	void jng_1(const Label& arg0);

	/// Jump short if not greater (ZF=1 or SF!= OF).
	fn jng(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not greater (ZF=1 or SF != OF).
	void jng_1(const Label& arg0, arg1: Hint);

	/// Jump near if not greater (ZF=1 or SF != OF).
	fn jng(&mut self, arg0: Rel32);

	/// Jump near if not greater (ZF=1 or SF != OF).
	fn jng(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not greater (ZF=1 or SF!= OF).
	fn jng(&mut self, arg0: Rel8);

	/// Jump short if not greater (ZF=1 or SF!= OF).
	fn jng(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not greater or equal (SF!= OF).
	fn jnge(&mut self, arg0: Label);

	/// Jump near if not greater or equal (SF != OF).
	void jnge_1(const Label& arg0);

	/// Jump short if not greater or equal (SF!= OF).
	fn jnge(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not greater or equal (SF != OF).
	void jnge_1(const Label& arg0, arg1: Hint);

	/// Jump near if not greater or equal (SF != OF).
	fn jnge(&mut self, arg0: Rel32);

	/// Jump near if not greater or equal (SF != OF).
	fn jnge(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not greater or equal (SF!= OF).
	fn jnge(&mut self, arg0: Rel8);

	/// Jump short if not greater or equal (SF!= OF).
	fn jnge(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not less (SF=OF).
	fn jnl(&mut self, arg0: Label);

	/// Jump near if not less (SF=OF).
	void jnl_1(const Label& arg0);

	/// Jump short if not less (SF=OF).
	fn jnl(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not less (SF=OF).
	void jnl_1(const Label& arg0, arg1: Hint);

	/// Jump near if not less (SF=OF).
	fn jnl(&mut self, arg0: Rel32);

	/// Jump near if not less (SF=OF).
	fn jnl(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not less (SF=OF).
	fn jnl(&mut self, arg0: Rel8);

	/// Jump short if not less (SF=OF).
	fn jnl(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Label);

	/// Jump near if not less or equal (ZF=0 and SF=OF).
	void jnle_1(const Label& arg0);

	/// Jump short if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not less or equal (ZF=0 and SF=OF).
	void jnle_1(const Label& arg0, arg1: Hint);

	/// Jump near if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Rel32);

	/// Jump near if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Rel8);

	/// Jump short if not less or equal (ZF=0 and SF=OF).
	fn jnle(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not overflow (OF=0).
	fn jno(&mut self, arg0: Label);

	/// Jump near if not overflow (OF=0).
	void jno_1(const Label& arg0);

	/// Jump short if not overflow (OF=0).
	fn jno(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not overflow (OF=0).
	void jno_1(const Label& arg0, arg1: Hint);

	/// Jump near if not overflow (OF=0).
	fn jno(&mut self, arg0: Rel32);

	/// Jump near if not overflow (OF=0).
	fn jno(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not overflow (OF=0).
	fn jno(&mut self, arg0: Rel8);

	/// Jump short if not overflow (OF=0).
	fn jno(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not parity (PF=0).
	fn jnp(&mut self, arg0: Label);

	/// Jump near if not parity (PF=0).
	void jnp_1(const Label& arg0);

	/// Jump short if not parity (PF=0).
	fn jnp(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not parity (PF=0).
	void jnp_1(const Label& arg0, arg1: Hint);

	/// Jump near if not parity (PF=0).
	fn jnp(&mut self, arg0: Rel32);

	/// Jump near if not parity (PF=0).
	fn jnp(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not parity (PF=0).
	fn jnp(&mut self, arg0: Rel8);

	/// Jump short if not parity (PF=0).
	fn jnp(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not sign (SF=0).
	fn jns(&mut self, arg0: Label);

	/// Jump near if not sign (SF=0).
	void jns_1(const Label& arg0);

	/// Jump short if not sign (SF=0).
	fn jns(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not sign (SF=0).
	void jns_1(const Label& arg0, arg1: Hint);

	/// Jump near if not sign (SF=0).
	fn jns(&mut self, arg0: Rel32);

	/// Jump near if not sign (SF=0).
	fn jns(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not sign (SF=0).
	fn jns(&mut self, arg0: Rel8);

	/// Jump short if not sign (SF=0).
	fn jns(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if not zero (ZF=0).
	fn jnz(&mut self, arg0: Label);

	/// Jump near if not zero (ZF=0).
	void jnz_1(const Label& arg0);

	/// Jump short if not zero (ZF=0).
	fn jnz(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if not zero (ZF=0).
	void jnz_1(const Label& arg0, arg1: Hint);

	/// Jump near if not zero (ZF=0).
	fn jnz(&mut self, arg0: Rel32);

	/// Jump near if not zero (ZF=0).
	fn jnz(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if not zero (ZF=0).
	fn jnz(&mut self, arg0: Rel8);

	/// Jump short if not zero (ZF=0).
	fn jnz(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if overflow (OF=1).
	fn jo(&mut self, arg0: Label);

	/// Jump near if overflow (OF=1).
	void jo_1(const Label& arg0);

	/// Jump short if overflow (OF=1).
	fn jo(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if overflow (OF=1).
	void jo_1(const Label& arg0, arg1: Hint);

	/// Jump near if overflow (OF=1).
	fn jo(&mut self, arg0: Rel32);

	/// Jump near if overflow (OF=1).
	fn jo(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if overflow (OF=1).
	fn jo(&mut self, arg0: Rel8);

	/// Jump short if overflow (OF=1).
	fn jo(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if parity (PF=1).
	fn jp(&mut self, arg0: Label);

	/// Jump near if parity (PF=1).
	void jp_1(const Label& arg0);

	/// Jump short if parity (PF=1).
	fn jp(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if parity (PF=1).
	void jp_1(const Label& arg0, arg1: Hint);

	/// Jump near if parity (PF=1).
	fn jp(&mut self, arg0: Rel32);

	/// Jump near if parity (PF=1).
	fn jp(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if parity (PF=1).
	fn jp(&mut self, arg0: Rel8);

	/// Jump short if parity (PF=1).
	fn jp(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if parity even (PF=1).
	fn jpe(&mut self, arg0: Label);

	/// Jump near if parity even (PF=1).
	void jpe_1(const Label& arg0);

	/// Jump short if parity even (PF=1).
	fn jpe(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if parity even (PF=1).
	void jpe_1(const Label& arg0, arg1: Hint);

	/// Jump near if parity even (PF=1).
	fn jpe(&mut self, arg0: Rel32);

	/// Jump near if parity even (PF=1).
	fn jpe(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if parity even (PF=1).
	fn jpe(&mut self, arg0: Rel8);

	/// Jump short if parity even (PF=1).
	fn jpe(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if parity odd (PF=0).
	fn jpo(&mut self, arg0: Label);

	/// Jump near if parity odd (PF=0).
	void jpo_1(const Label& arg0);

	/// Jump short if parity odd (PF=0).
	fn jpo(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if parity odd (PF=0).
	void jpo_1(const Label& arg0, arg1: Hint);

	/// Jump near if parity odd (PF=0).
	fn jpo(&mut self, arg0: Rel32);

	/// Jump near if parity odd (PF=0).
	fn jpo(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if parity odd (PF=0).
	fn jpo(&mut self, arg0: Rel8);

	/// Jump short if parity odd (PF=0).
	fn jpo(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if RCX register is 0.
	fn jrcxz(&mut self, arg0: Label);

	/// Jump short if RCX register is 0.
	fn jrcxz(&mut self, arg0: Label, arg1: Hint);

	/// Jump short if RCX register is 0.
	fn jrcxz(&mut self, arg0: Rel8);

	/// Jump short if RCX register is 0.
	fn jrcxz(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if sign (SF=1).
	fn js(&mut self, arg0: Label);

	/// Jump near if sign (SF=1).
	void js_1(const Label& arg0);

	/// Jump short if sign (SF=1).
	fn js(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if sign (SF=1).
	void js_1(const Label& arg0, arg1: Hint);

	/// Jump near if sign (SF=1).
	fn js(&mut self, arg0: Rel32);

	/// Jump near if sign (SF=1).
	fn js(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if sign (SF=1).
	fn js(&mut self, arg0: Rel8);

	/// Jump short if sign (SF=1).
	fn js(&mut self, arg0: Rel8, arg1: Hint);

	/// Jump short if zero (ZF = 1).
	fn jz(&mut self, arg0: Label);

	/// Jump near if 0 (ZF=1).
	void jz_1(const Label& arg0);

	/// Jump short if zero (ZF = 1).
	fn jz(&mut self, arg0: Label, arg1: Hint);

	/// Jump near if 0 (ZF=1).
	void jz_1(const Label& arg0, arg1: Hint);

	/// Jump near if 0 (ZF=1).
	fn jz(&mut self, arg0: Rel32);

	/// Jump near if 0 (ZF=1).
	fn jz(&mut self, arg0: Rel32, arg1: Hint);

	/// Jump short if zero (ZF = 1).
	fn jz(&mut self, arg0: Rel8);

	/// Jump short if zero (ZF = 1).
	fn jz(&mut self, arg0: Rel8, arg1: Hint);

	/// Load: AH = EFLAGS(SF:ZF:0:AF:0:PF:1:CF).
	fn lahf(&mut self);

	/// r16 = access rights referenced by r16/m16.
	fn lar(&mut self, arg0: R16, arg1: M16);

	/// r16 = access rights referenced by r16/m16.
	fn lar(&mut self, arg0: R16, arg1: R16);

	/// reg = access rights referenced by r32/m16.
	fn lar(&mut self, arg0: R32, arg1: M16);

	/// reg = access rights referenced by r32/m16.
	fn lar(&mut self, arg0: R32, arg1: R32);

	/// reg = access rights referenced by r32/m16.
	fn lar(&mut self, arg0: R64, arg1: M16);

	/// reg = access rights referenced by r32/m16.
	fn lar(&mut self, arg0: R64, arg1: R32);

	/// Load unaligned data from mem and return double quadword in xmm1.
	fn lddqu(&mut self, arg0: Xmm, arg1: M128);

	/// Load MXCSR register from m32.
	fn ldmxcsr(&mut self, arg0: M32);

	/// Store effective address for m in register r16.
	fn lea(&mut self, arg0: R16, arg1: M16);

	/// Store effective address for m in register r16.
	fn lea(&mut self, arg0: R16, arg1: M32);

	/// Store effective address for m in register r16.
	fn lea(&mut self, arg0: R16, arg1: M64);

	/// Store effective address for m in register r32.
	fn lea(&mut self, arg0: R32, arg1: M16);

	/// Store effective address for m in register r32.
	fn lea(&mut self, arg0: R32, arg1: M32);

	/// Store effective address for m in register r32.
	fn lea(&mut self, arg0: R32, arg1: M64);

	/// Store effective address for m in register r64.
	fn lea(&mut self, arg0: R64, arg1: M16);

	/// Store effective address for m in register r64.
	fn lea(&mut self, arg0: R64, arg1: M32);

	/// Store effective address for m in register r64.
	fn lea(&mut self, arg0: R64, arg1: M64);

	/// Set RSP to RBP, then pop RBP.
	fn leave(&mut self);

	/// Set SP to BP, then pop BP.
	fn leave(&mut self, arg0: Pref66);

	/// Serializes load operations.
	fn lfence(&mut self);

	/// Load FS:r16 with far pointer from memory.
	fn lfs(&mut self, arg0: R16, arg1: FarPtr1616);

	/// Load FS:r32 with far pointer from memory.
	fn lfs(&mut self, arg0: R32, arg1: FarPtr1632);

	/// Load FS:r64 with far pointer from memory.
	fn lfs(&mut self, arg0: R64, arg1: FarPtr1664);

	/// Load GS:r16 with far pointer from memory.
	fn lgs(&mut self, arg0: R16, arg1: FarPtr1616);

	/// Load GS:r32 with far pointer from memory.
	fn lgs(&mut self, arg0: R32, arg1: FarPtr1632);

	/// Load GS:r64 with far pointer from memory.
	fn lgs(&mut self, arg0: R64, arg1: FarPtr1664);

	/// Asserts LOCK# signal for duration of the accompanying instruction.
	fn lock(&mut self);

	/// For legacy mode, Load word at address DS:(E)SI into AX.
	/// For 64-bit mode load word at address (R)SI into AX.
	fn lods(&mut self, arg0: M16);

	/// For legacy mode, Load dword at address DS:(E)SI into EAX.
	/// For 64-bit mode load dword at address (R)SI into EAX.
	fn lods(&mut self, arg0: M32);

	/// Load qword at address (R)SI into RAX.
	fn lods(&mut self, arg0: M64);

	/// For legacy mode, Load byte at address DS:(E)SI into AL.
	/// For 64-bit mode load byte at address (R)SI into AL.
	fn lods(&mut self, arg0: M8);

	/// For legacy mode, Load byte at address DS:(E)SI into AL.
	/// For 64-bit mode load byte at address (R)SI into AL.
	fn lodsb(&mut self);

	/// For legacy mode, Load dword at address DS:(E)SI into EAX.
	/// For 64-bit mode load dword at address (R)SI into EAX.
	fn lodsd(&mut self);

	/// Load qword at address (R)SI into RAX.
	fn lodsq(&mut self);

	/// For legacy mode, Load word at address DS:(E)SI into AX.
	/// For 64-bit mode load word at address (R)SI into AX.
	fn lodsw(&mut self);

	/// Decrement count; jump short if count != 0.
	fn loop(&mut self, arg0: Label);

	/// Decrement count; jump short if count != 0.
	fn loop(&mut self, arg0: Rel8);

	/// Decrement count; jump short if count != 0 and  ZF = 1.
	fn loope(&mut self, arg0: Label);

	/// Decrement count; jump short if count != 0 and  ZF = 1.
	fn loope(&mut self, arg0: Rel8);

	/// Decrement count; jump short if count != 0 and  ZF = 0.
	fn loopne(&mut self, arg0: Label);

	/// Decrement count; jump short if count != 0 and  ZF = 0.
	fn loopne(&mut self, arg0: Rel8);

	/// Load: r16 = segment limit, selector r16/m16.
	fn lsl(&mut self, arg0: R16, arg1: M16);

	/// Load: r16 = segment limit, selector r16/m16.
	fn lsl(&mut self, arg0: R16, arg1: R16);

	/// Load: r32 = segment limit, selector r32/m16.
	fn lsl(&mut self, arg0: R32, arg1: M16);

	/// Load: r32 = segment limit, selector r32/m16.
	fn lsl(&mut self, arg0: R32, arg1: R32);

	/// Load: r64 = segment limit, selector r32/m16.
	fn lsl(&mut self, arg0: R64, arg1: M16);

	/// Load: r64 = segment limit, selector r32/m16.
	fn lsl(&mut self, arg0: R64, arg1: R32);

	/// Load SS:r16 with far pointer from memory.
	fn lss(&mut self, arg0: R16, arg1: FarPtr1616);

	/// Load SS:r32 with far pointer from memory.
	fn lss(&mut self, arg0: R32, arg1: FarPtr1632);

	/// Load SS:r64 with far pointer from memory.
	fn lss(&mut self, arg0: R64, arg1: FarPtr1664);

	/// Count the number of leading zero bits in r/m16, return result in r16.
	fn lzcnt(&mut self, arg0: R16, arg1: M16);

	/// Count the number of leading zero bits in r/m16, return result in r16.
	fn lzcnt(&mut self, arg0: R16, arg1: R16);

	/// Count the number of leading zero bits in r/m32, return result in r32.
	fn lzcnt(&mut self, arg0: R32, arg1: M32);

	/// Count the number of leading zero bits in r/m32, return result in r32.
	fn lzcnt(&mut self, arg0: R32, arg1: R32);

	/// Count the number of leading zero bits in r/m64, return result in r64.
	fn lzcnt(&mut self, arg0: R64, arg1: M64);

	/// Count the number of leading zero bits in r/m64, return result in r64.
	fn lzcnt(&mut self, arg0: R64, arg1: R64);

	/// Selectively write bytes from xmm1 to memory location using the byte mask in xmm2.
	/// The default memory location is specified by DS:DI/EDI/RDI.
	fn maskmovdqu(&mut self, arg0: Xmm, arg1: Xmm);

	/// Selectively write bytes from mm1 to memory location using the byte mask in mm2.
	/// The default memory location is specified by DS:DI/EDI/RDI.
	fn maskmovq(&mut self, arg0: Mm, arg1: Mm);

	/// Return the maximum double-precision floating-point values between xmm2/m128 and xmm1.
	fn maxpd(&mut self, arg0: Xmm, arg1: M128);

	/// Return the maximum double-precision floating-point values between xmm2/m128 and xmm1.
	fn maxpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the maximum single-precision floating-point values between xmm2/m128 and xmm1.
	fn maxps(&mut self, arg0: Xmm, arg1: M128);

	/// Return the maximum single-precision floating-point values between xmm2/m128 and xmm1.
	fn maxps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the maximum scalar double-precision floating-point value between xmm2/mem64 and xmm1.
	fn maxsd(&mut self, arg0: Xmm, arg1: M64);

	/// Return the maximum scalar double-precision floating-point value between xmm2/mem64 and xmm1.
	fn maxsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the maximum scalar single-precision floating-point value between xmm2/mem32 and xmm1.
	fn maxss(&mut self, arg0: Xmm, arg1: M32);

	/// Return the maximum scalar single-precision floating-point value between xmm2/mem32 and xmm1.
	fn maxss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Serializes load and store operations.
	fn mfence(&mut self);

	/// Return the minimum double-precision floating-point values between xmm2/m128 and xmm1.
	fn minpd(&mut self, arg0: Xmm, arg1: M128);

	/// Return the minimum double-precision floating-point values between xmm2/m128 and xmm1.
	fn minpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the minimum single-precision floating-point values between xmm2/m128 and xmm1.
	fn minps(&mut self, arg0: Xmm, arg1: M128);

	/// Return the minimum single-precision floating-point values between xmm2/m128 and xmm1.
	fn minps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the minimum scalar double-precision floating-point value between xmm2/mem64 and xmm1.
	fn minsd(&mut self, arg0: Xmm, arg1: M64);

	/// Return the minimum scalar double-precision floating-point value between xmm2/mem64 and xmm1.
	fn minsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Return the minimum scalar single-precision floating-point value between xmm2/mem32 and xmm1.
	fn minss(&mut self, arg0: Xmm, arg1: M32);

	/// Return the minimum scalar single-precision floating-point value between xmm2/mem32 and xmm1.
	fn minss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sets up a linear address range to be monitored by hardware and activates the monitor.
	/// The address range should be a write-back memory caching type.
	/// The address is DS:EAX (DS:RAX in 64-bit mode).
	fn monitor(&mut self);

	/// Move byte at (seg:offset) to AL.
	fn mov(&mut self, arg0: Al, arg1: Moffs8);

	/// Move byte at (offset) to AL.
	fn mov(&mut self, arg0: Al, arg1: Moffs8, arg2: PrefRexW);

	/// Move word at (seg:offset) to AX.
	fn mov(&mut self, arg0: Ax, arg1: Moffs16);

	/// Move doubleword at (seg:offset) to EAX.
	fn mov(&mut self, arg0: Eax, arg1: Moffs32);

	/// Move imm16 to r/m16.
	fn mov(&mut self, arg0: M16, arg1: Imm16);

	/// Move r16 to r/m16.
	fn mov(&mut self, arg0: M16, arg1: R16);

	/// Move segment register to r/m16.
	fn mov(&mut self, arg0: M16, arg1: Sreg);

	/// Move imm32 to r/m32.
	fn mov(&mut self, arg0: M32, arg1: Imm32);

	/// Move r32 to r/m32.
	fn mov(&mut self, arg0: M32, arg1: R32);

	/// Move imm32 sign extended to 64-bits to r/m64.
	fn mov(&mut self, arg0: M64, arg1: Imm32);

	/// Move r64 to r/m64.
	fn mov(&mut self, arg0: M64, arg1: R64);

	/// Move zero extended 16-bit segment register to r/m64.
	fn mov(&mut self, arg0: M64, arg1: Sreg);

	/// Move imm8 to r/m8.
	fn mov(&mut self, arg0: M8, arg1: Imm8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: M8, arg1: R8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: M8, arg1: Rh);

	/// Move AX to (seg:offset).
	fn mov(&mut self, arg0: Moffs16, arg1: Ax);

	/// Move EAX to (seg:offset).
	fn mov(&mut self, arg0: Moffs32, arg1: Eax);

	/// Move RAX to (offset).
	fn mov(&mut self, arg0: Moffs64, arg1: Rax);

	/// Move AL to (seg:offset).
	fn mov(&mut self, arg0: Moffs8, arg1: Al);

	/// Move AL to (offset).
	fn mov(&mut self, arg0: Moffs8, arg1: Al, arg2: PrefRexW);

	/// Move imm16 to r16.
	fn mov(&mut self, arg0: R16, arg1: Imm16);

	/// Move imm16 to r/m16.
	void mov_1(const R16& arg0, arg1: Imm16);

	/// Move r/m16 to r16.
	fn mov(&mut self, arg0: R16, arg1: M16);

	/// Move r16 to r/m16.
	fn mov(&mut self, arg0: R16, arg1: R16);

	/// Move r/m16 to r16.
	void mov_1(const R16& arg0, arg1: R16);

	/// Move segment register to r/m16.
	fn mov(&mut self, arg0: R16, arg1: Sreg);

	/// Move imm32 to r32.
	fn mov(&mut self, arg0: R32, arg1: Imm32);

	/// Move imm32 to r/m32.
	void mov_1(const R32& arg0, arg1: Imm32);

	/// Move r/m32 to r32.
	fn mov(&mut self, arg0: R32, arg1: M32);

	/// Move r32 to r/m32.
	fn mov(&mut self, arg0: R32, arg1: R32);

	/// Move r/m32 to r32.
	void mov_1(const R32& arg0, arg1: R32);

	/// Move imm32 sign extended to 64-bits to r/m64.
	fn mov(&mut self, arg0: R64, arg1: Imm32);

	/// Move imm64 to r64.
	fn mov(&mut self, arg0: R64, arg1: Imm64);

	/// Move r/m64 to r64.
	fn mov(&mut self, arg0: R64, arg1: M64);

	/// Move r64 to r/m64.
	fn mov(&mut self, arg0: R64, arg1: R64);

	/// Move r/m64 to r64.
	void mov_1(const R64& arg0, arg1: R64);

	/// Move zero extended 16-bit segment register to r/m64.
	fn mov(&mut self, arg0: R64, arg1: Sreg);

	/// Move imm8 to r8.
	fn mov(&mut self, arg0: R8, arg1: Imm8);

	/// Move imm8 to r/m8.
	void mov_1(const R8& arg0, arg1: Imm8);

	/// Move r/m8 to r8.
	fn mov(&mut self, arg0: R8, arg1: M8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: R8, arg1: R8);

	/// Move r/m8 to r8.
	void mov_1(const R8& arg0, arg1: R8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: R8, arg1: Rh);

	/// Move r/m8 to r8.
	void mov_1(const R8& arg0, arg1: Rh);

	/// Move quadword at (offset) to RAX.
	fn mov(&mut self, arg0: Rax, arg1: Moffs64);

	/// Move imm8 to r8.
	fn mov(&mut self, arg0: Rh, arg1: Imm8);

	/// Move imm8 to r/m8.
	void mov_1(const Rh& arg0, arg1: Imm8);

	/// Move r/m8 to r8.
	fn mov(&mut self, arg0: Rh, arg1: M8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: Rh, arg1: R8);

	/// Move r/m8 to r8.
	void mov_1(const Rh& arg0, arg1: R8);

	/// Move r8 to r/m8.
	fn mov(&mut self, arg0: Rh, arg1: Rh);

	/// Move r/m8 to r8.
	void mov_1(const Rh& arg0, arg1: Rh);

	/// Move r/m16 to segment register.
	fn mov(&mut self, arg0: Sreg, arg1: M16);

	/// Move lower 16 bits of r/m64 to segment register.
	fn mov(&mut self, arg0: Sreg, arg1: M64);

	/// Move r/m16 to segment register.
	fn mov(&mut self, arg0: Sreg, arg1: R16);

	/// Move lower 16 bits of r/m64 to segment register.
	fn mov(&mut self, arg0: Sreg, arg1: R64);

	/// Move packed double-precision floating-point values from xmm1 to xmm2/m128.
	fn movapd(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn movapd(&mut self, arg0: Xmm, arg1: M128);

	/// Move packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn movapd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move packed double-precision floating-point values from xmm1 to xmm2/m128.
	void movapd_1(const Xmm& arg0, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm1 to xmm2/m128.
	fn movaps(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn movaps(&mut self, arg0: Xmm, arg1: M128);

	/// Move packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn movaps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm1 to xmm2/m128.
	void movaps_1(const Xmm& arg0, arg1: Xmm);

	/// Reverse byte order in r16 and move to m16.
	fn movbe(&mut self, arg0: M16, arg1: R16);

	/// Reverse byte order in r32 and move to m32.
	fn movbe(&mut self, arg0: M32, arg1: R32);

	/// Reverse byte order in r64 and move to m64.
	fn movbe(&mut self, arg0: M64, arg1: R64);

	/// Reverse byte order in m16 and move to r16.
	fn movbe(&mut self, arg0: R16, arg1: M16);

	/// Reverse byte order in m32 and move to r32.
	fn movbe(&mut self, arg0: R32, arg1: M32);

	/// Reverse byte order in m64 and move to r64.
	fn movbe(&mut self, arg0: R64, arg1: M64);

	/// Move doubleword from mm to r/m32.
	fn movd(&mut self, arg0: M32, arg1: Mm);

	/// Move doubleword from xmm register to r/m32.
	fn movd(&mut self, arg0: M32, arg1: Xmm);

	/// Move doubleword from r/m32 to mm.
	fn movd(&mut self, arg0: Mm, arg1: M32);

	/// Move doubleword from r/m32 to mm.
	fn movd(&mut self, arg0: Mm, arg1: R32);

	/// Move doubleword from mm to r/m32.
	fn movd(&mut self, arg0: R32, arg1: Mm);

	/// Move doubleword from xmm register to r/m32.
	fn movd(&mut self, arg0: R32, arg1: Xmm);

	/// Move doubleword from r/m32 to xmm.
	fn movd(&mut self, arg0: Xmm, arg1: M32);

	/// Move doubleword from r/m32 to xmm.
	fn movd(&mut self, arg0: Xmm, arg1: R32);

	/// Move one double-precision floating-point value from the lower 64-bit operand in xmm2/m64 to xmm1 and duplicate.
	fn movddup(&mut self, arg0: Xmm, arg1: M64);

	/// Move one double-precision floating-point value from the lower 64-bit operand in xmm2/m64 to xmm1 and duplicate.
	fn movddup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move low quadword from xmm to mmx register.
	fn movdq2q(&mut self, arg0: Mm, arg1: Xmm);

	/// Move aligned double quadword from xmm1 to xmm2/m128.
	fn movdqa(&mut self, arg0: M128, arg1: Xmm);

	/// Move aligned double quadword from xmm2/m128 to xmm1.
	fn movdqa(&mut self, arg0: Xmm, arg1: M128);

	/// Move aligned double quadword from xmm2/m128 to xmm1.
	fn movdqa(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move aligned double quadword from xmm1 to xmm2/m128.
	void movdqa_1(const Xmm& arg0, arg1: Xmm);

	/// Move unaligned double quadword from xmm1 to xmm2/m128.
	fn movdqu(&mut self, arg0: M128, arg1: Xmm);

	/// Move unaligned double quadword from xmm2/m128 to xmm1.
	fn movdqu(&mut self, arg0: Xmm, arg1: M128);

	/// Move unaligned double quadword from xmm2/m128 to xmm1.
	fn movdqu(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move unaligned double quadword from xmm1 to xmm2/m128.
	void movdqu_1(const Xmm& arg0, arg1: Xmm);

	/// Move two packed single-precision floating-point values from high quadword of xmm2 to low quadword of xmm1.
	fn movhlps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move double-precision floating-point value from high quadword of xmm to m64.
	fn movhpd(&mut self, arg0: M64, arg1: Xmm);

	/// Move double-precision floating-point value from m64 to high quadword of xmm.
	fn movhpd(&mut self, arg0: Xmm, arg1: M64);

	/// Move two packed single-precision floating-point values from high quadword of xmm to m64.
	fn movhps(&mut self, arg0: M64, arg1: Xmm);

	/// Move two packed single-precision floating-point values from m64 to high quadword of xmm.
	fn movhps(&mut self, arg0: Xmm, arg1: M64);

	/// Move two packed single-precision floating-point values from low quadword of xmm2 to high quadword of xmm1.
	fn movlhps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move double-precision floating-point nvalue from low quadword of xmm register to m64.
	fn movlpd(&mut self, arg0: M64, arg1: Xmm);

	/// Move double-precision floating-point value from m64 to low quadword of xmm register.
	fn movlpd(&mut self, arg0: Xmm, arg1: M64);

	/// Move two packed single-precision floating-point values from low quadword of xmm to m64.
	fn movlps(&mut self, arg0: M64, arg1: Xmm);

	/// Move two packed single-precision floating-point values from m64 to low quadword of xmm.
	fn movlps(&mut self, arg0: Xmm, arg1: M64);

	/// Extract 2-bit sign mask from xmm and store in reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn movmskpd(&mut self, arg0: R32, arg1: Xmm);

	/// Extract 2-bit sign mask from xmm and store in reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn movmskpd(&mut self, arg0: R64, arg1: Xmm);

	/// Extract 4-bit sign mask from xmm and store in reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn movmskps(&mut self, arg0: R32, arg1: Xmm);

	/// Extract 4-bit sign mask from xmm and store in reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn movmskps(&mut self, arg0: R64, arg1: Xmm);

	/// Move double quadword from xmm to m128 using non-temporal hint.
	fn movntdq(&mut self, arg0: M128, arg1: Xmm);

	/// Move double quadword from m128 to xmm using non-temporal hint if WC memory type.
	fn movntdqa(&mut self, arg0: Xmm, arg1: M128);

	/// Move doubleword from r32 to m32 using non-temporal hint.
	fn movnti(&mut self, arg0: M32, arg1: R32);

	/// Move quadword from r64 to m64 using non-temporal hint.
	fn movnti(&mut self, arg0: M64, arg1: R64);

	/// Move packed double-precision floating-point values from xmm to m128 using non-temporal hint.
	fn movntpd(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm to m128 using non-temporal hint.
	fn movntps(&mut self, arg0: M128, arg1: Xmm);

	/// Move quadword from mm to m64 using non-temporal hint.
	fn movntq(&mut self, arg0: M64, arg1: Mm);

	/// Move quadword from mm to r/m64.
	fn movq(&mut self, arg0: M64, arg1: Mm);

	/// Move quadword from mm to mm/m64.
	void movq_1(const M64& arg0, arg1: Mm);

	/// Move quadword from xmm register to r/m64.
	fn movq(&mut self, arg0: M64, arg1: Xmm);

	/// Move quadword from xmm1 to xmm2/mem64.
	void movq_1(const M64& arg0, arg1: Xmm);

	/// Move quadword from r/m64 to mm.
	fn movq(&mut self, arg0: Mm, arg1: M64);

	/// Move quadword from mm/m64 to mm.
	void movq_1(const Mm& arg0, arg1: M64);

	/// Move quadword from mm/m64 to mm.
	fn movq(&mut self, arg0: Mm, arg1: Mm);

	/// Move quadword from mm to mm/m64.
	void movq_1(const Mm& arg0, arg1: Mm);

	/// Move quadword from r/m64 to mm.
	fn movq(&mut self, arg0: Mm, arg1: R64);

	/// Move quadword from mm to r/m64.
	fn movq(&mut self, arg0: R64, arg1: Mm);

	/// Move quadword from xmm register to r/m64.
	fn movq(&mut self, arg0: R64, arg1: Xmm);

	/// Move quadword from r/m64 to xmm.
	fn movq(&mut self, arg0: Xmm, arg1: M64);

	/// Move quadword from xmm2/mem64 to xmm1.
	void movq_1(const Xmm& arg0, arg1: M64);

	/// Move quadword from r/m64 to xmm.
	fn movq(&mut self, arg0: Xmm, arg1: R64);

	/// Move quadword from xmm2/mem64 to xmm1.
	fn movq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move quadword from xmm1 to xmm2/mem64.
	void movq_1(const Xmm& arg0, arg1: Xmm);

	/// Move quadword from mmx to low quadword of xmm.
	fn movq2dq(&mut self, arg0: Xmm, arg1: Mm);

	/// For legacy mode, move word from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move word at address (R|E)SI to (R|E)DI.
	fn movs(&mut self, arg0: M16, arg1: M16);

	/// For legacy mode, move dword from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move dword from address (R|E)SI to (R|E)DI.
	fn movs(&mut self, arg0: M32, arg1: M32);

	/// Move qword from address (R|E)SI to (R|E)DI.
	fn movs(&mut self, arg0: M64, arg1: M64);

	/// For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move byte from address (R|E)SI to (R|E)DI.
	fn movs(&mut self, arg0: M8, arg1: M8);

	/// For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move byte from address (R|E)SI to (R|E)DI.
	fn movsb(&mut self);

	/// For legacy mode, move dword from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move dword from address (R|E)SI to (R|E)DI.
	fn movsd(&mut self);

	/// Move scalar double-precision floating-point value from xmm1 register to xmm2/m64.
	fn movsd(&mut self, arg0: M64, arg1: Xmm);

	/// Move scalar double-precision floating-point value from xmm2/m64 to xmm1 register.
	fn movsd(&mut self, arg0: Xmm, arg1: M64);

	/// Move scalar double-precision floating-point value from xmm2/m64 to xmm1 register.
	fn movsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move scalar double-precision floating-point value from xmm1 register to xmm2/m64.
	void movsd_1(const Xmm& arg0, arg1: Xmm);

	/// Move two single-precision floating-point values from the higher 32-bit operand of each qword in xmm2/m128 to xmm1 and duplicate each 32-bit operand to the lower 32-bits of each qword.
	fn movshdup(&mut self, arg0: Xmm, arg1: M128);

	/// Move two single-precision floating-point values from the higher 32-bit operand of each qword in xmm2/m128 to xmm1 and duplicate each 32-bit operand to the lower 32-bits of each qword.
	fn movshdup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move two single-precision floating-point values from the lower 32-bit operand of each qword in xmm2/m128 to xmm1 and duplicate each 32-bit operand to the higher 32-bits of each qword.
	fn movsldup(&mut self, arg0: Xmm, arg1: M128);

	/// Move two single-precision floating-point values from the lower 32-bit operand of each qword in xmm2/m128 to xmm1 and duplicate each 32-bit operand to the higher 32-bits of each qword.
	fn movsldup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move qword from address (R|E)SI to (R|E)DI.
	fn movsq(&mut self);

	/// Move scalar single-precision floating-point value from xmm1 register to xmm2/m32.
	fn movss(&mut self, arg0: M32, arg1: Xmm);

	/// Move scalar single-precision floating-point value from xmm2/m32 to xmm1 register.
	fn movss(&mut self, arg0: Xmm, arg1: M32);

	/// Move scalar single-precision floating-point value from xmm2/m32 to xmm1 register.
	fn movss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move scalar single-precision floating-point value from xmm1 register to xmm2/m32.
	void movss_1(const Xmm& arg0, arg1: Xmm);

	/// For legacy mode, move word from address DS:(E)SI to ES:(E)DI.
	/// For 64-bit mode move word at address (R|E)SI to (R|E)DI.
	fn movsw(&mut self);

	/// Move byte to word with sign-extension.
	fn movsx(&mut self, arg0: R16, arg1: M8);

	/// Move byte to word with sign-extension.
	fn movsx(&mut self, arg0: R16, arg1: R8);

	/// Move byte to word with sign-extension.
	fn movsx(&mut self, arg0: R16, arg1: Rh);

	/// Move word to doubleword, with sign-extension.
	fn movsx(&mut self, arg0: R32, arg1: M16);

	/// Move byte to doubleword with sign-extension.
	fn movsx(&mut self, arg0: R32, arg1: M8);

	/// Move word to doubleword, with sign-extension.
	fn movsx(&mut self, arg0: R32, arg1: R16);

	/// Move byte to doubleword with sign-extension.
	fn movsx(&mut self, arg0: R32, arg1: R8);

	/// Move byte to doubleword with sign-extension.
	fn movsx(&mut self, arg0: R32, arg1: Rh);

	/// Move word to quadword with sign-extension.
	fn movsx(&mut self, arg0: R64, arg1: M16);

	/// Move byte to quadword with sign-extension.
	fn movsx(&mut self, arg0: R64, arg1: M8);

	/// Move word to quadword with sign-extension.
	fn movsx(&mut self, arg0: R64, arg1: R16);

	/// Move byte to quadword with sign-extension.
	fn movsx(&mut self, arg0: R64, arg1: R8);

	/// Move doubleword to quadword with sign-extension.
	fn movsxd(&mut self, arg0: R64, arg1: M32);

	/// Move doubleword to quadword with sign-extension.
	fn movsxd(&mut self, arg0: R64, arg1: R32);

	/// Move packed double-precision floating-point values from xmm1 to xmm2/m128.
	fn movupd(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn movupd(&mut self, arg0: Xmm, arg1: M128);

	/// Move packed double-precision floating-point values from xmm2/m128 to xmm1.
	fn movupd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move packed double-precision floating-point values from xmm1 to xmm2/m128.
	void movupd_1(const Xmm& arg0, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm1 to xmm2/m128.
	fn movups(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn movups(&mut self, arg0: Xmm, arg1: M128);

	/// Move packed single-precision floating-point values from xmm2/m128 to xmm1.
	fn movups(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move packed single-precision floating-point values from xmm1 to xmm2/m128.
	void movups_1(const Xmm& arg0, arg1: Xmm);

	/// Move byte to word with zero-extension.
	fn movzx(&mut self, arg0: R16, arg1: M8);

	/// Move byte to word with zero-extension.
	fn movzx(&mut self, arg0: R16, arg1: R8);

	/// Move byte to word with zero-extension.
	fn movzx(&mut self, arg0: R16, arg1: Rh);

	/// Move word to doubleword, zero-extension.
	fn movzx(&mut self, arg0: R32, arg1: M16);

	/// Move byte to doubleword, zero-extension.
	fn movzx(&mut self, arg0: R32, arg1: M8);

	/// Move word to doubleword, zero-extension.
	fn movzx(&mut self, arg0: R32, arg1: R16);

	/// Move byte to doubleword, zero-extension.
	fn movzx(&mut self, arg0: R32, arg1: R8);

	/// Move byte to doubleword, zero-extension.
	fn movzx(&mut self, arg0: R32, arg1: Rh);

	/// Move word to quadword, zero-extension.
	fn movzx(&mut self, arg0: R64, arg1: M16);

	/// Move byte to quadword, zero-extension.
	fn movzx(&mut self, arg0: R64, arg1: M8);

	/// Move word to quadword, zero-extension.
	fn movzx(&mut self, arg0: R64, arg1: R16);

	/// Move byte to quadword, zero-extension.
	fn movzx(&mut self, arg0: R64, arg1: R8);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1.
	/// Starting offsets within xmm1 and xmm2/m128 are determined by imm8.
	fn mpsadbw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1.
	/// Starting offsets within xmm1 and xmm2/m128 are determined by imm8.
	fn mpsadbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Unsigned multiply (DX:AX = AX * r/m16).
	fn mul(&mut self, arg0: M16);

	/// Unsigned multiply (EDX:EAX = EAX * r/m32).
	fn mul(&mut self, arg0: M32);

	/// Unsigned multiply (RDX:RAX = RAX * r/m64.
	fn mul(&mut self, arg0: M64);

	/// Unsigned multiply (AX = AL * r/m8).
	fn mul(&mut self, arg0: M8);

	/// Unsigned multiply (DX:AX = AX * r/m16).
	fn mul(&mut self, arg0: R16);

	/// Unsigned multiply (EDX:EAX = EAX * r/m32).
	fn mul(&mut self, arg0: R32);

	/// Unsigned multiply (RDX:RAX = RAX * r/m64.
	fn mul(&mut self, arg0: R64);

	/// Unsigned multiply (AX = AL * r/m8).
	fn mul(&mut self, arg0: R8);

	/// Unsigned multiply (AX = AL * r/m8).
	fn mul(&mut self, arg0: Rh);

	/// Multiply packed double-precision floating-point values in xmm2/m128 by xmm1.
	fn mulpd(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply packed double-precision floating-point values in xmm2/m128 by xmm1.
	fn mulpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply packed single-precision floating-point values in xmm2/mem by xmm1.
	fn mulps(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply packed single-precision floating-point values in xmm2/mem by xmm1.
	fn mulps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the low double-precision floating-point value in xmm2/mem64 by low double-precision floating-point value in xmm1.
	fn mulsd(&mut self, arg0: Xmm, arg1: M64);

	/// Multiply the low double-precision floating-point value in xmm2/mem64 by low double-precision floating-point value in xmm1.
	fn mulsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the low single-precision floating-point value in xmm2/mem by the low single-precision floating-point value in xmm1.
	fn mulss(&mut self, arg0: Xmm, arg1: M32);

	/// Multiply the low single-precision floating-point value in xmm2/mem by the low single-precision floating-point value in xmm1.
	fn mulss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unsigned multiply of r/m32 with EDX without affecting arithmetic flags.
	fn mulx(&mut self, arg0: R32, arg1: R32, arg2: M32);

	/// Unsigned multiply of r/m32 with EDX without affecting arithmetic flags.
	fn mulx(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Unsigned multiply of r/m64 with RDX without affecting arithmetic flags.
	fn mulx(&mut self, arg0: R64, arg1: R64, arg2: M64);

	/// Unsigned multiply of r/m64 with RDX without affecting arithmetic flags.
	fn mulx(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// A hint that allow the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events.
	fn mwait(&mut self);

	/// Two's complement negate r/m16.
	fn neg(&mut self, arg0: M16);

	/// Two's complement negate r/m32.
	fn neg(&mut self, arg0: M32);

	/// Two's complement negate r/m64.
	fn neg(&mut self, arg0: M64);

	/// Two's complement negate r/m8.
	fn neg(&mut self, arg0: M8);

	/// Two's complement negate r/m16.
	fn neg(&mut self, arg0: R16);

	/// Two's complement negate r/m32.
	fn neg(&mut self, arg0: R32);

	/// Two's complement negate r/m64.
	fn neg(&mut self, arg0: R64);

	/// Two's complement negate r/m8.
	fn neg(&mut self, arg0: R8);

	/// Two's complement negate r/m8.
	fn neg(&mut self, arg0: Rh);

	/// One byte no-operation instruction.
	fn nop(&mut self);

	/// Multi-byte no-operation instruction.
	fn nop(&mut self, arg0: M16);

	/// Multi-byte no-operation instruction.
	fn nop(&mut self, arg0: M32);

	/// Multi-byte no-operation instruction.
	fn nop(&mut self, arg0: R16);

	/// Multi-byte no-operation instruction.
	fn nop(&mut self, arg0: R32);

	/// Reverse each bit of r/m16.
	void not_(const M16& arg0);

	/// Reverse each bit of r/m32.
	void not_(const M32& arg0);

	/// Reverse each bit of r/m64.
	void not_(const M64& arg0);

	/// Reverse each bit of r/m8.
	void not_(const M8& arg0);

	/// Reverse each bit of r/m16.
	void not_(const R16& arg0);

	/// Reverse each bit of r/m32.
	void not_(const R32& arg0);

	/// Reverse each bit of r/m64.
	void not_(const R64& arg0);

	/// Reverse each bit of r/m8.
	void not_(const R8& arg0);

	/// Reverse each bit of r/m8.
	void not_(const Rh& arg0);

	/// AL OR imm8.
	void or_(const Al& arg0, arg1: Imm8);

	/// AX OR imm16.
	void or_(const Ax& arg0, arg1: Imm16);

	/// EAX OR imm32.
	void or_(const Eax& arg0, arg1: Imm32);

	/// r/m16 OR imm16.
	void or_(const M16& arg0, arg1: Imm16);

	/// r/m16 OR imm8 (sign-extended).
	void or_(const M16& arg0, arg1: Imm8);

	/// r/m16 OR r16.
	void or_(const M16& arg0, arg1: R16);

	/// r/m32 OR imm32.
	void or_(const M32& arg0, arg1: Imm32);

	/// r/m32 OR imm8 (sign-extended).
	void or_(const M32& arg0, arg1: Imm8);

	/// r/m32 OR r32.
	void or_(const M32& arg0, arg1: R32);

	/// r/m64 OR imm32 (sign-extended).
	void or_(const M64& arg0, arg1: Imm32);

	/// r/m64 OR imm8 (sign-extended).
	void or_(const M64& arg0, arg1: Imm8);

	/// r/m64 OR r64.
	void or_(const M64& arg0, arg1: R64);

	/// r/m8 OR imm8.
	void or_(const M8& arg0, arg1: Imm8);

	/// r/m8 OR r8.
	void or_(const M8& arg0, arg1: R8);

	/// r/m8 OR r8.
	void or_(const M8& arg0, arg1: Rh);

	/// r/m16 OR imm16.
	void or_(const R16& arg0, arg1: Imm16);

	/// r/m16 OR imm8 (sign-extended).
	void or_(const R16& arg0, arg1: Imm8);

	/// r16 OR r/m16.
	void or_(const R16& arg0, arg1: M16);

	/// r/m16 OR r16.
	void or_(const R16& arg0, arg1: R16);

	/// r16 OR r/m16.
	void or__1(const R16& arg0, arg1: R16);

	/// r/m32 OR imm32.
	void or_(const R32& arg0, arg1: Imm32);

	/// r/m32 OR imm8 (sign-extended).
	void or_(const R32& arg0, arg1: Imm8);

	/// r32 OR r/m32.
	void or_(const R32& arg0, arg1: M32);

	/// r/m32 OR r32.
	void or_(const R32& arg0, arg1: R32);

	/// r32 OR r/m32.
	void or__1(const R32& arg0, arg1: R32);

	/// r/m64 OR imm32 (sign-extended).
	void or_(const R64& arg0, arg1: Imm32);

	/// r/m64 OR imm8 (sign-extended).
	void or_(const R64& arg0, arg1: Imm8);

	/// r64 OR r/m64.
	void or_(const R64& arg0, arg1: M64);

	/// r/m64 OR r64.
	void or_(const R64& arg0, arg1: R64);

	/// r64 OR r/m64.
	void or__1(const R64& arg0, arg1: R64);

	/// r/m8 OR imm8.
	void or_(const R8& arg0, arg1: Imm8);

	/// r8 OR r/m8.
	void or_(const R8& arg0, arg1: M8);

	/// r/m8 OR r8.
	void or_(const R8& arg0, arg1: R8);

	/// r8 OR r/m8.
	void or__1(const R8& arg0, arg1: R8);

	/// r/m8 OR r8.
	void or_(const R8& arg0, arg1: Rh);

	/// r8 OR r/m8.
	void or__1(const R8& arg0, arg1: Rh);

	/// RAX OR imm32 (sign-extended).
	void or_(const Rax& arg0, arg1: Imm32);

	/// r/m8 OR imm8.
	void or_(const Rh& arg0, arg1: Imm8);

	/// r8 OR r/m8.
	void or_(const Rh& arg0, arg1: M8);

	/// r/m8 OR r8.
	void or_(const Rh& arg0, arg1: R8);

	/// r8 OR r/m8.
	void or__1(const Rh& arg0, arg1: R8);

	/// r/m8 OR r8.
	void or_(const Rh& arg0, arg1: Rh);

	/// r8 OR r/m8.
	void or__1(const Rh& arg0, arg1: Rh);

	/// Bitwise OR of xmm2/m128 and xmm1.
	fn orpd(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise OR of xmm2/m128 and xmm1.
	fn orpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Bitwise OR of xmm1 and xmm2/m128.
	fn orps(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise OR of xmm1 and xmm2/m128.
	fn orps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Output byte in AL to I/O port address in DX.
	fn out(&mut self, arg0: Dx, arg1: Al);

	/// Output word in AX to I/O port address in DX.
	fn out(&mut self, arg0: Dx, arg1: Ax);

	/// Output doubleword in EAX to I/O port address in DX.
	fn out(&mut self, arg0: Dx, arg1: Eax);

	/// Output byte in AL to I/O port address imm8.
	fn out(&mut self, arg0: Imm8, arg1: Al);

	/// Output word in AX to I/O port address imm8.
	fn out(&mut self, arg0: Imm8, arg1: Ax);

	/// Output doubleword in EAX to I/O port address imm8.
	fn out(&mut self, arg0: Imm8, arg1: Eax);

	/// Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outs(&mut self, arg0: Dx, arg1: M16);

	/// Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outs(&mut self, arg0: Dx, arg1: M32);

	/// Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outs(&mut self, arg0: Dx, arg1: M8);

	/// Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outsb(&mut self);

	/// Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outsd(&mut self);

	/// Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
	fn outsw(&mut self);

	/// Compute the absolute value of bytes in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsb(&mut self, arg0: Mm, arg1: M64);

	/// Compute the absolute value of bytes in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsb(&mut self, arg0: Mm, arg1: Mm);

	/// Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsb(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compute the absolute value of 32-bit integers in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsd(&mut self, arg0: Mm, arg1: M64);

	/// Compute the absolute value of 32-bit integers in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsd(&mut self, arg0: Mm, arg1: Mm);

	/// Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsd(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compute the absolute value of 16-bit integers in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsw(&mut self, arg0: Mm, arg1: M64);

	/// Compute the absolute value of 16-bit integers in mm2/m64 and store UNSIGNED result in mm1.
	fn pabsw(&mut self, arg0: Mm, arg1: Mm);

	/// Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsw(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn pabsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Converts 2 packed signed doubleword integers from mm1 and from mm2/m64 into 4 packed signed word integers in mm1 using signed saturation.
	fn packssdw(&mut self, arg0: Mm, arg1: M64);

	/// Converts 2 packed signed doubleword integers from mm1 and from mm2/m64 into 4 packed signed word integers in mm1 using signed saturation.
	fn packssdw(&mut self, arg0: Mm, arg1: Mm);

	/// Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation.
	fn packssdw(&mut self, arg0: Xmm, arg1: M128);

	/// Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation.
	fn packssdw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Converts 4 packed signed word integers from mm1 and from mm2/m64 into 8 packed signed byte integers in mm1 using signed saturation.
	fn packsswb(&mut self, arg0: Mm, arg1: M64);

	/// Converts 4 packed signed word integers from mm1 and from mm2/m64 into 8 packed signed byte integers in mm1 using signed saturation.
	fn packsswb(&mut self, arg0: Mm, arg1: Mm);

	/// Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation.
	fn packsswb(&mut self, arg0: Xmm, arg1: M128);

	/// Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation.
	fn packsswb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
	fn packusdw(&mut self, arg0: Xmm, arg1: M128);

	/// Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
	fn packusdw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Converts 4 signed word integers from mm and 4 signed word integers from mm/m64 into 8 unsigned byte integers in mm using unsigned saturation.
	fn packuswb(&mut self, arg0: Mm, arg1: M64);

	/// Converts 4 signed word integers from mm and 4 signed word integers from mm/m64 into 8 unsigned byte integers in mm using unsigned saturation.
	fn packuswb(&mut self, arg0: Mm, arg1: Mm);

	/// Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
	fn packuswb(&mut self, arg0: Xmm, arg1: M128);

	/// Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
	fn packuswb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed byte integers from mm/m64 and mm.
	fn paddb(&mut self, arg0: Mm, arg1: M64);

	/// Add packed byte integers from mm/m64 and mm.
	fn paddb(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed byte integers from xmm2/m128 and xmm1.
	fn paddb(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed byte integers from xmm2/m128 and xmm1.
	fn paddb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed doubleword integers from mm/m64 and mm.
	fn paddd(&mut self, arg0: Mm, arg1: M64);

	/// Add packed doubleword integers from mm/m64 and mm.
	fn paddd(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed doubleword integers from xmm2/m128 and xmm1.
	fn paddd(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed doubleword integers from xmm2/m128 and xmm1.
	fn paddd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add quadword integer mm2/m64 to mm1.
	fn paddq(&mut self, arg0: Mm, arg1: M64);

	/// Add quadword integer mm2/m64 to mm1.
	fn paddq(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed quadword integers xmm2/m128 to xmm1.
	fn paddq(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed quadword integers xmm2/m128 to xmm1.
	fn paddq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed signed byte integers from mm/m64 and mm and saturate the results.
	fn paddsb(&mut self, arg0: Mm, arg1: M64);

	/// Add packed signed byte integers from mm/m64 and mm and saturate the results.
	fn paddsb(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results.
	fn paddsb(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results.
	fn paddsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed signed word integers from mm/m64 and mm and saturate the results.
	fn paddsw(&mut self, arg0: Mm, arg1: M64);

	/// Add packed signed word integers from mm/m64 and mm and saturate the results.
	fn paddsw(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results.
	fn paddsw(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results.
	fn paddsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed unsigned byte integers from mm/m64 and mm and saturate the results.
	fn paddusb(&mut self, arg0: Mm, arg1: M64);

	/// Add packed unsigned byte integers from mm/m64 and mm and saturate the results.
	fn paddusb(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results.
	fn paddusb(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results.
	fn paddusb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed unsigned word integers from mm/m64 and mm and saturate the results.
	fn paddusw(&mut self, arg0: Mm, arg1: M64);

	/// Add packed unsigned word integers from mm/m64 and mm and saturate the results.
	fn paddusw(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results.
	fn paddusw(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results.
	fn paddusw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed word integers from mm/m64 and mm.
	fn paddw(&mut self, arg0: Mm, arg1: M64);

	/// Add packed word integers from mm/m64 and mm.
	fn paddw(&mut self, arg0: Mm, arg1: Mm);

	/// Add packed word integers from xmm2/m128 and xmm1.
	fn paddw(&mut self, arg0: Xmm, arg1: M128);

	/// Add packed word integers from xmm2/m128 and xmm1.
	fn paddw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into mm1.
	fn palignr(&mut self, arg0: Mm, arg1: M64, arg2: Imm8);

	/// Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into mm1.
	fn palignr(&mut self, arg0: Mm, arg1: Mm, arg2: Imm8);

	/// Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into xmm1.
	fn palignr(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into xmm1.
	fn palignr(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Bitwise AND mm/m64 and mm.
	fn pand(&mut self, arg0: Mm, arg1: M64);

	/// Bitwise AND mm/m64 and mm.
	fn pand(&mut self, arg0: Mm, arg1: Mm);

	/// Bitwise AND of xmm2/m128 and xmm1.
	fn pand(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise AND of xmm2/m128 and xmm1.
	fn pand(&mut self, arg0: Xmm, arg1: Xmm);

	/// Bitwise AND NOT of mm/m64 and mm.
	fn pandn(&mut self, arg0: Mm, arg1: M64);

	/// Bitwise AND NOT of mm/m64 and mm.
	fn pandn(&mut self, arg0: Mm, arg1: Mm);

	/// Bitwise AND NOT of xmm2/m128 and xmm1.
	fn pandn(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise AND NOT of xmm2/m128 and xmm1.
	fn pandn(&mut self, arg0: Xmm, arg1: Xmm);

	/// Gives hint to processor that improves performance of spin-wait loops.
	fn pause(&mut self);

	/// Average packed unsigned byte integers from mm2/m64 and mm1 with rounding.
	fn pavgb(&mut self, arg0: Mm, arg1: M64);

	/// Average packed unsigned byte integers from mm2/m64 and mm1 with rounding.
	fn pavgb(&mut self, arg0: Mm, arg1: Mm);

	/// Average packed unsigned byte integers from xmm2/m128 and xmm1 with rounding.
	fn pavgb(&mut self, arg0: Xmm, arg1: M128);

	/// Average packed unsigned byte integers from xmm2/m128 and xmm1 with rounding.
	fn pavgb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Average packed unsigned word integers from mm2/m64 and mm1 with rounding.
	fn pavgw(&mut self, arg0: Mm, arg1: M64);

	/// Average packed unsigned word integers from mm2/m64 and mm1 with rounding.
	fn pavgw(&mut self, arg0: Mm, arg1: Mm);

	/// Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding.
	fn pavgw(&mut self, arg0: Xmm, arg1: M128);

	/// Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding.
	fn pavgw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Select byte values from xmm1 and xmm2/m128 from mask specified in the high bit of each byte in XMM0 and store the values into xmm1.
	fn pblendvb(&mut self, arg0: Xmm, arg1: M128, arg2: Xmm0);

	/// Select byte values from xmm1 and xmm2/m128 from mask specified in the high bit of each byte in XMM0 and store the values into xmm1.
	fn pblendvb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm0);

	/// Select words from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn pblendw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Select words from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1.
	fn pblendw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Carry-less multiplication of one quadword of xmm1 by one quadword of xmm2/m128, stores the 128-bit result in xmm1.
	/// The immediate is used to determine which quadwords of xmm1 and xmm2/m128 should be used.
	fn pclmulqdq(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Carry-less multiplication of one quadword of xmm1 by one quadword of xmm2/m128, stores the 128-bit result in xmm1.
	/// The immediate is used to determine which quadwords of xmm1 and xmm2/m128 should be used.
	fn pclmulqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Compare packed bytes in mm/m64 and mm for equality.
	fn pcmpeqb(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed bytes in mm/m64 and mm for equality.
	fn pcmpeqb(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed bytes in xmm2/m128 and xmm1 for equality.
	fn pcmpeqb(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed bytes in xmm2/m128 and xmm1 for equality.
	fn pcmpeqb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed doublewords in mm/m64 and mm for equality.
	fn pcmpeqd(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed doublewords in mm/m64 and mm for equality.
	fn pcmpeqd(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed doublewords in xmm2/m128 and xmm1 for equality.
	fn pcmpeqd(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed doublewords in xmm2/m128 and xmm1 for equality.
	fn pcmpeqd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed qwords in xmm2/m128 and xmm1 for equality.
	fn pcmpeqq(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed qwords in xmm2/m128 and xmm1 for equality.
	fn pcmpeqq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed words in mm/m64 and mm for equality.
	fn pcmpeqw(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed words in mm/m64 and mm for equality.
	fn pcmpeqw(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed words in xmm2/m128 and xmm1 for equality.
	fn pcmpeqw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed words in xmm2/m128 and xmm1 for equality.
	fn pcmpeqw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.
	fn pcmpestri(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.
	fn pcmpestri(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.
	fn pcmpestrm(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.
	fn pcmpestrm(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Compare packed signed byte integers in mm and mm/m64 for greater than.
	fn pcmpgtb(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed signed byte integers in mm and mm/m64 for greater than.
	fn pcmpgtb(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtb(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed doubleword integers in mm and mm/m64 for greater than.
	fn pcmpgtd(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed signed doubleword integers in mm and mm/m64 for greater than.
	fn pcmpgtd(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtd(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed qwords in xmm2/m128 and xmm1 for greater than.
	fn pcmpgtq(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed qwords in xmm2/m128 and xmm1 for greater than.
	fn pcmpgtq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed word integers in mm and mm/m64 for greater than.
	fn pcmpgtw(&mut self, arg0: Mm, arg1: M64);

	/// Compare packed signed word integers in mm and mm/m64 for greater than.
	fn pcmpgtw(&mut self, arg0: Mm, arg1: Mm);

	/// Compare packed signed word integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed word integers in xmm1 and xmm2/m128 for greater than.
	fn pcmpgtw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.
	fn pcmpistri(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.
	fn pcmpistri(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating a mask, and storing the result in XMM0.
	fn pcmpistrm(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating a mask, and storing the result in XMM0.
	fn pcmpistrm(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Parallel deposit of bits from r32b using mask in r/m32, result is written to r32a.
	fn pdep(&mut self, arg0: R32, arg1: R32, arg2: M32);

	/// Parallel deposit of bits from r32b using mask in r/m32, result is written to r32a.
	fn pdep(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Parallel deposit of bits from r64b using mask in r/m64, result is written to r64a.
	fn pdep(&mut self, arg0: R64, arg1: R64, arg2: M64);

	/// Parallel deposit of bits from r64b using mask in r/m64, result is written to r64a.
	fn pdep(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Parallel extract of bits from r32b using mask in r/m32, result is written to r32a.
	fn pext(&mut self, arg0: R32, arg1: R32, arg2: M32);

	/// Parallel extract of bits from r32b using mask in r/m32, result is written to r32a.
	fn pext(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Parallel extract of bits from r64b using mask in r/m64, result is written to r64a.
	fn pext(&mut self, arg0: R64, arg1: R64, arg2: M64);

	/// Parallel extract of bits from r64b using mask in r/m64, result is written to r64a.
	fn pext(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into rreg or m8.
	/// The upper bits of r32 or r64 are zeroed.
	fn pextrb(&mut self, arg0: M8, arg1: Xmm, arg2: Imm8);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into rreg or m8.
	/// The upper bits of r32 or r64 are zeroed.
	fn pextrb(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into rreg or m8.
	/// The upper bits of r32 or r64 are zeroed.
	fn pextrb(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32.
	fn pextrd(&mut self, arg0: M32, arg1: Xmm, arg2: Imm8);

	/// Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32.
	fn pextrd(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64.
	fn pextrq(&mut self, arg0: M64, arg1: Xmm, arg2: Imm8);

	/// Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64.
	fn pextrq(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16.
	/// Zero-extend the result in the destination, r32 or r64.
	fn pextrw(&mut self, arg0: M16, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from mm and move it to reg, bits 15-0.
	/// The upper bits of r32 or r64 is zeroed.
	fn pextrw(&mut self, arg0: R32, arg1: Mm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm and move it to reg, bits 15-0.
	/// The upper bits of r32 or r64 is zeroed.
	fn pextrw(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16.
	/// Zero-extend the result in the destination, r32 or r64.
	void pextrw_1(const R32& arg0, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from mm and move it to reg, bits 15-0.
	/// The upper bits of r32 or r64 is zeroed.
	fn pextrw(&mut self, arg0: R64, arg1: Mm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm and move it to reg, bits 15-0.
	/// The upper bits of r32 or r64 is zeroed.
	fn pextrw(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16.
	/// Zero-extend the result in the destination, r32 or r64.
	void pextrw_1(const R64& arg0, arg1: Xmm, arg2: Imm8);

	/// Add 32-bit integers horizontally, pack to MM1.
	fn phaddd(&mut self, arg0: Mm, arg1: M64);

	/// Add 32-bit integers horizontally, pack to MM1.
	fn phaddd(&mut self, arg0: Mm, arg1: Mm);

	/// Add 32-bit integers horizontally, pack to XMM1.
	fn phaddd(&mut self, arg0: Xmm, arg1: M128);

	/// Add 32-bit integers horizontally, pack to XMM1.
	fn phaddd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add 16-bit signed integers horizontally, pack saturated integers to MM1.
	fn phaddsw(&mut self, arg0: Mm, arg1: M64);

	/// Add 16-bit signed integers horizontally, pack saturated integers to MM1.
	fn phaddsw(&mut self, arg0: Mm, arg1: Mm);

	/// Add 16-bit signed integers horizontally, pack saturated integers to XMM1.
	fn phaddsw(&mut self, arg0: Xmm, arg1: M128);

	/// Add 16-bit signed integers horizontally, pack saturated integers to XMM1.
	fn phaddsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add 16-bit integers horizontally, pack to MM1.
	fn phaddw(&mut self, arg0: Mm, arg1: M64);

	/// Add 16-bit integers horizontally, pack to MM1.
	fn phaddw(&mut self, arg0: Mm, arg1: Mm);

	/// Add 16-bit integers horizontally, pack to XMM1.
	fn phaddw(&mut self, arg0: Xmm, arg1: M128);

	/// Add 16-bit integers horizontally, pack to XMM1.
	fn phaddw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.
	fn phminposuw(&mut self, arg0: Xmm, arg1: M128);

	/// Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.
	fn phminposuw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract 32-bit signed integers horizontally, pack to MM1.
	fn phsubd(&mut self, arg0: Mm, arg1: M64);

	/// Subtract 32-bit signed integers horizontally, pack to MM1.
	fn phsubd(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract 32-bit signed integers horizontally, pack to XMM1.
	fn phsubd(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract 32-bit signed integers horizontally, pack to XMM1.
	fn phsubd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to MM1.
	fn phsubsw(&mut self, arg0: Mm, arg1: M64);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to MM1.
	fn phsubsw(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to XMM1.
	fn phsubsw(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to XMM1.
	fn phsubsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract 16-bit signed integers horizontally, pack to MM1.
	fn phsubw(&mut self, arg0: Mm, arg1: M64);

	/// Subtract 16-bit signed integers horizontally, pack to MM1.
	fn phsubw(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract 16-bit signed integers horizontally, pack to XMM1.
	fn phsubw(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract 16-bit signed integers horizontally, pack to XMM1.
	fn phsubw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8.
	fn pinsrb(&mut self, arg0: Xmm, arg1: M8, arg2: Imm8);

	/// Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8.
	fn pinsrb(&mut self, arg0: Xmm, arg1: R32, arg2: Imm8);

	/// Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8.
	fn pinsrd(&mut self, arg0: Xmm, arg1: M32, arg2: Imm8);

	/// Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8.
	fn pinsrd(&mut self, arg0: Xmm, arg1: R32, arg2: Imm8);

	/// Insert the low word from r32 or from m16 into mm at the word position specified by imm8.
	fn pinsrw(&mut self, arg0: Mm, arg1: M16, arg2: Imm8);

	/// Insert the low word from r32 or from m16 into mm at the word position specified by imm8.
	fn pinsrw(&mut self, arg0: Mm, arg1: R32, arg2: Imm8);

	/// Move the low word of r32 or from m16 into xmm at the word position specified by imm8.
	fn pinsrw(&mut self, arg0: Xmm, arg1: M16, arg2: Imm8);

	/// Move the low word of r32 or from m16 into xmm at the word position specified by imm8.
	fn pinsrw(&mut self, arg0: Xmm, arg1: R32, arg2: Imm8);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to MM1.
	fn pmaddubsw(&mut self, arg0: Mm, arg1: M64);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to MM1.
	fn pmaddubsw(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to XMM1.
	fn pmaddubsw(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to XMM1.
	fn pmaddubsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed words in mm by the packed words in mm/m64, add adjacent doubleword results, and store in mm.
	fn pmaddwd(&mut self, arg0: Mm, arg1: M64);

	/// Multiply the packed words in mm by the packed words in mm/m64, add adjacent doubleword results, and store in mm.
	fn pmaddwd(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply the packed word integers in xmm1 by the packed word integers in xmm2/m128, add adjacent doubleword results, and store in xmm1.
	fn pmaddwd(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed word integers in xmm1 by the packed word integers in xmm2/m128, add adjacent doubleword results, and store in xmm1.
	fn pmaddwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxsb(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxsd(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare signed word integers in mm2/m64 and mm1 and return maximum values.
	fn pmaxsw(&mut self, arg0: Mm, arg1: M64);

	/// Compare signed word integers in mm2/m64 and mm1 and return maximum values.
	fn pmaxsw(&mut self, arg0: Mm, arg1: Mm);

	/// Compare signed word integers in xmm2/m128 and xmm1 and return maximum values.
	fn pmaxsw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare signed word integers in xmm2/m128 and xmm1 and return maximum values.
	fn pmaxsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare unsigned byte integers in mm2/m64 and mm1 and returns maximum values.
	fn pmaxub(&mut self, arg0: Mm, arg1: M64);

	/// Compare unsigned byte integers in mm2/m64 and mm1 and returns maximum values.
	fn pmaxub(&mut self, arg0: Mm, arg1: Mm);

	/// Compare unsigned byte integers in xmm2/m128 and xmm1 and returns maximum values.
	fn pmaxub(&mut self, arg0: Xmm, arg1: M128);

	/// Compare unsigned byte integers in xmm2/m128 and xmm1 and returns maximum values.
	fn pmaxub(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxud(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxud(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed unsigned word integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxuw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed unsigned word integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
	fn pmaxuw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminsb(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminsd(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare signed word integers in mm2/m64 and mm1 and return minimum values.
	fn pminsw(&mut self, arg0: Mm, arg1: M64);

	/// Compare signed word integers in mm2/m64 and mm1 and return minimum values.
	fn pminsw(&mut self, arg0: Mm, arg1: Mm);

	/// Compare signed word integers in xmm2/m128 and xmm1 and return minimum values.
	fn pminsw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare signed word integers in xmm2/m128 and xmm1 and return minimum values.
	fn pminsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare unsigned byte integers in mm2/m64 and mm1 and returns minimum values.
	fn pminub(&mut self, arg0: Mm, arg1: M64);

	/// Compare unsigned byte integers in mm2/m64 and mm1 and returns minimum values.
	fn pminub(&mut self, arg0: Mm, arg1: Mm);

	/// Compare unsigned byte integers in xmm2/m128 and xmm1 and returns minimum values.
	fn pminub(&mut self, arg0: Xmm, arg1: M128);

	/// Compare unsigned byte integers in xmm2/m128 and xmm1 and returns minimum values.
	fn pminub(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminud(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminud(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare packed unsigned word integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminuw(&mut self, arg0: Xmm, arg1: M128);

	/// Compare packed unsigned word integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
	fn pminuw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move a byte mask of mm to reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn pmovmskb(&mut self, arg0: R32, arg1: Mm);

	/// Move a byte mask of xmm to reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn pmovmskb(&mut self, arg0: R32, arg1: Xmm);

	/// Move a byte mask of mm to reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn pmovmskb(&mut self, arg0: R64, arg1: Mm);

	/// Move a byte mask of xmm to reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn pmovmskb(&mut self, arg0: R64, arg1: Xmm);

	/// Sign extend 4 packed signed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed signed 32-bit integers in xmm1.
	fn pmovsxbd(&mut self, arg0: Xmm, arg1: M32);

	/// Sign extend 4 packed signed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed signed 32-bit integers in xmm1.
	fn pmovsxbd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 2 packed signed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxbq(&mut self, arg0: Xmm, arg1: M16);

	/// Sign extend 2 packed signed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxbq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 8 packed signed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed signed 16-bit integers in xmm1.
	fn pmovsxbw(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 8 packed signed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed signed 16-bit integers in xmm1.
	fn pmovsxbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 2 packed signed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxdq(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 2 packed signed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1.
	fn pmovsxwd(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1.
	fn pmovsxwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 2 packed signed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxwq(&mut self, arg0: Xmm, arg1: M32);

	/// Sign extend 2 packed signed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed signed 64-bit integers in xmm1.
	fn pmovsxwq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn pmovzxbd(&mut self, arg0: Xmm, arg1: M32);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn pmovzxbd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn pmovzxbq(&mut self, arg0: Xmm, arg1: M16);

	/// Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn pmovzxbq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn pmovzxbw(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn pmovzxbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn pmovzxdq(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn pmovzxdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn pmovzxwd(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn pmovzxwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn pmovzxwq(&mut self, arg0: Xmm, arg1: M32);

	/// Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn pmovzxwq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed signed dword integers in xmm1 and xmm2/m128 and store the quadword product in xmm1.
	fn pmuldq(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed signed dword integers in xmm1 and xmm2/m128 and store the quadword product in xmm1.
	fn pmuldq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to MM1.
	fn pmulhrsw(&mut self, arg0: Mm, arg1: M64);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to MM1.
	fn pmulhrsw(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to XMM1.
	fn pmulhrsw(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to XMM1.
	fn pmulhrsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed unsigned word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.
	fn pmulhuw(&mut self, arg0: Mm, arg1: M64);

	/// Multiply the packed unsigned word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.
	fn pmulhuw(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply the packed unsigned word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.
	fn pmulhuw(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed unsigned word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.
	fn pmulhuw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed signed word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.
	fn pmulhw(&mut self, arg0: Mm, arg1: M64);

	/// Multiply the packed signed word integers in mm1 register and mm2/m64, and store the high 16 bits of the results in mm1.
	fn pmulhw(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.
	fn pmulhw(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1.
	fn pmulhw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1.
	fn pmulld(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1.
	fn pmulld(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply the packed signed word integers in mm1 register and mm2/m64, and store the low 16 bits of the results in mm1.
	fn pmullw(&mut self, arg0: Mm, arg1: M64);

	/// Multiply the packed signed word integers in mm1 register and mm2/m64, and store the low 16 bits of the results in mm1.
	fn pmullw(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the low 16 bits of the results in xmm1.
	fn pmullw(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the low 16 bits of the results in xmm1.
	fn pmullw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Multiply unsigned doubleword integer in mm1 by unsigned doubleword integer in mm2/m64, and store the quadword result in mm1.
	fn pmuludq(&mut self, arg0: Mm, arg1: M64);

	/// Multiply unsigned doubleword integer in mm1 by unsigned doubleword integer in mm2/m64, and store the quadword result in mm1.
	fn pmuludq(&mut self, arg0: Mm, arg1: Mm);

	/// Multiply packed unsigned doubleword integers in xmm1 by packed unsigned doubleword integers in xmm2/m128, and store the quadword results in xmm1.
	fn pmuludq(&mut self, arg0: Xmm, arg1: M128);

	/// Multiply packed unsigned doubleword integers in xmm1 by packed unsigned doubleword integers in xmm2/m128, and store the quadword results in xmm1.
	fn pmuludq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Pop top of stack into FS; increment stack pointer by 64 bits.
	fn pop(&mut self, arg0: Fs);

	/// Pop top of stack into FS; increment stack pointer by 16 bits.
	fn pop(&mut self, arg0: Fs, arg1: Pref66);

	/// Pop top of stack into GS; increment stack pointer by 64 bits.
	fn pop(&mut self, arg0: Gs);

	/// Pop top of stack into GS; increment stack pointer by 16 bits.
	fn pop(&mut self, arg0: Gs, arg1: Pref66);

	/// Pop top of stack into m16; increment stack pointer.
	fn pop(&mut self, arg0: M16);

	/// Pop top of stack into m64; increment stack pointer.
	/// Cannot encode 32-bit operand size.
	fn pop(&mut self, arg0: M64);

	/// Pop top of stack into m16; increment stack pointer.
	fn pop(&mut self, arg0: R16);

	/// Pop top of stack into r16; increment stack pointer.
	void pop_1(const R16& arg0);

	/// Pop top of stack into m64; increment stack pointer.
	/// Cannot encode 32-bit operand size.
	fn pop(&mut self, arg0: R64);

	/// Pop top of stack into r64; increment stack pointer.
	/// Cannot encode 32-bit operand size.
	void pop_1(const R64& arg0);

	/// POPCNT on r/m16.
	fn popcnt(&mut self, arg0: R16, arg1: M16);

	/// POPCNT on r/m16.
	fn popcnt(&mut self, arg0: R16, arg1: R16);

	/// POPCNT on r/m32.
	fn popcnt(&mut self, arg0: R32, arg1: M32);

	/// POPCNT on r/m32.
	fn popcnt(&mut self, arg0: R32, arg1: R32);

	/// POPCNT on r/m64.
	fn popcnt(&mut self, arg0: R64, arg1: M64);

	/// POPCNT on r/m64.
	fn popcnt(&mut self, arg0: R64, arg1: R64);

	/// Pop top of stack into lower 16 bits of EFLAGS.
	fn popf(&mut self);

	/// Pop top of stack and zero-extend into RFLAGS.
	fn popfq(&mut self);

	/// Bitwise OR of mm/m64 and mm.
	fn por(&mut self, arg0: Mm, arg1: M64);

	/// Bitwise OR of mm/m64 and mm.
	fn por(&mut self, arg0: Mm, arg1: Mm);

	/// Bitwise OR of xmm2/m128 and xmm1.
	fn por(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise OR of xmm2/m128 and xmm1.
	fn por(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move data from m8 closer to the processor using NTA hint.
	fn prefetchnta(&mut self, arg0: M8);

	/// Move data from m8 closer to the processor using T0 hint.
	fn prefetcht0(&mut self, arg0: M8);

	/// Move data from m8 closer to the processor using T1 hint.
	fn prefetcht1(&mut self, arg0: M8);

	/// Move data from m8 closer to the processor using T2 hint.
	fn prefetcht2(&mut self, arg0: M8);

	/// Computes the absolute differences of the packed unsigned byte integers from mm2 /m64 and mm1; differences are then summed to produce an unsigned word integer result.
	fn psadbw(&mut self, arg0: Mm, arg1: M64);

	/// Computes the absolute differences of the packed unsigned byte integers from mm2 /m64 and mm1; differences are then summed to produce an unsigned word integer result.
	fn psadbw(&mut self, arg0: Mm, arg1: Mm);

	/// Computes the absolute differences of the packed unsigned byte integers from xmm2 /m128 and xmm1; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.
	fn psadbw(&mut self, arg0: Xmm, arg1: M128);

	/// Computes the absolute differences of the packed unsigned byte integers from xmm2 /m128 and xmm1; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.
	fn psadbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shuffle bytes in mm1 according to contents of mm2/m64.
	fn pshufb(&mut self, arg0: Mm, arg1: M64);

	/// Shuffle bytes in mm1 according to contents of mm2/m64.
	fn pshufb(&mut self, arg0: Mm, arg1: Mm);

	/// Shuffle bytes in xmm1 according to contents of xmm2/m128.
	fn pshufb(&mut self, arg0: Xmm, arg1: M128);

	/// Shuffle bytes in xmm1 according to contents of xmm2/m128.
	fn pshufb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshufd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshufd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshufhw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshufhw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshuflw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn pshuflw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1.
	fn pshufw(&mut self, arg0: Mm, arg1: M64, arg2: Imm8);

	/// Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1.
	fn pshufw(&mut self, arg0: Mm, arg1: Mm, arg2: Imm8);

	/// Negate/zero/preserve packed byte integers in mm1 depending on the corresponding sign in mm2/m64.
	fn psignb(&mut self, arg0: Mm, arg1: M64);

	/// Negate/zero/preserve packed byte integers in mm1 depending on the corresponding sign in mm2/m64.
	fn psignb(&mut self, arg0: Mm, arg1: Mm);

	/// Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignb(&mut self, arg0: Xmm, arg1: M128);

	/// Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Negate/zero/preserve packed doubleword integers in mm1 depending on the corresponding sign in mm2/m128.
	fn psignd(&mut self, arg0: Mm, arg1: M64);

	/// Negate/zero/preserve packed doubleword integers in mm1 depending on the corresponding sign in mm2/m128.
	fn psignd(&mut self, arg0: Mm, arg1: Mm);

	/// Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignd(&mut self, arg0: Xmm, arg1: M128);

	/// Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Negate/zero/preserve packed word integers in mm1 depending on the corresponding sign in mm2/m128.
	fn psignw(&mut self, arg0: Mm, arg1: M64);

	/// Negate/zero/preserve packed word integers in mm1 depending on the corresponding sign in mm2/m128.
	fn psignw(&mut self, arg0: Mm, arg1: Mm);

	/// Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignw(&mut self, arg0: Xmm, arg1: M128);

	/// Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128.
	fn psignw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift doublewords in mm left by imm8 while shifting in 0s.
	fn pslld(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift doublewords in mm left by mm/m64 while shifting in 0s.
	fn pslld(&mut self, arg0: Mm, arg1: M64);

	/// Shift doublewords in mm left by mm/m64 while shifting in 0s.
	fn pslld(&mut self, arg0: Mm, arg1: Mm);

	/// Shift doublewords in xmm1 left by imm8 while shifting in 0s.
	fn pslld(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift doublewords in xmm1 left by xmm2/m128 while shifting in 0s.
	fn pslld(&mut self, arg0: Xmm, arg1: M128);

	/// Shift doublewords in xmm1 left by xmm2/m128 while shifting in 0s.
	fn pslld(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift xmm1 left by imm8 bytes while shifting in 0s.
	fn pslldq(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift quadword in mm left by imm8 while shifting in 0s.
	fn psllq(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift quadword in mm left by mm/m64 while shifting in 0s.
	fn psllq(&mut self, arg0: Mm, arg1: M64);

	/// Shift quadword in mm left by mm/m64 while shifting in 0s.
	fn psllq(&mut self, arg0: Mm, arg1: Mm);

	/// Shift quadwords in xmm1 left by imm8 while shifting in 0s.
	fn psllq(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift quadwords in xmm1 left by xmm2/m128 while shifting in 0s.
	fn psllq(&mut self, arg0: Xmm, arg1: M128);

	/// Shift quadwords in xmm1 left by xmm2/m128 while shifting in 0s.
	fn psllq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift words in mm left by imm8 while shifting in 0s.
	fn psllw(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift words in mm left mm/m64 while shifting in 0s.
	fn psllw(&mut self, arg0: Mm, arg1: M64);

	/// Shift words in mm left mm/m64 while shifting in 0s.
	fn psllw(&mut self, arg0: Mm, arg1: Mm);

	/// Shift words in xmm1 left by imm8 while shifting in 0s.
	fn psllw(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift words in xmm1 left by xmm2/m128 while shifting in 0s.
	fn psllw(&mut self, arg0: Xmm, arg1: M128);

	/// Shift words in xmm1 left by xmm2/m128 while shifting in 0s.
	fn psllw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift doublewords in mm right by imm8 while shifting in sign bits.
	fn psrad(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift doublewords in mm right by mm/m64 while shifting in sign bits.
	fn psrad(&mut self, arg0: Mm, arg1: M64);

	/// Shift doublewords in mm right by mm/m64 while shifting in sign bits.
	fn psrad(&mut self, arg0: Mm, arg1: Mm);

	/// Shift doublewords in xmm1 right by imm8 while shifting in sign bits.
	fn psrad(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift doubleword in xmm1 right by xmm2 /m128 while shifting in sign bits.
	fn psrad(&mut self, arg0: Xmm, arg1: M128);

	/// Shift doubleword in xmm1 right by xmm2 /m128 while shifting in sign bits.
	fn psrad(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift words in mm right by imm8 while shifting in sign bits.
	fn psraw(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift words in mm right by mm/m64 while shifting in sign bits.
	fn psraw(&mut self, arg0: Mm, arg1: M64);

	/// Shift words in mm right by mm/m64 while shifting in sign bits.
	fn psraw(&mut self, arg0: Mm, arg1: Mm);

	/// Shift words in xmm1 right by imm8 while shifting in sign bits.
	fn psraw(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift words in xmm1 right by xmm2/m128 while shifting in sign bits.
	fn psraw(&mut self, arg0: Xmm, arg1: M128);

	/// Shift words in xmm1 right by xmm2/m128 while shifting in sign bits.
	fn psraw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift doublewords in mm right by imm8 while shifting in 0s.
	fn psrld(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift doublewords in mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrld(&mut self, arg0: Mm, arg1: M64);

	/// Shift doublewords in mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrld(&mut self, arg0: Mm, arg1: Mm);

	/// Shift doublewords in xmm1 right by imm8 while shifting in 0s.
	fn psrld(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift doublewords in xmm1 right by amount specified in xmm2 /m128 while shifting in 0s.
	fn psrld(&mut self, arg0: Xmm, arg1: M128);

	/// Shift doublewords in xmm1 right by amount specified in xmm2 /m128 while shifting in 0s.
	fn psrld(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift xmm1 right by imm8 while shifting in 0s.
	fn psrldq(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift mm right by imm8 while shifting in 0s.
	fn psrlq(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrlq(&mut self, arg0: Mm, arg1: M64);

	/// Shift mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrlq(&mut self, arg0: Mm, arg1: Mm);

	/// Shift quadwords in xmm1 right by imm8 while shifting in 0s.
	fn psrlq(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift quadwords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
	fn psrlq(&mut self, arg0: Xmm, arg1: M128);

	/// Shift quadwords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
	fn psrlq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Shift words in mm right by imm8 while shifting in 0s.
	fn psrlw(&mut self, arg0: Mm, arg1: Imm8);

	/// Shift words in mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrlw(&mut self, arg0: Mm, arg1: M64);

	/// Shift words in mm right by amount specified in mm/m64 while shifting in 0s.
	fn psrlw(&mut self, arg0: Mm, arg1: Mm);

	/// Shift words in xmm1 right by imm8 while shifting in 0s.
	fn psrlw(&mut self, arg0: Xmm, arg1: Imm8);

	/// Shift words in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
	fn psrlw(&mut self, arg0: Xmm, arg1: M128);

	/// Shift words in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
	fn psrlw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract packed byte integers in mm/m64 from packed byte integers in mm.
	fn psubb(&mut self, arg0: Mm, arg1: M64);

	/// Subtract packed byte integers in mm/m64 from packed byte integers in mm.
	fn psubb(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1.
	fn psubb(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1.
	fn psubb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract packed doubleword integers in mm/m64 from packed doubleword integers in mm.
	fn psubd(&mut self, arg0: Mm, arg1: M64);

	/// Subtract packed doubleword integers in mm/m64 from packed doubleword integers in mm.
	fn psubd(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1.
	fn psubd(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1.
	fn psubd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract quadword integer in mm1 from mm2 /m64.
	fn psubq(&mut self, arg0: Mm, arg1: M64);

	/// Subtract quadword integer in mm1 from mm2 /m64.
	fn psubq(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed quadword integers in xmm1 from xmm2 /m128.
	fn psubq(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed quadword integers in xmm1 from xmm2 /m128.
	fn psubq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract signed packed bytes in mm/m64 from signed packed bytes in mm and saturate results.
	fn psubsb(&mut self, arg0: Mm, arg1: M64);

	/// Subtract signed packed bytes in mm/m64 from signed packed bytes in mm and saturate results.
	fn psubsb(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results.
	fn psubsb(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results.
	fn psubsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract signed packed words in mm/m64 from signed packed words in mm and saturate results.
	fn psubsw(&mut self, arg0: Mm, arg1: M64);

	/// Subtract signed packed words in mm/m64 from signed packed words in mm and saturate results.
	fn psubsw(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results.
	fn psubsw(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results.
	fn psubsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract unsigned packed bytes in mm/m64 from unsigned packed bytes in mm and saturate result.
	fn psubusb(&mut self, arg0: Mm, arg1: M64);

	/// Subtract unsigned packed bytes in mm/m64 from unsigned packed bytes in mm and saturate result.
	fn psubusb(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result.
	fn psubusb(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result.
	fn psubusb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract unsigned packed words in mm/m64 from unsigned packed words in mm and saturate result.
	fn psubusw(&mut self, arg0: Mm, arg1: M64);

	/// Subtract unsigned packed words in mm/m64 from unsigned packed words in mm and saturate result.
	fn psubusw(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result.
	fn psubusw(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result.
	fn psubusw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract packed word integers in mm/m64 from packed word integers in mm.
	fn psubw(&mut self, arg0: Mm, arg1: M64);

	/// Subtract packed word integers in mm/m64 from packed word integers in mm.
	fn psubw(&mut self, arg0: Mm, arg1: Mm);

	/// Subtract packed word integers in xmm2/m128 from packed word integers in xmm1.
	fn psubw(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed word integers in xmm2/m128 from packed word integers in xmm1.
	fn psubw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Set ZF if xmm2/m128 AND xmm1 result is all 0s.
	/// Set CF if xmm2/m128 AND NOT xmm1 result is all 0s.
	fn ptest(&mut self, arg0: Xmm, arg1: M128);

	/// Set ZF if xmm2/m128 AND xmm1 result is all 0s.
	/// Set CF if xmm2/m128 AND NOT xmm1 result is all 0s.
	fn ptest(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpack and interleave high-order bytes from mm and mm/m64 into mm.
	fn punpckhbw(&mut self, arg0: Mm, arg1: M64);

	/// Unpack and interleave high-order bytes from mm and mm/m64 into mm.
	fn punpckhbw(&mut self, arg0: Mm, arg1: Mm);

	/// Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1.
	fn punpckhbw(&mut self, arg0: Xmm, arg1: M128);

	/// Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1.
	fn punpckhbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpack and interleave high-order doublewords from mm and mm/m64 into mm.
	fn punpckhdq(&mut self, arg0: Mm, arg1: M64);

	/// Unpack and interleave high-order doublewords from mm and mm/m64 into mm.
	fn punpckhdq(&mut self, arg0: Mm, arg1: Mm);

	/// Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1.
	fn punpckhdq(&mut self, arg0: Xmm, arg1: M128);

	/// Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1.
	fn punpckhdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1.
	fn punpckhqdq(&mut self, arg0: Xmm, arg1: M128);

	/// Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1.
	fn punpckhqdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpack and interleave high-order words from mm and mm/m64 into mm.
	fn punpckhwd(&mut self, arg0: Mm, arg1: M64);

	/// Unpack and interleave high-order words from mm and mm/m64 into mm.
	fn punpckhwd(&mut self, arg0: Mm, arg1: Mm);

	/// Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1.
	fn punpckhwd(&mut self, arg0: Xmm, arg1: M128);

	/// Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1.
	fn punpckhwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Interleave low-order bytes from mm and mm/m32 into mm.
	fn punpcklbw(&mut self, arg0: Mm, arg1: M32);

	/// Interleave low-order bytes from mm and mm/m32 into mm.
	fn punpcklbw(&mut self, arg0: Mm, arg1: Mm);

	/// Interleave low-order bytes from xmm1 and xmm2/m128 into xmm1.
	fn punpcklbw(&mut self, arg0: Xmm, arg1: M128);

	/// Interleave low-order bytes from xmm1 and xmm2/m128 into xmm1.
	fn punpcklbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Interleave low-order doublewords from mm and mm/m32 into mm.
	fn punpckldq(&mut self, arg0: Mm, arg1: M32);

	/// Interleave low-order doublewords from mm and mm/m32 into mm.
	fn punpckldq(&mut self, arg0: Mm, arg1: Mm);

	/// Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1.
	fn punpckldq(&mut self, arg0: Xmm, arg1: M128);

	/// Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1.
	fn punpckldq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register.
	fn punpcklqdq(&mut self, arg0: Xmm, arg1: M128);

	/// Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register.
	fn punpcklqdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Interleave low-order words from mm and mm/m32 into mm.
	fn punpcklwd(&mut self, arg0: Mm, arg1: M32);

	/// Interleave low-order words from mm and mm/m32 into mm.
	fn punpcklwd(&mut self, arg0: Mm, arg1: Mm);

	/// Interleave low-order words from xmm1 and xmm2/m128 into xmm1.
	fn punpcklwd(&mut self, arg0: Xmm, arg1: M128);

	/// Interleave low-order words from xmm1 and xmm2/m128 into xmm1.
	fn punpcklwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Push FS.
	fn push(&mut self, arg0: Fs);

	/// Push GS.
	fn push(&mut self, arg0: Gs);

	/// Push r/m16.
	fn push(&mut self, arg0: M16);

	/// Push r/m64.
	fn push(&mut self, arg0: M64);

	/// Push r/m16.
	fn push(&mut self, arg0: R16);

	/// Push r16.
	void push_1(const R16& arg0);

	/// Push r/m64.
	fn push(&mut self, arg0: R64);

	/// Push r64.
	void push_1(const R64& arg0);

	/// Push lower 16 bits of EFLAGS.
	fn pushf(&mut self);

	/// Push RFLAGS.
	fn pushfq(&mut self);

	/// Push imm16 (sign-extended to 64-bits).
	fn pushq(&mut self, arg0: Imm16);

	/// Push imm32 (sign-extended to 64-bits).
	fn pushq(&mut self, arg0: Imm32);

	/// Push imm8 (sign-extended to 64-bits).
	fn pushq(&mut self, arg0: Imm8);

	/// Push imm16 (sign-extended to 16-bits).
	fn pushw(&mut self, arg0: Imm16);

	/// Push imm8 (sign-extended to 16-bits).
	fn pushw(&mut self, arg0: Imm8);

	/// Bitwise XOR of mm/m64 and mm.
	fn pxor(&mut self, arg0: Mm, arg1: M64);

	/// Bitwise XOR of mm/m64 and mm.
	fn pxor(&mut self, arg0: Mm, arg1: Mm);

	/// Bitwise XOR of xmm2/m128 and xmm1.
	fn pxor(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise XOR of xmm2/m128 and xmm1.
	fn pxor(&mut self, arg0: Xmm, arg1: Xmm);

	/// Rotate 17 bits (CF, r/m16) left CL times.
	fn rcl(&mut self, arg0: M16, arg1: Cl);

	/// Rotate 17 bits (CF, r/m16) left imm8 times.
	fn rcl(&mut self, arg0: M16, arg1: Imm8);

	/// Rotate 17 bits (CF, r/m16) left once.
	fn rcl(&mut self, arg0: M16, arg1: One);

	/// Rotate 33 bits (CF, r/m32) left CL times.
	fn rcl(&mut self, arg0: M32, arg1: Cl);

	/// Rotate 33 bits (CF, r/m32) left imm8 times.
	fn rcl(&mut self, arg0: M32, arg1: Imm8);

	/// Rotate 33 bits (CF, r/m32) left once.
	fn rcl(&mut self, arg0: M32, arg1: One);

	/// Rotate 65 bits (CF, r/m64) left CL times.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: M64, arg1: Cl);

	/// Rotate 65 bits (CF, r/m64) left imm8 times.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: M64, arg1: Imm8);

	/// Rotate 65 bits (CF, r/m64) left once.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: M64, arg1: One);

	/// Rotate 9 bits (CF, r/m8) left CL times.
	fn rcl(&mut self, arg0: M8, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) left imm8 times.
	fn rcl(&mut self, arg0: M8, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) left once.
	fn rcl(&mut self, arg0: M8, arg1: One);

	/// Rotate 17 bits (CF, r/m16) left CL times.
	fn rcl(&mut self, arg0: R16, arg1: Cl);

	/// Rotate 17 bits (CF, r/m16) left imm8 times.
	fn rcl(&mut self, arg0: R16, arg1: Imm8);

	/// Rotate 17 bits (CF, r/m16) left once.
	fn rcl(&mut self, arg0: R16, arg1: One);

	/// Rotate 33 bits (CF, r/m32) left CL times.
	fn rcl(&mut self, arg0: R32, arg1: Cl);

	/// Rotate 33 bits (CF, r/m32) left imm8 times.
	fn rcl(&mut self, arg0: R32, arg1: Imm8);

	/// Rotate 33 bits (CF, r/m32) left once.
	fn rcl(&mut self, arg0: R32, arg1: One);

	/// Rotate 65 bits (CF, r/m64) left CL times.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: R64, arg1: Cl);

	/// Rotate 65 bits (CF, r/m64) left imm8 times.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: R64, arg1: Imm8);

	/// Rotate 65 bits (CF, r/m64) left once.
	/// Uses a 6 bit count.
	fn rcl(&mut self, arg0: R64, arg1: One);

	/// Rotate 9 bits (CF, r/m8) left CL times.
	fn rcl(&mut self, arg0: R8, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) left imm8 times.
	fn rcl(&mut self, arg0: R8, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) left once.
	fn rcl(&mut self, arg0: R8, arg1: One);

	/// Rotate 9 bits (CF, r/m8) left CL times.
	fn rcl(&mut self, arg0: Rh, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) left imm8 times.
	fn rcl(&mut self, arg0: Rh, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) left once.
	fn rcl(&mut self, arg0: Rh, arg1: One);

	/// Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn rcpps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn rcpps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm2/m32 and stores the result in xmm1.
	fn rcpss(&mut self, arg0: Xmm, arg1: M32);

	/// Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm2/m32 and stores the result in xmm1.
	fn rcpss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Rotate 17 bits (CF, r/m16) right CL times.
	fn rcr(&mut self, arg0: M16, arg1: Cl);

	/// Rotate 17 bits (CF, r/m16) right imm8 times.
	fn rcr(&mut self, arg0: M16, arg1: Imm8);

	/// Rotate 17 bits (CF, r/m16) right once.
	fn rcr(&mut self, arg0: M16, arg1: One);

	/// Rotate 33 bits (CF, r/m32) right CL times.
	fn rcr(&mut self, arg0: M32, arg1: Cl);

	/// Rotate 33 bits (CF, r/m32) right imm8 times.
	fn rcr(&mut self, arg0: M32, arg1: Imm8);

	/// Rotate 33 bits (CF, r/m32) right once.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: M32, arg1: One);

	/// Rotate 65 bits (CF, r/m64) right CL times.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: M64, arg1: Cl);

	/// Rotate 65 bits (CF, r/m64) right imm8 times.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: M64, arg1: Imm8);

	/// Rotate 65 bits (CF, r/m64) right once.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: M64, arg1: One);

	/// Rotate 9 bits (CF, r/m8) right CL times.
	fn rcr(&mut self, arg0: M8, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) right imm8 times.
	fn rcr(&mut self, arg0: M8, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) right once.
	fn rcr(&mut self, arg0: M8, arg1: One);

	/// Rotate 17 bits (CF, r/m16) right CL times.
	fn rcr(&mut self, arg0: R16, arg1: Cl);

	/// Rotate 17 bits (CF, r/m16) right imm8 times.
	fn rcr(&mut self, arg0: R16, arg1: Imm8);

	/// Rotate 17 bits (CF, r/m16) right once.
	fn rcr(&mut self, arg0: R16, arg1: One);

	/// Rotate 33 bits (CF, r/m32) right CL times.
	fn rcr(&mut self, arg0: R32, arg1: Cl);

	/// Rotate 33 bits (CF, r/m32) right imm8 times.
	fn rcr(&mut self, arg0: R32, arg1: Imm8);

	/// Rotate 33 bits (CF, r/m32) right once.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: R32, arg1: One);

	/// Rotate 65 bits (CF, r/m64) right CL times.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: R64, arg1: Cl);

	/// Rotate 65 bits (CF, r/m64) right imm8 times.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: R64, arg1: Imm8);

	/// Rotate 65 bits (CF, r/m64) right once.
	/// Uses a 6 bit count.
	fn rcr(&mut self, arg0: R64, arg1: One);

	/// Rotate 9 bits (CF, r/m8) right CL times.
	fn rcr(&mut self, arg0: R8, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) right imm8 times.
	fn rcr(&mut self, arg0: R8, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) right once.
	fn rcr(&mut self, arg0: R8, arg1: One);

	/// Rotate 9 bits (CF, r/m8) right CL times.
	fn rcr(&mut self, arg0: Rh, arg1: Cl);

	/// Rotate 9 bits (CF, r/m8) right imm8 times.
	fn rcr(&mut self, arg0: Rh, arg1: Imm8);

	/// Rotate 9 bits (CF, r/m8) right once.
	fn rcr(&mut self, arg0: Rh, arg1: One);

	/// Load the 32-bit destination register with the FS base address.
	fn rdfsbase(&mut self, arg0: R32);

	/// Load the 64-bit destination register with the FS base address.
	fn rdfsbase(&mut self, arg0: R64);

	/// Load the 32-bit destination register with the GS base address.
	fn rdgsbase(&mut self, arg0: R32);

	/// Load the 64-bit destination register with the GS base address.
	fn rdgsbase(&mut self, arg0: R64);

	/// Read a 16-bit random number and store in the destination register.
	fn rdrand(&mut self, arg0: R16);

	/// Read a 32-bit random number and store in the destination register.
	fn rdrand(&mut self, arg0: R32);

	/// Read a 64-bit random number and store in the destination register.
	fn rdrand(&mut self, arg0: R64);

	/// Input (E)CX words from port DX into ES:[(E)DI.].
	void rep_ins(const M16& arg0, arg1: Dx);

	/// Input (E)CX doublewords from port DX into ES:[(E)DI].
	void rep_ins(const M32& arg0, arg1: Dx);

	/// Input RCX default size from port DX into [RDI].
	void rep_ins(const M64& arg0, arg1: Dx);

	/// Input (E)CX bytes from port DX into ES:[(E)DI].
	void rep_ins(const M8& arg0, arg1: Dx);

	/// Input RCX bytes from port DX into [RDI].
	void rep_ins_1(const M8& arg0, arg1: Dx);

	/// Load (E)CX bytes from DS:[(E)SI] to AL.
	void rep_lods(const Al& arg0);

	/// Load RCX bytes from [RSI] to AL.
	void rep_lods_1(const Al& arg0);

	/// Load (E)CX words from DS:[(E)SI] to AX.
	void rep_lods(const Ax& arg0);

	/// Load (E)CX doublewords from DS:[(E)SI] to EAX.
	void rep_lods(const Eax& arg0);

	/// Load RCX quadwords from [RSI] to RAX.
	void rep_lods(const Rax& arg0);

	/// Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].
	void rep_movs(const M16& arg0, arg1: M16);

	/// Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].
	void rep_movs(const M32& arg0, arg1: M32);

	/// Move RCX quadwords from [RSI] to [RDI].
	void rep_movs(const M64& arg0, arg1: M64);

	/// Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].
	void rep_movs(const M8& arg0, arg1: M8);

	/// Move RCX bytes from [RSI] to [RDI].
	void rep_movs_1(const M8& arg0, arg1: M8);

	/// Output (E)CX words from DS:[(E)SI] to port DX.
	void rep_outs(const Dx& arg0, arg1: M16);

	/// Output (E)CX doublewords from DS:[(E)SI] to port DX.
	void rep_outs(const Dx& arg0, arg1: M32);

	/// Output RCX default size from [RSI] to port DX.
	void rep_outs(const Dx& arg0, arg1: M64);

	/// Output (E)CX bytes from DS:[(E)SI] to port DX.
	void rep_outs(const Dx& arg0, arg1: M8);

	/// Output RCX bytes from [RSI] to port DX.
	void rep_outs_1(const Dx& arg0, arg1: M8);

	/// Fill (E)CX words at ES:[(E)DI] with AX.
	void rep_stos(const M16& arg0);

	/// Fill (E)CX doublewords at ES:[(E)DI] with EAX.
	void rep_stos(const M32& arg0);

	/// Fill RCX quadwords at [RDI] with RAX.
	void rep_stos(const M64& arg0);

	/// Fill (E)CX bytes at ES:[(E)DI] with AL.
	void rep_stos(const M8& arg0);

	/// Fill RCX bytes at [RDI] with AL.
	void rep_stos_1(const M8& arg0);

	/// Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].
	void repe_cmps(const M16& arg0, arg1: M16);

	/// Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].
	void repe_cmps(const M32& arg0, arg1: M32);

	/// Find non-matching quadwords in [RDI] and [RSI].
	void repe_cmps(const M64& arg0, arg1: M64);

	/// Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].
	void repe_cmps(const M8& arg0, arg1: M8);

	/// Find non-matching bytes in [RDI] and [RSI].
	void repe_cmps_1(const M8& arg0, arg1: M8);

	/// Find non-AX word starting at ES:[(E)DI].
	void repe_scas(const M16& arg0);

	/// Find non-EAX doubleword starting at ES:[(E)DI].
	void repe_scas(const M32& arg0);

	/// Find non-RAX quadword starting at [RDI].
	void repe_scas(const M64& arg0);

	/// Find non-AL byte starting at ES:[(E)DI].
	void repe_scas(const M8& arg0);

	/// Find non-AL byte starting at [RDI].
	void repe_scas_1(const M8& arg0);

	/// Find matching words in ES:[(E)DI] and DS:[(E)SI].
	void repne_cmps(const M16& arg0, arg1: M16);

	/// Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].
	void repne_cmps(const M32& arg0, arg1: M32);

	/// Find matching doublewords in [RDI] and [RSI].
	void repne_cmps(const M64& arg0, arg1: M64);

	/// Find matching bytes in ES:[(E)DI] and DS:[(E)SI].
	void repne_cmps(const M8& arg0, arg1: M8);

	/// Find matching bytes in [RDI] and [RSI].
	void repne_cmps_1(const M8& arg0, arg1: M8);

	/// Find AX, starting at ES:[(E)DI].
	void repne_scas(const M16& arg0);

	/// Find EAX, starting at ES:[(E)DI].
	void repne_scas(const M32& arg0);

	/// Find RAX, starting at [RDI].
	void repne_scas(const M64& arg0);

	/// Find AL, starting at ES:[(E)DI].
	void repne_scas(const M8& arg0);

	/// Find AL, starting at [RDI].
	void repne_scas_1(const M8& arg0);

	/// Near return to calling procedure.
	fn ret(&mut self);

	/// Far return to calling procedure.
	fn ret(&mut self, arg0: Far);

	/// Near return to calling procedure and pop imm16 bytes from stack.
	fn ret(&mut self, arg0: Imm16);

	/// Far return to calling procedure and pop imm16 bytes from stack.
	fn ret(&mut self, arg0: Imm16, arg1: Far);

	/// Rotate 16 bits r/m16 left CL times.
	fn rol(&mut self, arg0: M16, arg1: Cl);

	/// Rotate 16 bits r/m16 left imm8 times.
	fn rol(&mut self, arg0: M16, arg1: Imm8);

	/// Rotate 16 bits r/m16 left once.
	fn rol(&mut self, arg0: M16, arg1: One);

	/// Rotate 32 bits r/m32 left CL times.
	fn rol(&mut self, arg0: M32, arg1: Cl);

	/// Rotate 32 bits r/m32 left imm8 times.
	fn rol(&mut self, arg0: M32, arg1: Imm8);

	/// Rotate 32 bits r/m32 left once.
	fn rol(&mut self, arg0: M32, arg1: One);

	/// Rotate 64 bits r/m64 left CL times.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: M64, arg1: Cl);

	/// Rotate 64 bits r/m64 left imm8 times.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: M64, arg1: Imm8);

	/// Rotate 64 bits r/m64 left once.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: M64, arg1: One);

	/// Rotate 8 bits r/m8 left CL times.
	fn rol(&mut self, arg0: M8, arg1: Cl);

	/// Rotate 8 bits r/m8 left imm8 times.
	fn rol(&mut self, arg0: M8, arg1: Imm8);

	/// Rotate 8 bits r/m8 left once.
	fn rol(&mut self, arg0: M8, arg1: One);

	/// Rotate 16 bits r/m16 left CL times.
	fn rol(&mut self, arg0: R16, arg1: Cl);

	/// Rotate 16 bits r/m16 left imm8 times.
	fn rol(&mut self, arg0: R16, arg1: Imm8);

	/// Rotate 16 bits r/m16 left once.
	fn rol(&mut self, arg0: R16, arg1: One);

	/// Rotate 32 bits r/m32 left CL times.
	fn rol(&mut self, arg0: R32, arg1: Cl);

	/// Rotate 32 bits r/m32 left imm8 times.
	fn rol(&mut self, arg0: R32, arg1: Imm8);

	/// Rotate 32 bits r/m32 left once.
	fn rol(&mut self, arg0: R32, arg1: One);

	/// Rotate 64 bits r/m64 left CL times.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: R64, arg1: Cl);

	/// Rotate 64 bits r/m64 left imm8 times.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: R64, arg1: Imm8);

	/// Rotate 64 bits r/m64 left once.
	/// Uses a 6 bit count.
	fn rol(&mut self, arg0: R64, arg1: One);

	/// Rotate 8 bits r/m8 left CL times.
	fn rol(&mut self, arg0: R8, arg1: Cl);

	/// Rotate 8 bits r/m8 left imm8 times.
	fn rol(&mut self, arg0: R8, arg1: Imm8);

	/// Rotate 8 bits r/m8 left once.
	fn rol(&mut self, arg0: R8, arg1: One);

	/// Rotate 8 bits r/m8 left CL times.
	fn rol(&mut self, arg0: Rh, arg1: Cl);

	/// Rotate 8 bits r/m8 left imm8 times.
	fn rol(&mut self, arg0: Rh, arg1: Imm8);

	/// Rotate 8 bits r/m8 left once.
	fn rol(&mut self, arg0: Rh, arg1: One);

	/// Rotate 16 bits r/m16 right CL times.
	fn ror(&mut self, arg0: M16, arg1: Cl);

	/// Rotate 16 bits r/m16 right imm8 times.
	fn ror(&mut self, arg0: M16, arg1: Imm8);

	/// Rotate 16 bits r/m16 right once.
	fn ror(&mut self, arg0: M16, arg1: One);

	/// Rotate 32 bits r/m32 right CL times.
	fn ror(&mut self, arg0: M32, arg1: Cl);

	/// Rotate 32 bits r/m32 right imm8 times.
	fn ror(&mut self, arg0: M32, arg1: Imm8);

	/// Rotate 32 bits r/m32 right once.
	fn ror(&mut self, arg0: M32, arg1: One);

	/// Rotate 64 bits r/m64 right CL times.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: M64, arg1: Cl);

	/// Rotate 64 bits r/m64 right imm8 times.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: M64, arg1: Imm8);

	/// Rotate 64 bits r/m64 right once.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: M64, arg1: One);

	/// Rotate 8 bits r/m8 right CL times.
	fn ror(&mut self, arg0: M8, arg1: Cl);

	/// Rotate 8 bits r/m16 right imm8 times.
	fn ror(&mut self, arg0: M8, arg1: Imm8);

	/// Rotate 8 bits r/m8 right once.
	fn ror(&mut self, arg0: M8, arg1: One);

	/// Rotate 16 bits r/m16 right CL times.
	fn ror(&mut self, arg0: R16, arg1: Cl);

	/// Rotate 16 bits r/m16 right imm8 times.
	fn ror(&mut self, arg0: R16, arg1: Imm8);

	/// Rotate 16 bits r/m16 right once.
	fn ror(&mut self, arg0: R16, arg1: One);

	/// Rotate 32 bits r/m32 right CL times.
	fn ror(&mut self, arg0: R32, arg1: Cl);

	/// Rotate 32 bits r/m32 right imm8 times.
	fn ror(&mut self, arg0: R32, arg1: Imm8);

	/// Rotate 32 bits r/m32 right once.
	fn ror(&mut self, arg0: R32, arg1: One);

	/// Rotate 64 bits r/m64 right CL times.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: R64, arg1: Cl);

	/// Rotate 64 bits r/m64 right imm8 times.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: R64, arg1: Imm8);

	/// Rotate 64 bits r/m64 right once.
	/// Uses a 6 bit count.
	fn ror(&mut self, arg0: R64, arg1: One);

	/// Rotate 8 bits r/m8 right CL times.
	fn ror(&mut self, arg0: R8, arg1: Cl);

	/// Rotate 8 bits r/m16 right imm8 times.
	fn ror(&mut self, arg0: R8, arg1: Imm8);

	/// Rotate 8 bits r/m8 right once.
	fn ror(&mut self, arg0: R8, arg1: One);

	/// Rotate 8 bits r/m8 right CL times.
	fn ror(&mut self, arg0: Rh, arg1: Cl);

	/// Rotate 8 bits r/m16 right imm8 times.
	fn ror(&mut self, arg0: Rh, arg1: Imm8);

	/// Rotate 8 bits r/m8 right once.
	fn ror(&mut self, arg0: Rh, arg1: One);

	/// Rotate 32-bit r/m32 right imm8 times without affecting arithmetic flags.
	fn rorx(&mut self, arg0: R32, arg1: M32, arg2: Imm8);

	/// Rotate 32-bit r/m32 right imm8 times without affecting arithmetic flags.
	fn rorx(&mut self, arg0: R32, arg1: R32, arg2: Imm8);

	/// Rotate 64-bit r/m64 right imm8 times without affecting arithmetic flags.
	fn rorx(&mut self, arg0: R64, arg1: M64, arg2: Imm8);

	/// Rotate 64-bit r/m64 right imm8 times without affecting arithmetic flags.
	fn rorx(&mut self, arg0: R64, arg1: R64, arg2: Imm8);

	/// Round packed double precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundpd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Round packed double precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Round packed single precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Round packed single precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Round the low packed double precision floating-point value in xmm2/m64 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundsd(&mut self, arg0: Xmm, arg1: M64, arg2: Imm8);

	/// Round the low packed double precision floating-point value in xmm2/m64 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Round the low packed single precision floating-point value in xmm2/m32 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundss(&mut self, arg0: Xmm, arg1: M32, arg2: Imm8);

	/// Round the low packed single precision floating-point value in xmm2/m32 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn roundss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Computes the approximate reciprocals of the square roots of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn rsqrtps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes the approximate reciprocals of the square roots of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn rsqrtps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes the approximate reciprocal of the square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1.
	fn rsqrtss(&mut self, arg0: Xmm, arg1: M32);

	/// Computes the approximate reciprocal of the square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1.
	fn rsqrtss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Loads SF, ZF, AF, PF, and CF from AH into EFLAGS register.
	fn sahf(&mut self);

	/// Multiply r/m16 by 2, CL times.
	fn sal(&mut self, arg0: M16, arg1: Cl);

	/// Multiply r/m16 by 2, imm8 times.
	fn sal(&mut self, arg0: M16, arg1: Imm8);

	/// Multiply r/m16 by 2, once.
	fn sal(&mut self, arg0: M16, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn sal(&mut self, arg0: M32, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn sal(&mut self, arg0: M32, arg1: Imm8);

	/// Multiply r/m32 by 2, once.
	fn sal(&mut self, arg0: M32, arg1: One);

	/// Multiply r/m64 by 2, CL times.
	fn sal(&mut self, arg0: M64, arg1: Cl);

	/// Multiply r/m64 by 2, imm8 times.
	fn sal(&mut self, arg0: M64, arg1: Imm8);

	/// Multiply r/m64 by 2, once.
	fn sal(&mut self, arg0: M64, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn sal(&mut self, arg0: M8, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn sal(&mut self, arg0: M8, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn sal(&mut self, arg0: M8, arg1: One);

	/// Multiply r/m16 by 2, CL times.
	fn sal(&mut self, arg0: R16, arg1: Cl);

	/// Multiply r/m16 by 2, imm8 times.
	fn sal(&mut self, arg0: R16, arg1: Imm8);

	/// Multiply r/m16 by 2, once.
	fn sal(&mut self, arg0: R16, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn sal(&mut self, arg0: R32, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn sal(&mut self, arg0: R32, arg1: Imm8);

	/// Multiply r/m32 by 2, once.
	fn sal(&mut self, arg0: R32, arg1: One);

	/// Multiply r/m64 by 2, CL times.
	fn sal(&mut self, arg0: R64, arg1: Cl);

	/// Multiply r/m64 by 2, imm8 times.
	fn sal(&mut self, arg0: R64, arg1: Imm8);

	/// Multiply r/m64 by 2, once.
	fn sal(&mut self, arg0: R64, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn sal(&mut self, arg0: R8, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn sal(&mut self, arg0: R8, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn sal(&mut self, arg0: R8, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn sal(&mut self, arg0: Rh, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn sal(&mut self, arg0: Rh, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn sal(&mut self, arg0: Rh, arg1: One);

	/// Signed divide r/m16 by 2, CL times.
	fn sar(&mut self, arg0: M16, arg1: Cl);

	/// Signed divide r/m16 by 2, imm8 times.
	fn sar(&mut self, arg0: M16, arg1: Imm8);

	/// Signed divide r/m16 by 2, once.
	fn sar(&mut self, arg0: M16, arg1: One);

	/// Signed divide r/m32 by 2, CL times.
	fn sar(&mut self, arg0: M32, arg1: Cl);

	/// Signed divide r/m32 by 2, imm8 times.
	fn sar(&mut self, arg0: M32, arg1: Imm8);

	/// Signed divide r/m32 by 2, once.
	fn sar(&mut self, arg0: M32, arg1: One);

	/// Signed divide r/m32 by 2, CL times.
	fn sar(&mut self, arg0: M64, arg1: Cl);

	/// Signed divide r/m32 by 2, imm8 times.
	fn sar(&mut self, arg0: M64, arg1: Imm8);

	/// Signed divide r/m32 by 2, once.
	fn sar(&mut self, arg0: M64, arg1: One);

	/// Signed divide r/m8 by 2, CL times.
	fn sar(&mut self, arg0: M8, arg1: Cl);

	/// Signed divide r/m8 by 2, imm8 time.
	fn sar(&mut self, arg0: M8, arg1: Imm8);

	/// Signed divide r/m8 by 2, once.
	fn sar(&mut self, arg0: M8, arg1: One);

	/// Signed divide r/m16 by 2, CL times.
	fn sar(&mut self, arg0: R16, arg1: Cl);

	/// Signed divide r/m16 by 2, imm8 times.
	fn sar(&mut self, arg0: R16, arg1: Imm8);

	/// Signed divide r/m16 by 2, once.
	fn sar(&mut self, arg0: R16, arg1: One);

	/// Signed divide r/m32 by 2, CL times.
	fn sar(&mut self, arg0: R32, arg1: Cl);

	/// Signed divide r/m32 by 2, imm8 times.
	fn sar(&mut self, arg0: R32, arg1: Imm8);

	/// Signed divide r/m32 by 2, once.
	fn sar(&mut self, arg0: R32, arg1: One);

	/// Signed divide r/m32 by 2, CL times.
	fn sar(&mut self, arg0: R64, arg1: Cl);

	/// Signed divide r/m32 by 2, imm8 times.
	fn sar(&mut self, arg0: R64, arg1: Imm8);

	/// Signed divide r/m32 by 2, once.
	fn sar(&mut self, arg0: R64, arg1: One);

	/// Signed divide r/m8 by 2, CL times.
	fn sar(&mut self, arg0: R8, arg1: Cl);

	/// Signed divide r/m8 by 2, imm8 time.
	fn sar(&mut self, arg0: R8, arg1: Imm8);

	/// Signed divide r/m8 by 2, once.
	fn sar(&mut self, arg0: R8, arg1: One);

	/// Signed divide r/m8 by 2, CL times.
	fn sar(&mut self, arg0: Rh, arg1: Cl);

	/// Signed divide r/m8 by 2, imm8 time.
	fn sar(&mut self, arg0: Rh, arg1: Imm8);

	/// Signed divide r/m8 by 2, once.
	fn sar(&mut self, arg0: Rh, arg1: One);

	/// Shift r/m32 arithmetically right with count specified in r32b.
	fn sarx(&mut self, arg0: R32, arg1: M32, arg2: R32);

	/// Shift r/m32 arithmetically right with count specified in r32b.
	fn sarx(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Shift r/m64 arithmetically right with count specified in r64b.
	fn sarx(&mut self, arg0: R64, arg1: M64, arg2: R64);

	/// Shift r/m64 arithmetically right with count specified in r64b.
	fn sarx(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Subtract with borrow imm8 from AL.
	fn sbb(&mut self, arg0: Al, arg1: Imm8);

	/// Subtract with borrow imm16 from AX.
	fn sbb(&mut self, arg0: Ax, arg1: Imm16);

	/// Subtract with borrow imm32 from EAX.
	fn sbb(&mut self, arg0: Eax, arg1: Imm32);

	/// Subtract with borrow imm16 from r/m16.
	fn sbb(&mut self, arg0: M16, arg1: Imm16);

	/// Subtract with borrow sign-extended imm8 from r/m16.
	fn sbb(&mut self, arg0: M16, arg1: Imm8);

	/// Subtract with borrow r16 from r/m16.
	fn sbb(&mut self, arg0: M16, arg1: R16);

	/// Subtract with borrow imm32 from r/m32.
	fn sbb(&mut self, arg0: M32, arg1: Imm32);

	/// Subtract with borrow sign-extended imm8 from r/m32.
	fn sbb(&mut self, arg0: M32, arg1: Imm8);

	/// Subtract with borrow r32 from r/m32.
	fn sbb(&mut self, arg0: M32, arg1: R32);

	/// Subtract with borrow sign-extended imm32 to 64-bits from r/m64.
	fn sbb(&mut self, arg0: M64, arg1: Imm32);

	/// Subtract with borrow sign-extended imm8 from r/m64.
	fn sbb(&mut self, arg0: M64, arg1: Imm8);

	/// Subtract with borrow r64 from r/m64.
	fn sbb(&mut self, arg0: M64, arg1: R64);

	/// Subtract with borrow imm8 from r/m8.
	fn sbb(&mut self, arg0: M8, arg1: Imm8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: M8, arg1: R8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: M8, arg1: Rh);

	/// Subtract with borrow imm16 from r/m16.
	fn sbb(&mut self, arg0: R16, arg1: Imm16);

	/// Subtract with borrow sign-extended imm8 from r/m16.
	fn sbb(&mut self, arg0: R16, arg1: Imm8);

	/// Subtract with borrow r/m16 from r16.
	fn sbb(&mut self, arg0: R16, arg1: M16);

	/// Subtract with borrow r16 from r/m16.
	fn sbb(&mut self, arg0: R16, arg1: R16);

	/// Subtract with borrow r/m16 from r16.
	void sbb_1(const R16& arg0, arg1: R16);

	/// Subtract with borrow imm32 from r/m32.
	fn sbb(&mut self, arg0: R32, arg1: Imm32);

	/// Subtract with borrow sign-extended imm8 from r/m32.
	fn sbb(&mut self, arg0: R32, arg1: Imm8);

	/// Subtract with borrow r/m32 from r32.
	fn sbb(&mut self, arg0: R32, arg1: M32);

	/// Subtract with borrow r32 from r/m32.
	fn sbb(&mut self, arg0: R32, arg1: R32);

	/// Subtract with borrow r/m32 from r32.
	void sbb_1(const R32& arg0, arg1: R32);

	/// Subtract with borrow sign-extended imm32 to 64-bits from r/m64.
	fn sbb(&mut self, arg0: R64, arg1: Imm32);

	/// Subtract with borrow sign-extended imm8 from r/m64.
	fn sbb(&mut self, arg0: R64, arg1: Imm8);

	/// Subtract with borrow r/m64 from r64.
	fn sbb(&mut self, arg0: R64, arg1: M64);

	/// Subtract with borrow r64 from r/m64.
	fn sbb(&mut self, arg0: R64, arg1: R64);

	/// Subtract with borrow r/m64 from r64.
	void sbb_1(const R64& arg0, arg1: R64);

	/// Subtract with borrow imm8 from r/m8.
	fn sbb(&mut self, arg0: R8, arg1: Imm8);

	/// Subtract with borrow r/m8 from r8.
	fn sbb(&mut self, arg0: R8, arg1: M8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: R8, arg1: R8);

	/// Subtract with borrow r/m8 from r8.
	void sbb_1(const R8& arg0, arg1: R8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: R8, arg1: Rh);

	/// Subtract with borrow r/m8 from r8.
	void sbb_1(const R8& arg0, arg1: Rh);

	/// Subtract with borrow sign-extended imm.32 to 64-bits from RAX.
	fn sbb(&mut self, arg0: Rax, arg1: Imm32);

	/// Subtract with borrow imm8 from r/m8.
	fn sbb(&mut self, arg0: Rh, arg1: Imm8);

	/// Subtract with borrow r/m8 from r8.
	fn sbb(&mut self, arg0: Rh, arg1: M8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: Rh, arg1: R8);

	/// Subtract with borrow r/m8 from r8.
	void sbb_1(const Rh& arg0, arg1: R8);

	/// Subtract with borrow r8 from r/m8.
	fn sbb(&mut self, arg0: Rh, arg1: Rh);

	/// Subtract with borrow r/m8 from r8.
	void sbb_1(const Rh& arg0, arg1: Rh);

	/// Compare AX with word at ES:(E)DI or RDI, then set status flags.
	fn scas(&mut self, arg0: M16);

	/// Compare EAX with doubleword at ES(E)DI or RDI then set status flags.
	fn scas(&mut self, arg0: M32);

	/// Compare RAX with quadword at RDI or EDI then set status flags.
	fn scas(&mut self, arg0: M64);

	/// Compare AL with byte at ES:(E)DI or RDI, then set status flags.
	fn scas(&mut self, arg0: M8);

	/// Compare AL with byte at ES:(E)DI or RDI then set status flags.
	fn scasb(&mut self);

	/// Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.
	fn scasd(&mut self);

	/// Compare RAX with quadword at RDI or EDI then set status flags.
	fn scasq(&mut self);

	/// Compare AX with word at ES:(E)DI or RDI then set status flags.
	fn scasw(&mut self);

	/// Set byte if above (CF=0 and ZF=0).
	fn seta(&mut self, arg0: M8);

	/// Set byte if above (CF=0 and ZF=0).
	fn seta(&mut self, arg0: R8);

	/// Set byte if above (CF=0 and ZF=0).
	fn seta(&mut self, arg0: Rh);

	/// Set byte if above or equal (CF=0).
	fn setae(&mut self, arg0: M8);

	/// Set byte if above or equal (CF=0).
	fn setae(&mut self, arg0: R8);

	/// Set byte if above or equal (CF=0).
	fn setae(&mut self, arg0: Rh);

	/// Set byte if below (CF=1).
	fn setb(&mut self, arg0: M8);

	/// Set byte if below (CF=1).
	fn setb(&mut self, arg0: R8);

	/// Set byte if below (CF=1).
	fn setb(&mut self, arg0: Rh);

	/// Set byte if below or equal (CF=1 or ZF=1).
	fn setbe(&mut self, arg0: M8);

	/// Set byte if below or equal (CF=1 or ZF=1).
	fn setbe(&mut self, arg0: R8);

	/// Set byte if below or equal (CF=1 or ZF=1).
	fn setbe(&mut self, arg0: Rh);

	/// Set byte if carry (CF=1).
	fn setc(&mut self, arg0: M8);

	/// Set byte if carry (CF=1).
	fn setc(&mut self, arg0: R8);

	/// Set byte if carry (CF=1).
	fn setc(&mut self, arg0: Rh);

	/// Set byte if equal (ZF=1).
	fn sete(&mut self, arg0: M8);

	/// Set byte if equal (ZF=1).
	fn sete(&mut self, arg0: R8);

	/// Set byte if equal (ZF=1).
	fn sete(&mut self, arg0: Rh);

	/// Set byte if greater (ZF=0 and SF=OF).
	fn setg(&mut self, arg0: M8);

	/// Set byte if greater (ZF=0 and SF=OF).
	fn setg(&mut self, arg0: R8);

	/// Set byte if greater (ZF=0 and SF=OF).
	fn setg(&mut self, arg0: Rh);

	/// Set byte if greater or equal (SF=OF).
	fn setge(&mut self, arg0: M8);

	/// Set byte if greater or equal (SF=OF).
	fn setge(&mut self, arg0: R8);

	/// Set byte if greater or equal (SF=OF).
	fn setge(&mut self, arg0: Rh);

	/// Set byte if less (SF!= OF).
	fn setl(&mut self, arg0: M8);

	/// Set byte if less (SF!= OF).
	fn setl(&mut self, arg0: R8);

	/// Set byte if less (SF!= OF).
	fn setl(&mut self, arg0: Rh);

	/// Set byte if less or equal (ZF=1 or SF!= OF).
	fn setle(&mut self, arg0: M8);

	/// Set byte if less or equal (ZF=1 or SF!= OF).
	fn setle(&mut self, arg0: R8);

	/// Set byte if less or equal (ZF=1 or SF!= OF).
	fn setle(&mut self, arg0: Rh);

	/// Set byte if not above (CF=1 or ZF=1).
	fn setna(&mut self, arg0: M8);

	/// Set byte if not above (CF=1 or ZF=1).
	fn setna(&mut self, arg0: R8);

	/// Set byte if not above (CF=1 or ZF=1).
	fn setna(&mut self, arg0: Rh);

	/// Set byte if not above or equal (CF=1).
	fn setnae(&mut self, arg0: M8);

	/// Set byte if not above or equal (CF=1).
	fn setnae(&mut self, arg0: R8);

	/// Set byte if not above or equal (CF=1).
	fn setnae(&mut self, arg0: Rh);

	/// Set byte if not below (CF=0).
	fn setnb(&mut self, arg0: M8);

	/// Set byte if not below (CF=0).
	fn setnb(&mut self, arg0: R8);

	/// Set byte if not below (CF=0).
	fn setnb(&mut self, arg0: Rh);

	/// Set byte if not below or equal (CF=0 and ZF=0).
	fn setnbe(&mut self, arg0: M8);

	/// Set byte if not below or equal (CF=0 and ZF=0).
	fn setnbe(&mut self, arg0: R8);

	/// Set byte if not below or equal (CF=0 and ZF=0).
	fn setnbe(&mut self, arg0: Rh);

	/// Set byte if not carry (CF=0).
	fn setnc(&mut self, arg0: M8);

	/// Set byte if not carry (CF=0).
	fn setnc(&mut self, arg0: R8);

	/// Set byte if not carry (CF=0).
	fn setnc(&mut self, arg0: Rh);

	/// Set byte if not equal (ZF=0).
	fn setne(&mut self, arg0: M8);

	/// Set byte if not equal (ZF=0).
	fn setne(&mut self, arg0: R8);

	/// Set byte if not equal (ZF=0).
	fn setne(&mut self, arg0: Rh);

	/// Set byte if not greater (ZF=1 or SF!= OF).
	fn setng(&mut self, arg0: M8);

	/// Set byte if not greater (ZF=1 or SF!= OF).
	fn setng(&mut self, arg0: R8);

	/// Set byte if not greater (ZF=1 or SF!= OF).
	fn setng(&mut self, arg0: Rh);

	/// Set byte if not greater or equal (SF!= OF).
	fn setnge(&mut self, arg0: M8);

	/// Set byte if not greater or equal (SF!= OF).
	fn setnge(&mut self, arg0: R8);

	/// Set byte if not greater or equal (SF!= OF).
	fn setnge(&mut self, arg0: Rh);

	/// Set byte if not less (SF=OF).
	fn setnl(&mut self, arg0: M8);

	/// Set byte if not less (SF=OF).
	fn setnl(&mut self, arg0: R8);

	/// Set byte if not less (SF=OF).
	fn setnl(&mut self, arg0: Rh);

	/// Set byte if not less or equal (ZF=0 and SF=OF).
	fn setnle(&mut self, arg0: M8);

	/// Set byte if not less or equal (ZF=0 and SF=OF).
	fn setnle(&mut self, arg0: R8);

	/// Set byte if not less or equal (ZF=0 and SF=OF).
	fn setnle(&mut self, arg0: Rh);

	/// Set byte if not overflow (OF=0).
	fn setno(&mut self, arg0: M8);

	/// Set byte if not overflow (OF=0).
	fn setno(&mut self, arg0: R8);

	/// Set byte if not overflow (OF=0).
	fn setno(&mut self, arg0: Rh);

	/// Set byte if not parity (PF=0).
	fn setnp(&mut self, arg0: M8);

	/// Set byte if not parity (PF=0).
	fn setnp(&mut self, arg0: R8);

	/// Set byte if not parity (PF=0).
	fn setnp(&mut self, arg0: Rh);

	/// Set byte if not sign (SF=0).
	fn setns(&mut self, arg0: M8);

	/// Set byte if not sign (SF=0).
	fn setns(&mut self, arg0: R8);

	/// Set byte if not sign (SF=0).
	fn setns(&mut self, arg0: Rh);

	/// Set byte if not zero (ZF=0).
	fn setnz(&mut self, arg0: M8);

	/// Set byte if not zero (ZF=0).
	fn setnz(&mut self, arg0: R8);

	/// Set byte if not zero (ZF=0).
	fn setnz(&mut self, arg0: Rh);

	/// Set byte if overflow (OF=1).
	fn seto(&mut self, arg0: M8);

	/// Set byte if overflow (OF=1).
	fn seto(&mut self, arg0: R8);

	/// Set byte if overflow (OF=1).
	fn seto(&mut self, arg0: Rh);

	/// Set byte if parity (PF=1).
	fn setp(&mut self, arg0: M8);

	/// Set byte if parity (PF=1).
	fn setp(&mut self, arg0: R8);

	/// Set byte if parity (PF=1).
	fn setp(&mut self, arg0: Rh);

	/// Set byte if parity even (PF=1).
	fn setpe(&mut self, arg0: M8);

	/// Set byte if parity even (PF=1).
	fn setpe(&mut self, arg0: R8);

	/// Set byte if parity even (PF=1).
	fn setpe(&mut self, arg0: Rh);

	/// Set byte if parity odd (PF=0).
	fn setpo(&mut self, arg0: M8);

	/// Set byte if parity odd (PF=0).
	fn setpo(&mut self, arg0: R8);

	/// Set byte if parity odd (PF=0).
	fn setpo(&mut self, arg0: Rh);

	/// Set byte if sign (SF=1).
	fn sets(&mut self, arg0: M8);

	/// Set byte if sign (SF=1).
	fn sets(&mut self, arg0: R8);

	/// Set byte if sign (SF=1).
	fn sets(&mut self, arg0: Rh);

	/// Set byte if zero (ZF=1).
	fn setz(&mut self, arg0: M8);

	/// Set byte if zero (ZF=1).
	fn setz(&mut self, arg0: R8);

	/// Set byte if zero (ZF=1).
	fn setz(&mut self, arg0: Rh);

	/// Serializes store operations.
	fn sfence(&mut self);

	/// Multiply r/m16 by 2, CL times.
	fn shl(&mut self, arg0: M16, arg1: Cl);

	/// Multiply r/m16 by 2, imm8 times.
	fn shl(&mut self, arg0: M16, arg1: Imm8);

	/// Multiply r/m16 by 2, once.
	fn shl(&mut self, arg0: M16, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn shl(&mut self, arg0: M32, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn shl(&mut self, arg0: M32, arg1: Imm8);

	/// Multiply r/m32 by 2, once.
	fn shl(&mut self, arg0: M32, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn shl(&mut self, arg0: M64, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn shl(&mut self, arg0: M64, arg1: Imm8);

	/// Multiply r/m64 by 2, once.
	fn shl(&mut self, arg0: M64, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn shl(&mut self, arg0: M8, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn shl(&mut self, arg0: M8, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn shl(&mut self, arg0: M8, arg1: One);

	/// Multiply r/m16 by 2, CL times.
	fn shl(&mut self, arg0: R16, arg1: Cl);

	/// Multiply r/m16 by 2, imm8 times.
	fn shl(&mut self, arg0: R16, arg1: Imm8);

	/// Multiply r/m16 by 2, once.
	fn shl(&mut self, arg0: R16, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn shl(&mut self, arg0: R32, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn shl(&mut self, arg0: R32, arg1: Imm8);

	/// Multiply r/m32 by 2, once.
	fn shl(&mut self, arg0: R32, arg1: One);

	/// Multiply r/m32 by 2, CL times.
	fn shl(&mut self, arg0: R64, arg1: Cl);

	/// Multiply r/m32 by 2, imm8 times.
	fn shl(&mut self, arg0: R64, arg1: Imm8);

	/// Multiply r/m64 by 2, once.
	fn shl(&mut self, arg0: R64, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn shl(&mut self, arg0: R8, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn shl(&mut self, arg0: R8, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn shl(&mut self, arg0: R8, arg1: One);

	/// Multiply r/m8 by 2, CL times.
	fn shl(&mut self, arg0: Rh, arg1: Cl);

	/// Multiply r/m8 by 2, imm8 times.
	fn shl(&mut self, arg0: Rh, arg1: Imm8);

	/// Multiply r/m8 by 2, once.
	fn shl(&mut self, arg0: Rh, arg1: One);

	/// Shift r/m16 to left CL places while shifting bits from r16 in from the right.
	fn shld(&mut self, arg0: M16, arg1: R16, arg2: Cl);

	/// Shift r/m16 to left imm8 places while shifting bits from r16 in from the right.
	fn shld(&mut self, arg0: M16, arg1: R16, arg2: Imm8);

	/// Shift r/m32 to left CL places while shifting bits from r32 in from the right.
	fn shld(&mut self, arg0: M32, arg1: R32, arg2: Cl);

	/// Shift r/m32 to left imm8 places while shifting bits from r32 in from the right.
	fn shld(&mut self, arg0: M32, arg1: R32, arg2: Imm8);

	/// Shift r/m64 to left CL places while shifting bits from r64 in from the right.
	fn shld(&mut self, arg0: M64, arg1: R64, arg2: Cl);

	/// Shift r/m64 to left imm8 places while shifting bits from r64 in from the right.
	fn shld(&mut self, arg0: M64, arg1: R64, arg2: Imm8);

	/// Shift r/m16 to left CL places while shifting bits from r16 in from the right.
	fn shld(&mut self, arg0: R16, arg1: R16, arg2: Cl);

	/// Shift r/m16 to left imm8 places while shifting bits from r16 in from the right.
	fn shld(&mut self, arg0: R16, arg1: R16, arg2: Imm8);

	/// Shift r/m32 to left CL places while shifting bits from r32 in from the right.
	fn shld(&mut self, arg0: R32, arg1: R32, arg2: Cl);

	/// Shift r/m32 to left imm8 places while shifting bits from r32 in from the right.
	fn shld(&mut self, arg0: R32, arg1: R32, arg2: Imm8);

	/// Shift r/m64 to left CL places while shifting bits from r64 in from the right.
	fn shld(&mut self, arg0: R64, arg1: R64, arg2: Cl);

	/// Shift r/m64 to left imm8 places while shifting bits from r64 in from the right.
	fn shld(&mut self, arg0: R64, arg1: R64, arg2: Imm8);

	/// Shift r/m32 logically left with count specified in r32b.
	fn shlx(&mut self, arg0: R32, arg1: M32, arg2: R32);

	/// Shift r/m32 logically left with count specified in r32b.
	fn shlx(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Shift r/m64 logically left with count specified in r64b.
	fn shlx(&mut self, arg0: R64, arg1: M64, arg2: R64);

	/// Shift r/m64 logically left with count specified in r64b.
	fn shlx(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Unsigned divide r/m16 by 2, CL times.
	fn shr(&mut self, arg0: M16, arg1: Cl);

	/// Unsigned divide r/m16 by 2, imm8 times.
	fn shr(&mut self, arg0: M16, arg1: Imm8);

	/// Unsigned divide r/m16 by 2, once.
	fn shr(&mut self, arg0: M16, arg1: One);

	/// Unsigned divide r/m32 by 2, CL times.
	fn shr(&mut self, arg0: M32, arg1: Cl);

	/// Unsigned divide r/m32 by 2, imm8 times.
	fn shr(&mut self, arg0: M32, arg1: Imm8);

	/// Unsigned divide r/m32 by 2, once.
	fn shr(&mut self, arg0: M32, arg1: One);

	/// Unsigned divide r/m32 by 2, CL times.
	fn shr(&mut self, arg0: M64, arg1: Cl);

	/// Unsigned divide r/m32 by 2, imm8 times.
	fn shr(&mut self, arg0: M64, arg1: Imm8);

	/// Unsigned divide r/m32 by 2, once.
	fn shr(&mut self, arg0: M64, arg1: One);

	/// Unsigned divide r/m8 by 2, CL times.
	fn shr(&mut self, arg0: M8, arg1: Cl);

	/// Unsigned divide r/m8 by 2, imm8 times.
	fn shr(&mut self, arg0: M8, arg1: Imm8);

	/// Unsigned divide r/m8 by 2, once.
	fn shr(&mut self, arg0: M8, arg1: One);

	/// Unsigned divide r/m16 by 2, CL times.
	fn shr(&mut self, arg0: R16, arg1: Cl);

	/// Unsigned divide r/m16 by 2, imm8 times.
	fn shr(&mut self, arg0: R16, arg1: Imm8);

	/// Unsigned divide r/m16 by 2, once.
	fn shr(&mut self, arg0: R16, arg1: One);

	/// Unsigned divide r/m32 by 2, CL times.
	fn shr(&mut self, arg0: R32, arg1: Cl);

	/// Unsigned divide r/m32 by 2, imm8 times.
	fn shr(&mut self, arg0: R32, arg1: Imm8);

	/// Unsigned divide r/m32 by 2, once.
	fn shr(&mut self, arg0: R32, arg1: One);

	/// Unsigned divide r/m32 by 2, CL times.
	fn shr(&mut self, arg0: R64, arg1: Cl);

	/// Unsigned divide r/m32 by 2, imm8 times.
	fn shr(&mut self, arg0: R64, arg1: Imm8);

	/// Unsigned divide r/m32 by 2, once.
	fn shr(&mut self, arg0: R64, arg1: One);

	/// Unsigned divide r/m8 by 2, CL times.
	fn shr(&mut self, arg0: R8, arg1: Cl);

	/// Unsigned divide r/m8 by 2, imm8 times.
	fn shr(&mut self, arg0: R8, arg1: Imm8);

	/// Unsigned divide r/m8 by 2, once.
	fn shr(&mut self, arg0: R8, arg1: One);

	/// Unsigned divide r/m8 by 2, CL times.
	fn shr(&mut self, arg0: Rh, arg1: Cl);

	/// Unsigned divide r/m8 by 2, imm8 times.
	fn shr(&mut self, arg0: Rh, arg1: Imm8);

	/// Unsigned divide r/m8 by 2, once.
	fn shr(&mut self, arg0: Rh, arg1: One);

	/// Shift r/m16 to right CL places while shifting bits from r16 in from the left.
	fn shrd(&mut self, arg0: M16, arg1: R16, arg2: Cl);

	/// Shift r/m16 to right imm8 places while shifting bits from r16 in from the left.
	fn shrd(&mut self, arg0: M16, arg1: R16, arg2: Imm8);

	/// Shift r/m32 to right CL places while shifting bits from r32 in from the left.
	fn shrd(&mut self, arg0: M32, arg1: R32, arg2: Cl);

	/// Shift r/m32 to right imm8 places while shifting bits from r32 in from the left.
	fn shrd(&mut self, arg0: M32, arg1: R32, arg2: Imm8);

	/// Shift r/m64 to right CL places while shifting bits from r64 in from the left.
	fn shrd(&mut self, arg0: M64, arg1: R64, arg2: Cl);

	/// Shift r/m64 to right imm8 places while shifting bits from r64 in from the left.
	fn shrd(&mut self, arg0: M64, arg1: R64, arg2: Imm8);

	/// Shift r/m16 to right CL places while shifting bits from r16 in from the left.
	fn shrd(&mut self, arg0: R16, arg1: R16, arg2: Cl);

	/// Shift r/m16 to right imm8 places while shifting bits from r16 in from the left.
	fn shrd(&mut self, arg0: R16, arg1: R16, arg2: Imm8);

	/// Shift r/m32 to right CL places while shifting bits from r32 in from the left.
	fn shrd(&mut self, arg0: R32, arg1: R32, arg2: Cl);

	/// Shift r/m32 to right imm8 places while shifting bits from r32 in from the left.
	fn shrd(&mut self, arg0: R32, arg1: R32, arg2: Imm8);

	/// Shift r/m64 to right CL places while shifting bits from r64 in from the left.
	fn shrd(&mut self, arg0: R64, arg1: R64, arg2: Cl);

	/// Shift r/m64 to right imm8 places while shifting bits from r64 in from the left.
	fn shrd(&mut self, arg0: R64, arg1: R64, arg2: Imm8);

	/// Shift r/m32 logically right with count specified in r32b.
	fn shrx(&mut self, arg0: R32, arg1: M32, arg2: R32);

	/// Shift r/m32 logically right with count specified in r32b.
	fn shrx(&mut self, arg0: R32, arg1: R32, arg2: R32);

	/// Shift r/m64 logically right with count specified in r64b.
	fn shrx(&mut self, arg0: R64, arg1: M64, arg2: R64);

	/// Shift r/m64 logically right with count specified in r64b.
	fn shrx(&mut self, arg0: R64, arg1: R64, arg2: R64);

	/// Shuffle packed double-precision floating- point values selected by imm8 from xmm1 and xmm2/m128 to xmm1.
	fn shufpd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle packed double-precision floating- point values selected by imm8 from xmm1 and xmm2/m128 to xmm1.
	fn shufpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle packed single-precision floating-point values selected by imm8 from xmm1 and xmm1/m128 to xmm1.
	fn shufps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle packed single-precision floating-point values selected by imm8 from xmm1 and xmm1/m128 to xmm1.
	fn shufps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Computes square roots of the packed double- precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn sqrtpd(&mut self, arg0: Xmm, arg1: M128);

	/// Computes square roots of the packed double- precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn sqrtpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes square roots of the packed single- precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn sqrtps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes square roots of the packed single- precision floating-point values in xmm2/m128 and stores the results in xmm1.
	fn sqrtps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes square root of the low double- precision floating-point value in xmm2/m64 and stores the results in xmm1.
	fn sqrtsd(&mut self, arg0: Xmm, arg1: M64);

	/// Computes square root of the low double- precision floating-point value in xmm2/m64 and stores the results in xmm1.
	fn sqrtsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes square root of the low single- precision floating-point value in xmm2/m32 and stores the results in xmm1.
	fn sqrtss(&mut self, arg0: Xmm, arg1: M32);

	/// Computes square root of the low single- precision floating-point value in xmm2/m32 and stores the results in xmm1.
	fn sqrtss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Set CF flag.
	fn stc(&mut self);

	/// Set DF flag.
	void std_();

	/// Set interrupt flag; external, maskable interrupts enabled at the end of the next instruction.
	fn sti(&mut self);

	/// Store contents of MXCSR register to m32.
	fn stmxcsr(&mut self, arg0: M32);

	/// For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.
	fn stos(&mut self, arg0: M16);

	/// For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.
	fn stos(&mut self, arg0: M32);

	/// Store RAX at address RDI or EDI.
	fn stos(&mut self, arg0: M64);

	/// For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.
	fn stos(&mut self, arg0: M8);

	/// For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.
	fn stosb(&mut self);

	/// For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.
	fn stosd(&mut self);

	/// Store RAX at address RDI or EDI.
	fn stosq(&mut self);

	/// For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.
	fn stosw(&mut self);

	/// Subtract imm8 from AL.
	fn sub(&mut self, arg0: Al, arg1: Imm8);

	/// Subtract imm16 from AX.
	fn sub(&mut self, arg0: Ax, arg1: Imm16);

	/// Subtract imm32 from EAX.
	fn sub(&mut self, arg0: Eax, arg1: Imm32);

	/// Subtract imm16 from r/m16.
	fn sub(&mut self, arg0: M16, arg1: Imm16);

	/// Subtract sign-extended imm8 from r/m16.
	fn sub(&mut self, arg0: M16, arg1: Imm8);

	/// Subtract r16 from r/m16.
	fn sub(&mut self, arg0: M16, arg1: R16);

	/// Subtract imm32 from r/m32.
	fn sub(&mut self, arg0: M32, arg1: Imm32);

	/// Subtract sign-extended imm8 from r/m32.
	fn sub(&mut self, arg0: M32, arg1: Imm8);

	/// Subtract r32 from r/m32.
	fn sub(&mut self, arg0: M32, arg1: R32);

	/// Subtract imm32 sign-extended to 64-bits from r/m64.
	fn sub(&mut self, arg0: M64, arg1: Imm32);

	/// Subtract sign-extended imm8 from r/m64.
	fn sub(&mut self, arg0: M64, arg1: Imm8);

	/// Subtract r64 from r/m64.
	fn sub(&mut self, arg0: M64, arg1: R64);

	/// Subtract imm8 from r/m8.
	fn sub(&mut self, arg0: M8, arg1: Imm8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: M8, arg1: R8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: M8, arg1: Rh);

	/// Subtract imm16 from r/m16.
	fn sub(&mut self, arg0: R16, arg1: Imm16);

	/// Subtract sign-extended imm8 from r/m16.
	fn sub(&mut self, arg0: R16, arg1: Imm8);

	/// Subtract r/m16 from r16.
	fn sub(&mut self, arg0: R16, arg1: M16);

	/// Subtract r16 from r/m16.
	fn sub(&mut self, arg0: R16, arg1: R16);

	/// Subtract r/m16 from r16.
	void sub_1(const R16& arg0, arg1: R16);

	/// Subtract imm32 from r/m32.
	fn sub(&mut self, arg0: R32, arg1: Imm32);

	/// Subtract sign-extended imm8 from r/m32.
	fn sub(&mut self, arg0: R32, arg1: Imm8);

	/// Subtract r/m32 from r32.
	fn sub(&mut self, arg0: R32, arg1: M32);

	/// Subtract r32 from r/m32.
	fn sub(&mut self, arg0: R32, arg1: R32);

	/// Subtract r/m32 from r32.
	void sub_1(const R32& arg0, arg1: R32);

	/// Subtract imm32 sign-extended to 64-bits from r/m64.
	fn sub(&mut self, arg0: R64, arg1: Imm32);

	/// Subtract sign-extended imm8 from r/m64.
	fn sub(&mut self, arg0: R64, arg1: Imm8);

	/// Subtract r/m64 from r64.
	fn sub(&mut self, arg0: R64, arg1: M64);

	/// Subtract r64 from r/m64.
	fn sub(&mut self, arg0: R64, arg1: R64);

	/// Subtract r/m64 from r64.
	void sub_1(const R64& arg0, arg1: R64);

	/// Subtract imm8 from r/m8.
	fn sub(&mut self, arg0: R8, arg1: Imm8);

	/// Subtract r/m8 from r8.
	fn sub(&mut self, arg0: R8, arg1: M8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: R8, arg1: R8);

	/// Subtract r/m8 from r8.
	void sub_1(const R8& arg0, arg1: R8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: R8, arg1: Rh);

	/// Subtract r/m8 from r8.
	void sub_1(const R8& arg0, arg1: Rh);

	/// Subtract imm32 sign-extended to 64-bits from RAX.
	fn sub(&mut self, arg0: Rax, arg1: Imm32);

	/// Subtract imm8 from r/m8.
	fn sub(&mut self, arg0: Rh, arg1: Imm8);

	/// Subtract r/m8 from r8.
	fn sub(&mut self, arg0: Rh, arg1: M8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: Rh, arg1: R8);

	/// Subtract r/m8 from r8.
	void sub_1(const Rh& arg0, arg1: R8);

	/// Subtract r8 from r/m8.
	fn sub(&mut self, arg0: Rh, arg1: Rh);

	/// Subtract r/m8 from r8.
	void sub_1(const Rh& arg0, arg1: Rh);

	/// Subtract packed double-precision floating- point values in xmm2/m128 from xmm1.
	fn subpd(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed double-precision floating- point values in xmm2/m128 from xmm1.
	fn subpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract packed single-precision floating-point values in xmm2/mem from xmm1.
	fn subps(&mut self, arg0: Xmm, arg1: M128);

	/// Subtract packed single-precision floating-point values in xmm2/mem from xmm1.
	fn subps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtracts the low double-precision floating- point values in xmm2/mem64 from xmm1.
	fn subsd(&mut self, arg0: Xmm, arg1: M64);

	/// Subtracts the low double-precision floating- point values in xmm2/mem64 from xmm1.
	fn subsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract the lower single-precision floating- point values in xmm2/m32 from xmm1.
	fn subss(&mut self, arg0: Xmm, arg1: M32);

	/// Subtract the lower single-precision floating- point values in xmm2/m32 from xmm1.
	fn subss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Exchanges the current GS base register value with the value contained in MSR address C0000102H.
	fn swapgs(&mut self);

	/// Fast call to privilege level 0 system procedures.
	fn syscall(&mut self);

	/// Fast call to privilege level 0 system procedures.
	fn sysenter(&mut self);

	/// Fast return to privilege level 3 user code.
	fn sysexit(&mut self);

	/// Fast return to 64-bit mode privilege level 3 user code.
	fn sysexit(&mut self, arg0: PrefRexW);

	/// Return to compatibility mode from fast system call.
	fn sysret(&mut self);

	/// Return to 64-bit mode from fast system call.
	fn sysret(&mut self, arg0: PrefRexW);

	/// AND imm8 with AL; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Al, arg1: Imm8);

	/// AND imm16 with AX; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Ax, arg1: Imm16);

	/// AND imm32 with EAX; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Eax, arg1: Imm32);

	/// AND imm16 with r/m16; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M16, arg1: Imm16);

	/// AND r16 with r/m16; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M16, arg1: R16);

	/// AND imm32 with r/m32; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M32, arg1: Imm32);

	/// AND r32 with r/m32; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M32, arg1: R32);

	/// AND imm32 sign-extended to 64-bits with r/m64; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M64, arg1: Imm32);

	/// AND r64 with r/m64; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M64, arg1: R64);

	/// AND imm8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M8, arg1: Imm8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M8, arg1: R8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: M8, arg1: Rh);

	/// AND imm16 with r/m16; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R16, arg1: Imm16);

	/// AND r16 with r/m16; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R16, arg1: R16);

	/// AND imm32 with r/m32; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R32, arg1: Imm32);

	/// AND r32 with r/m32; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R32, arg1: R32);

	/// AND imm32 sign-extended to 64-bits with r/m64; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R64, arg1: Imm32);

	/// AND r64 with r/m64; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R64, arg1: R64);

	/// AND imm8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R8, arg1: Imm8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R8, arg1: R8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: R8, arg1: Rh);

	/// AND imm32 sign-extended to 64-bits with RAX; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Rax, arg1: Imm32);

	/// AND imm8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Rh, arg1: Imm8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Rh, arg1: R8);

	/// AND r8 with r/m8; set SF, ZF, PF according to result.
	fn test(&mut self, arg0: Rh, arg1: Rh);

	/// Count the number of trailing zero bits in r/m16, return result in r16.
	fn tzcnt(&mut self, arg0: R16, arg1: M16);

	/// Count the number of trailing zero bits in r/m16, return result in r16.
	fn tzcnt(&mut self, arg0: R16, arg1: R16);

	/// Count the number of trailing zero bits in r/m32, return result in r32.
	fn tzcnt(&mut self, arg0: R32, arg1: M32);

	/// Count the number of trailing zero bits in r/m32, return result in r32.
	fn tzcnt(&mut self, arg0: R32, arg1: R32);

	/// Count the number of trailing zero bits in r/m64, return result in r64.
	fn tzcnt(&mut self, arg0: R64, arg1: M64);

	/// Count the number of trailing zero bits in r/m64, return result in r64.
	fn tzcnt(&mut self, arg0: R64, arg1: R64);

	/// Compares (unordered) the low double- precision floating-point values in xmm1 and xmm2/m64 and set the EFLAGS accordingly.
	fn ucomisd(&mut self, arg0: Xmm, arg1: M64);

	/// Compares (unordered) the low double- precision floating-point values in xmm1 and xmm2/m64 and set the EFLAGS accordingly.
	fn ucomisd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare lower single-precision floating-point value in xmm1 register with lower single- precision floating-point value in xmm2/mem and set the status flags accordingly.
	fn ucomiss(&mut self, arg0: Xmm, arg1: M32);

	/// Compare lower single-precision floating-point value in xmm1 register with lower single- precision floating-point value in xmm2/mem and set the status flags accordingly.
	fn ucomiss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Raise invalid opcode exception.
	fn ud2(&mut self);

	/// Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm1 and xmm2/m128.
	fn unpckhpd(&mut self, arg0: Xmm, arg1: M128);

	/// Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm1 and xmm2/m128.
	fn unpckhpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm1 and xmm2/mem into xmm1.
	fn unpckhps(&mut self, arg0: Xmm, arg1: M128);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm1 and xmm2/mem into xmm1.
	fn unpckhps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm1 and xmm2/m128.
	fn unpcklpd(&mut self, arg0: Xmm, arg1: M128);

	/// Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm1 and xmm2/m128.
	fn unpcklpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/mem into xmm1.
	fn unpcklps(&mut self, arg0: Xmm, arg1: M128);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/mem into xmm1.
	fn unpcklps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Add packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add the low double-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.
	fn vaddsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Add the low double-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.
	fn vaddsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add the low single-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.
	fn vaddss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Add the low single-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.
	fn vaddss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add/subtract packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add/subtract packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add / subtract packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add / subtract packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add/subtract single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add/subtract single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vaddsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add / subtract single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add / subtract single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vaddsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.
	fn vaesdec(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.
	fn vaesdec(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.
	fn vaesdeclast(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.
	fn vaesdeclast(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from the xmm3/m128; store the result in xmm1.
	fn vaesenc(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from the xmm3/m128; store the result in xmm1.
	fn vaesenc(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128 bit round key from xmm3/m128; store the result in xmm1.
	fn vaesenclast(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128 bit round key from xmm3/m128; store the result in xmm1.
	fn vaesenclast(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.
	fn vaesimc(&mut self, arg0: Xmm, arg1: M128);

	/// Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.
	fn vaesimc(&mut self, arg0: Xmm, arg1: Xmm);

	/// Assist in AES round key generation using 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.
	fn vaeskeygenassist(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Assist in AES round key generation using 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.
	fn vaeskeygenassist(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vandnpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vandnpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vandnpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vandnpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vandnps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vandnps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical AND NOT of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vandnps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical AND NOT of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vandnps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vandpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vandpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vandpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vandpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vandps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vandps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vandps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vandps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Select packed double-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.
	fn vblendpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Select packed double-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.
	fn vblendpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Select packed double-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.
	fn vblendpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Select packed double-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.
	fn vblendpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Select packed single-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.
	fn vblendps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Select packed single-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.
	fn vblendps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Select packed single-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.
	fn vblendps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Select packed single-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.
	fn vblendps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Conditionally copy double-precision floating- point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the mask operand, xmm4.
	fn vblendvpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Xmm);

	/// Conditionally copy double-precision floating- point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the mask operand, xmm4.
	fn vblendvpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Xmm);

	/// Conditionally copy double-precision floating- point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4.
	fn vblendvpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Ymm);

	/// Conditionally copy double-precision floating- point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4.
	fn vblendvpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Ymm);

	/// Conditionally copy single-precision floating- point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the specified mask operand, xmm4.
	fn vblendvps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Xmm);

	/// Conditionally copy single-precision floating- point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the specified mask operand, xmm4.
	fn vblendvps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Xmm);

	/// Conditionally copy single-precision floating- point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the specified mask register, ymm4.
	fn vblendvps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Ymm);

	/// Conditionally copy single-precision floating- point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the specified mask register, ymm4.
	fn vblendvps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Ymm);

	/// Broadcast 128 bits of floating-point data in mem to low and high 128-bits in ymm1.
	fn vbroadcastf128(&mut self, arg0: Ymm, arg1: M128);

	/// Broadcast 128 bits of integer data in mem to low and high 128-bits in ymm1.
	fn vbroadcasti128(&mut self, arg0: Ymm, arg1: M128);

	/// Broadcast double-precision floating-point element in mem to four locations in ymm1.
	fn vbroadcastsd(&mut self, arg0: Ymm, arg1: M64);

	/// Broadcast low double-precision floating-point element in the source operand to four locations in ymm1.
	fn vbroadcastsd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Broadcast single-precision floating-point element in mem to four locations in xmm1.
	fn vbroadcastss(&mut self, arg0: Xmm, arg1: M32);

	/// Broadcast the low single-precision floating- point element in the source operand to four locations in xmm1.
	fn vbroadcastss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Broadcast single-precision floating-point element in mem to eight locations in ymm1.
	fn vbroadcastss(&mut self, arg0: Ymm, arg1: M32);

	/// Broadcast low single-precision floating-point element in the source operand to eight locations in ymm1.
	fn vbroadcastss(&mut self, arg0: Ymm, arg1: Xmm);

	/// Compare packed double-precision floating- point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Compare packed double-precision floating- point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Compare packed double-precision floating- point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmppd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Compare packed double-precision floating- point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmppd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Compare packed single-precision floating- point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Compare packed single-precision floating- point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Compare packed single-precision floating- point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmpps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Compare packed single-precision floating- point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
	fn vcmpps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Compare low double precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate.
	fn vcmpsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64, arg3: Imm8);

	/// Compare low double precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate.
	fn vcmpsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Compare low single precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.
	fn vcmpss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32, arg3: Imm8);

	/// Compare low single precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.
	fn vcmpss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Compare low double precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn vcomisd(&mut self, arg0: Xmm, arg1: M64);

	/// Compare low double precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn vcomisd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare low single precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn vcomiss(&mut self, arg0: Xmm, arg1: M32);

	/// Compare low single precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn vcomiss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.
	fn vcvtdq2pd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.
	fn vcvtdq2pd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed signed doubleword integers from ymm2/mem to four packed double-precision floating-point values in ymm1.
	fn vcvtdq2pd(&mut self, arg0: Ymm, arg1: M128);

	/// Convert four packed signed doubleword integers from ymm2/mem to four packed double-precision floating-point values in ymm1.
	fn vcvtdq2pd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.
	fn vcvtdq2ps(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.
	fn vcvtdq2ps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert eight packed signed doubleword integers from ymm2/mem to eight packed single-precision floating-point values in ymm1.
	fn vcvtdq2ps(&mut self, arg0: Ymm, arg1: M256);

	/// Convert eight packed signed doubleword integers from ymm2/mem to eight packed single-precision floating-point values in ymm1.
	fn vcvtdq2ps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two signed doubleword integers in xmm1.
	fn vcvtpd2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four signed doubleword integers in xmm1.
	fn vcvtpd2dq(&mut self, arg0: Xmm, arg1: M256);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two signed doubleword integers in xmm1.
	fn vcvtpd2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four signed doubleword integers in xmm1.
	fn vcvtpd2dq(&mut self, arg0: Xmm, arg1: Ymm);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two single- precision floating-point values in xmm1.
	fn vcvtpd2ps(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four single- precision floating-point values in xmm1.
	fn vcvtpd2ps(&mut self, arg0: Xmm, arg1: M256);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two single- precision floating-point values in xmm1.
	fn vcvtpd2ps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four single- precision floating-point values in xmm1.
	fn vcvtpd2ps(&mut self, arg0: Xmm, arg1: Ymm);

	/// Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point value in xmm1.
	fn vcvtph2ps(&mut self, arg0: Xmm, arg1: M64);

	/// Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point value in xmm1.
	fn vcvtph2ps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point value in ymm1.
	fn vcvtph2ps(&mut self, arg0: Ymm, arg1: M128);

	/// Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point value in ymm1.
	fn vcvtph2ps(&mut self, arg0: Ymm, arg1: Xmm);

	/// Convert four packed single precision floating- point values from xmm2/mem to four packed signed doubleword values in xmm1.
	fn vcvtps2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed single precision floating- point values from xmm2/mem to four packed signed doubleword values in xmm1.
	fn vcvtps2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert eight packed single precision floating- point values from ymm2/mem to eight packed signed doubleword values in ymm1.
	fn vcvtps2dq(&mut self, arg0: Ymm, arg1: M256);

	/// Convert eight packed single precision floating- point values from ymm2/mem to eight packed signed doubleword values in ymm1.
	fn vcvtps2dq(&mut self, arg0: Ymm, arg1: Ymm);

	/// Convert two packed single-precision floating- point values in xmm2/mem to two packed double-precision floating-point values in xmm1.
	fn vcvtps2pd(&mut self, arg0: Xmm, arg1: M64);

	/// Convert two packed single-precision floating- point values in xmm2/mem to two packed double-precision floating-point values in xmm1.
	fn vcvtps2pd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed single-precision floating- point values in xmm2/mem to four packed double-precision floating-point values in ymm1.
	fn vcvtps2pd(&mut self, arg0: Ymm, arg1: M128);

	/// Convert four packed single-precision floating- point values in xmm2/mem to four packed double-precision floating-point values in ymm1.
	fn vcvtps2pd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Convert eight packed single-precision floating-point value in ymm2 to packed half-precision (16-bit) floating-point value in xmm1/mem.
	/// Imm8 provides rounding controls.
	fn vcvtps2ph(&mut self, arg0: M128, arg1: Ymm, arg2: Imm8);

	/// Convert four packed single-precision float- ing-point value in xmm2 to packed half- precision (16-bit) floating-point value in xmm1/mem.
	/// Imm8 provides rounding con- trols.
	fn vcvtps2ph(&mut self, arg0: M64, arg1: Xmm, arg2: Imm8);

	/// Convert four packed single-precision float- ing-point value in xmm2 to packed half- precision (16-bit) floating-point value in xmm1/mem.
	/// Imm8 provides rounding con- trols.
	fn vcvtps2ph(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Convert eight packed single-precision floating-point value in ymm2 to packed half-precision (16-bit) floating-point value in xmm1/mem.
	/// Imm8 provides rounding controls.
	fn vcvtps2ph(&mut self, arg0: Xmm, arg1: Ymm, arg2: Imm8);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed doubleword integer r32.
	fn vcvtsd2si(&mut self, arg0: R32, arg1: M64);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed doubleword integer r32.
	fn vcvtsd2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64.
	fn vcvtsd2si(&mut self, arg0: R64, arg1: M64);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64.
	fn vcvtsd2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2.
	fn vcvtsd2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2.
	fn vcvtsd2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.
	fn vcvtsi2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.
	fn vcvtsi2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.
	fn vcvtsi2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: R32);

	/// Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.
	fn vcvtsi2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: R64);

	/// Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.
	fn vcvtsi2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.
	fn vcvtsi2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.
	fn vcvtsi2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: R32);

	/// Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.
	fn vcvtsi2ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: R64);

	/// Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2.
	fn vcvtss2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2.
	fn vcvtss2sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.
	fn vcvtss2si(&mut self, arg0: R32, arg1: M32);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.
	fn vcvtss2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.
	fn vcvtss2si(&mut self, arg0: R64, arg1: M32);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.
	fn vcvtss2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.
	fn vcvttpd2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four signed doubleword integers in xmm1 using truncation.
	fn vcvttpd2dq(&mut self, arg0: Xmm, arg1: M256);

	/// Convert two packed double-precision floating- point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.
	fn vcvttpd2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert four packed double-precision floating- point values in ymm2/mem to four signed doubleword integers in xmm1 using truncation.
	fn vcvttpd2dq(&mut self, arg0: Xmm, arg1: Ymm);

	/// Convert four packed single precision floating- point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.
	fn vcvttps2dq(&mut self, arg0: Xmm, arg1: M128);

	/// Convert four packed single precision floating- point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.
	fn vcvttps2dq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Convert eight packed single precision floating- point values from ymm2/mem to eight packed signed doubleword values in ymm1 using truncation.
	fn vcvttps2dq(&mut self, arg0: Ymm, arg1: M256);

	/// Convert eight packed single precision floating- point values from ymm2/mem to eight packed signed doubleword values in ymm1 using truncation.
	fn vcvttps2dq(&mut self, arg0: Ymm, arg1: Ymm);

	/// Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.
	fn vcvttsd2si(&mut self, arg0: R32, arg1: M64);

	/// Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.
	fn vcvttsd2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.
	fn vcvttsd2si(&mut self, arg0: R64, arg1: M64);

	/// Convert one double precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.
	fn vcvttsd2si(&mut self, arg0: R64, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.
	fn vcvttss2si(&mut self, arg0: R32, arg1: M32);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.
	fn vcvttss2si(&mut self, arg0: R32, arg1: Xmm);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.
	fn vcvttss2si(&mut self, arg0: R64, arg1: M32);

	/// Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.
	fn vcvttss2si(&mut self, arg0: R64, arg1: Xmm);

	/// Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.
	fn vdivpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.
	fn vdivpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.
	fn vdivpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.
	fn vdivpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Divide packed single-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.
	fn vdivps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Divide packed single-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.
	fn vdivps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Divide packed single-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.
	fn vdivps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Divide packed single-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.
	fn vdivps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Divide low double-precision floating point values in xmm2 by low double precision floating-point value in xmm3/mem64.
	fn vdivsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Divide low double-precision floating point values in xmm2 by low double precision floating-point value in xmm3/mem64.
	fn vdivsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Divide low single-precision floating point value in xmm2 by low single precision floating-point value in xmm3/m32.
	fn vdivss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Divide low single-precision floating point value in xmm2 by low single precision floating-point value in xmm3/m32.
	fn vdivss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Selectively multiply packed DP floating-point values from xmm2 with packed DP floating- point values from xmm3, add and selectively store the packed DP floating-point values to xmm1.
	fn vdppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Selectively multiply packed DP floating-point values from xmm2 with packed DP floating- point values from xmm3, add and selectively store the packed DP floating-point values to xmm1.
	fn vdppd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Multiply packed SP floating point values from xmm1 with packed SP floating point values from xmm2/mem selectively add and store to xmm1.
	fn vdpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Multiply packed SP floating point values from xmm1 with packed SP floating point values from xmm2/mem selectively add and store to xmm1.
	fn vdpps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Multiply packed single-precision floating-point values from ymm2 with packed SP floating point values from ymm3/mem, selectively add pairs of elements and store to ymm1.
	fn vdpps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Multiply packed single-precision floating-point values from ymm2 with packed SP floating point values from ymm3/mem, selectively add pairs of elements and store to ymm1.
	fn vdpps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Set ZF=1 if segment specified with r/m16 can be read.
	fn verr(&mut self, arg0: M16);

	/// Set ZF=1 if segment specified with r/m16 can be read.
	fn verr(&mut self, arg0: R16);

	/// Set ZF=1 if segment specified with r/m16 can be written.
	fn verw(&mut self, arg0: M16);

	/// Set ZF=1 if segment specified with r/m16 can be written.
	fn verw(&mut self, arg0: R16);

	/// Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/mem.
	fn vextractf128(&mut self, arg0: M128, arg1: Ymm, arg2: Imm8);

	/// Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/mem.
	fn vextractf128(&mut self, arg0: Xmm, arg1: Ymm, arg2: Imm8);

	/// Extract 128 bits of integer data from ymm2 and store results in xmm1/mem.
	fn vextracti128(&mut self, arg0: M128, arg1: Ymm, arg2: Imm8);

	/// Extract 128 bits of integer data from ymm2 and store results in xmm1/mem.
	fn vextracti128(&mut self, arg0: Xmm, arg1: Ymm, arg2: Imm8);

	/// Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32.
	/// Zero extend the results in 64-bit register if applicable.
	fn vextractps(&mut self, arg0: M32, arg1: Xmm, arg2: Imm8);

	/// Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32.
	/// Zero extend the results in 64-bit register if applicable.
	fn vextractps(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, add to ymm1 and put result in ymm0.
	fn vfmadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, add to ymm1 and put result in ymm0.
	fn vfmadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, add to ymm1 and put result in ymm0.
	fn vfmadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, add to ymm1 and put result in ymm0.
	fn vfmadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, add to xmm1 and put result in xmm0.
	fn vfmadd132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, add to ymm2/mem and put result in ymm0.
	fn vfmadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, add to ymm2/mem and put result in ymm0.
	fn vfmadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, add to ymm2/mem and put result in ymm0.
	fn vfmadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, add to ymm2/mem and put result in ymm0.
	fn vfmadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, add to xmm2/mem and put result in xmm0.
	fn vfmadd213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, add to ymm0 and put result in ymm0.
	fn vfmadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, add to ymm0 and put result in ymm0.
	fn vfmadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, add to ymm0 and put result in ymm0.
	fn vfmadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, add to ymm0 and put result in ymm0.
	fn vfmadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, add to xmm0 and put result in xmm0.
	fn vfmadd231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, add/subtract elements in xmm1 and put result in xmm0.
	fn vfmaddsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, add/subtract elements in xmm1 and put result in xmm0.
	fn vfmaddsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, add/subtract elements in ymm1 and put result in ymm0.
	fn vfmaddsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, add/subtract elements in ymm1 and put result in ymm0.
	fn vfmaddsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, add/subtract elements in xmm1 and put result in xmm0.
	fn vfmaddsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, add/subtract elements in xmm1 and put result in xmm0.
	fn vfmaddsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, add/subtract elements in ymm1 and put result in ymm0.
	fn vfmaddsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, add/subtract elements in ymm1 and put result in ymm0.
	fn vfmaddsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, add/subtract elements in xmm2/mem and put result in xmm0.
	fn vfmaddsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, add/subtract elements in xmm2/mem and put result in xmm0.
	fn vfmaddsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, add/subtract elements in ymm2/mem and put result in ymm0.
	fn vfmaddsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, add/subtract elements in ymm2/mem and put result in ymm0.
	fn vfmaddsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, add/subtract elements in xmm2/mem and put result in xmm0.
	fn vfmaddsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, add/subtract elements in xmm2/mem and put result in xmm0.
	fn vfmaddsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, add/subtract elements in ymm2/mem and put result in ymm0.
	fn vfmaddsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, add/subtract elements in ymm2/mem and put result in ymm0.
	fn vfmaddsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, add/subtract elements in xmm0 and put result in xmm0.
	fn vfmaddsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, add/subtract elements in xmm0 and put result in xmm0.
	fn vfmaddsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, add/subtract elements in ymm0 and put result in ymm0.
	fn vfmaddsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, add/subtract elements in ymm0 and put result in ymm0.
	fn vfmaddsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, add/subtract elements in xmm0 and put result in xmm0.
	fn vfmaddsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, add/subtract elements in xmm0 and put result in xmm0.
	fn vfmaddsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, add/subtract elements in ymm0 and put result in ymm0.
	fn vfmaddsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, add/subtract elements in ymm0 and put result in ymm0.
	fn vfmaddsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, subtract ymm1 and put result in ymm0.
	fn vfmsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, subtract ymm1 and put result in ymm0.
	fn vfmsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, subtract ymm1 and put result in ymm0.
	fn vfmsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, subtract ymm1 and put result in ymm0.
	fn vfmsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, subtract xmm1 and put result in xmm0.
	fn vfmsub132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, subtract ymm2/mem and put result in ymm0.
	fn vfmsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, subtract ymm2/mem and put result in ymm0.
	fn vfmsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, subtract ymm2/mem and put result in ymm0.
	fn vfmsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, subtract ymm2/mem and put result in ymm0.
	fn vfmsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, subtract xmm2/mem and put result in xmm0.
	fn vfmsub213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, subtract ymm0 and put result in ymm0.
	fn vfmsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, subtract ymm0 and put result in ymm0.
	fn vfmsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, subtract ymm0 and put result in ymm0.
	fn vfmsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, subtract ymm0 and put result in ymm0.
	fn vfmsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, subtract xmm0 and put result in xmm0.
	fn vfmsub231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, subtract/add elements in xmm1 and put result in xmm0.
	fn vfmsubadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, subtract/add elements in xmm1 and put result in xmm0.
	fn vfmsubadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, subtract/add elements in ymm1 and put result in ymm0.
	fn vfmsubadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, subtract/add elements in ymm1 and put result in ymm0.
	fn vfmsubadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, subtract/add elements in xmm1 and put result in xmm0.
	fn vfmsubadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, subtract/add elements in xmm1 and put result in xmm0.
	fn vfmsubadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, subtract/add elements in ymm1 and put result in ymm0.
	fn vfmsubadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, subtract/add elements in ymm1 and put result in ymm0.
	fn vfmsubadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, subtract/add elements in xmm2/mem and put result in xmm0.
	fn vfmsubadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, subtract/add elements in xmm2/mem and put result in xmm0.
	fn vfmsubadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, subtract/add elements in ymm2/mem and put result in ymm0.
	fn vfmsubadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, subtract/add elements in ymm2/mem and put result in ymm0.
	fn vfmsubadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, subtract/add elements in xmm2/mem and put result in xmm0.
	fn vfmsubadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, subtract/add elements in xmm2/mem and put result in xmm0.
	fn vfmsubadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, subtract/add elements in ymm2/mem and put result in ymm0.
	fn vfmsubadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, subtract/add elements in ymm2/mem and put result in ymm0.
	fn vfmsubadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, subtract/add elements in xmm0 and put result in xmm0.
	fn vfmsubadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, subtract/add elements in xmm0 and put result in xmm0.
	fn vfmsubadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, subtract/add elements in ymm0 and put result in ymm0.
	fn vfmsubadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, subtract/add elements in ymm0 and put result in ymm0.
	fn vfmsubadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, subtract/add elements in xmm0 and put result in xmm0.
	fn vfmsubadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, subtract/add elements in xmm0 and put result in xmm0.
	fn vfmsubadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, subtract/add elements in ymm0 and put result in ymm0.
	fn vfmsubadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, subtract/add elements in ymm0 and put result in ymm0.
	fn vfmsubadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and add to ymm1 and put result in ymm0.
	fn vfnmadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and add to ymm1 and put result in ymm0.
	fn vfnmadd132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and add to ymm1 and put result in ymm0.
	fn vfnmadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and add to ymm1 and put result in ymm0.
	fn vfnmadd132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and add to xmm1 and put result in xmm0.
	fn vfnmadd132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, negate the multiplication result and add to ymm2/mem and put result in ymm0.
	fn vfnmadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, negate the multiplication result and add to ymm2/mem and put result in ymm0.
	fn vfnmadd213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, negate the multiplication result and add to ymm2/mem and put result in ymm0.
	fn vfnmadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, negate the multiplication result and add to ymm2/mem and put result in ymm0.
	fn vfnmadd213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, negate the multiplication result and add to xmm2/mem and put result in xmm0.
	fn vfnmadd213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and add to ymm0 and put result in ymm0.
	fn vfnmadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and add to ymm0 and put result in ymm0.
	fn vfnmadd231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and add to ymm0 and put result in ymm0.
	fn vfnmadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and add to ymm0 and put result in ymm0.
	fn vfnmadd231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and add to xmm0 and put result in xmm0.
	fn vfnmadd231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and subtract ymm1 and put result in ymm0.
	fn vfnmsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and subtract ymm1 and put result in ymm0.
	fn vfnmsub132pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and subtract ymm1 and put result in ymm0.
	fn vfnmsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm2/mem, negate the multiplication result and subtract ymm1 and put result in ymm0.
	fn vfnmsub132ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm2/mem, negate the multiplication result and subtract xmm1 and put result in xmm0.
	fn vfnmsub132ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, negate the multiplication result and subtract ymm2/mem and put result in ymm0.
	fn vfnmsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm0 and ymm1, negate the multiplication result and subtract ymm2/mem and put result in ymm0.
	fn vfnmsub213pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, negate the multiplication result and subtract ymm2/mem and put result in ymm0.
	fn vfnmsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm0 and ymm1, negate the multiplication result and subtract ymm2/mem and put result in ymm0.
	fn vfnmsub213ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm0 and xmm1, negate the multiplication result and subtract xmm2/mem and put result in xmm0.
	fn vfnmsub213ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231pd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and subtract ymm0 and put result in ymm0.
	fn vfnmsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and subtract ymm0 and put result in ymm0.
	fn vfnmsub231pd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231ps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and subtract ymm0 and put result in ymm0.
	fn vfnmsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm1 and ymm2/mem, negate the multiplication result and subtract ymm0 and put result in ymm0.
	fn vfnmsub231ps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply scalar double-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231sd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply scalar single-precision floating-point value from xmm1 and xmm2/mem, negate the multiplication result and subtract xmm0 and put result in xmm0.
	fn vfnmsub231ss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Using dword indices specified in vm32x, gather double-precision FP values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vgatherdpd(&mut self, arg0: Xmm, arg1: M32, arg2: Xmm);

	/// Using dword indices specified in vm32x, gather double-precision FP values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vgatherdpd(&mut self, arg0: Ymm, arg1: M32, arg2: Ymm);

	/// Using dword indices specified in vm32x, gather single-precision FP values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vgatherdps(&mut self, arg0: Xmm, arg1: M32, arg2: Xmm);

	/// Using dword indices specified in vm32x, gather single-precision FP values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vgatherdps(&mut self, arg0: Ymm, arg1: M32, arg2: Ymm);

	/// Using qword indices specified in vm64x, gather double-precision FP values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vgatherqpd(&mut self, arg0: Xmm, arg1: M64, arg2: Xmm);

	/// Using qword indices specified in vm64y, gather double-precision FP values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vgatherqpd(&mut self, arg0: Ymm, arg1: M64, arg2: Ymm);

	/// Using qword indices specified in vm64x, gather single-precision FP values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vgatherqps(&mut self, arg0: Xmm, arg1: M64, arg2: Xmm);

	/// Using qword indices specified in vm64y, gather single-precision FP values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	void vgatherqps_1(const Xmm& arg0, arg1: M64, arg2: Xmm);

	/// Horizontal add packed double-precision floating-point values from xmm2 and xmm3/mem.
	fn vhaddpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Horizontal add packed double-precision floating-point values from xmm2 and xmm3/mem.
	fn vhaddpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Horizontal add packed double-precision floating-point values from ymm2 and ymm3/mem.
	fn vhaddpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Horizontal add packed double-precision floating-point values from ymm2 and ymm3/mem.
	fn vhaddpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Horizontal add packed single-precision floating-point values from xmm2 and xmm3/mem.
	fn vhaddps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Horizontal add packed single-precision floating-point values from xmm2 and xmm3/mem.
	fn vhaddps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Horizontal add packed single-precision floating-point values from ymm2 and ymm3/mem.
	fn vhaddps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Horizontal add packed single-precision floating-point values from ymm2 and ymm3/mem.
	fn vhaddps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Horizontal subtract packed double-precision floating-point values from xmm2 and xmm3/mem.
	fn vhsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Horizontal subtract packed double-precision floating-point values from xmm2 and xmm3/mem.
	fn vhsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Horizontal subtract packed double-precision floating-point values from ymm2 and ymm3/mem.
	fn vhsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Horizontal subtract packed double-precision floating-point values from ymm2 and ymm3/mem.
	fn vhsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Horizontal subtract packed single-precision floating-point values from xmm2 and xmm3/mem.
	fn vhsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Horizontal subtract packed single-precision floating-point values from xmm2 and xmm3/mem.
	fn vhsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Horizontal subtract packed single-precision floating-point values from ymm2 and ymm3/mem.
	fn vhsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Horizontal subtract packed single-precision floating-point values from ymm2 and ymm3/mem.
	fn vhsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Insert a single precision floating-point value selected by imm8 from xmm3/m128 into ymm2 at the specified destination element specified by imm8 and zero out destination elements in ymm1 as indicated in imm8.
	fn vinsertf128(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128, arg3: Imm8);

	/// Insert a single precision floating-point value selected by imm8 from xmm3/m128 into ymm2 at the specified destination element specified by imm8 and zero out destination elements in ymm1 as indicated in imm8.
	fn vinsertf128(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm, arg3: Imm8);

	/// Insert 128-bits of integer data from xmm3/mem and the remaining values from ymm2 into ymm1.
	fn vinserti128(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128, arg3: Imm8);

	/// Insert 128-bits of integer data from xmm3/mem and the remaining values from ymm2 into ymm1.
	fn vinserti128(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm, arg3: Imm8);

	/// Insert a single precision floating point value selected by imm8 from xmm3/m32 and merge into xmm2 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.
	fn vinsertps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32, arg3: Imm8);

	/// Insert a single precision floating point value selected by imm8 from xmm3/m32 and merge into xmm2 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.
	fn vinsertps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Load unaligned packed integer values from mem to xmm1.
	fn vlddqu(&mut self, arg0: Xmm, arg1: M128);

	/// Load unaligned packed integer values from mem to ymm1.
	fn vlddqu(&mut self, arg0: Ymm, arg1: M256);

	/// Load MXCSR register from m32.
	fn vldmxcsr(&mut self, arg0: M32);

	/// Selectively write bytes from xmm1 to memory location using the byte mask in xmm2.
	/// The default memory location is specified by DS:DI/EDI/RDI.
	fn vmaskmovdqu(&mut self, arg0: Xmm, arg1: Xmm);

	/// Conditionally store packed double-precision values from xmm2 using mask in xmm1.
	fn vmaskmovpd(&mut self, arg0: M128, arg1: Xmm, arg2: Xmm);

	/// Conditionally store packed double-precision values from ymm2 using mask in ymm1.
	fn vmaskmovpd(&mut self, arg0: M256, arg1: Ymm, arg2: Ymm);

	/// Conditionally load packed double-precision values from m128 using mask in xmm2 and store in xmm1.
	fn vmaskmovpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Conditionally load packed double-precision values from m256 using mask in ymm2 and store in ymm1.
	fn vmaskmovpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Conditionally store packed single-precision values from xmm2 using mask in xmm1.
	fn vmaskmovps(&mut self, arg0: M128, arg1: Xmm, arg2: Xmm);

	/// Conditionally store packed single-precision values from ymm2 using mask in ymm1.
	fn vmaskmovps(&mut self, arg0: M256, arg1: Ymm, arg2: Ymm);

	/// Conditionally load packed single-precision values from m128 using mask in xmm2 and store in xmm1.
	fn vmaskmovps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Conditionally load packed single-precision values from m256 using mask in ymm2 and store in ymm1.
	fn vmaskmovps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the maximum double-precision floating-point values between xmm2 and xmm3/mem.
	fn vmaxpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the maximum double-precision floating-point values between xmm2 and xmm3/mem.
	fn vmaxpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the maximum packed double-precision floating-point values between ymm2 and ymm3/mem.
	fn vmaxpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the maximum packed double-precision floating-point values between ymm2 and ymm3/mem.
	fn vmaxpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the maximum single-precision floating-point values between xmm2 and xmm3/mem.
	fn vmaxps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the maximum single-precision floating-point values between xmm2 and xmm3/mem.
	fn vmaxps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the maximum single double-precision floating-point values between ymm2 and ymm3/mem.
	fn vmaxps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the maximum single double-precision floating-point values between ymm2 and ymm3/mem.
	fn vmaxps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the maximum scalar double-precision floating-point value between xmm3/mem64 and xmm2.
	fn vmaxsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Return the maximum scalar double-precision floating-point value between xmm3/mem64 and xmm2.
	fn vmaxsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the maximum scalar single-precision floating-point value between xmm3/mem32 and xmm2.
	fn vmaxss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Return the maximum scalar single-precision floating-point value between xmm3/mem32 and xmm2.
	fn vmaxss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the minimum double-precision floating-point values between xmm2 and xmm3/mem.
	fn vminpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the minimum double-precision floating-point values between xmm2 and xmm3/mem.
	fn vminpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the minimum packed double-precision floating-point values between ymm2 and ymm3/mem.
	fn vminpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the minimum packed double-precision floating-point values between ymm2 and ymm3/mem.
	fn vminpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the minimum single-precision floating-point values between xmm2 and xmm3/mem.
	fn vminps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the minimum single-precision floating-point values between xmm2 and xmm3/mem.
	fn vminps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the minimum single double-precision floating-point values between ymm2 and ymm3/mem.
	fn vminps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the minimum single double-precision floating-point values between ymm2 and ymm3/mem.
	fn vminps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the minimum scalar double precision floating-point value between xmm3/mem64 and xmm2.
	fn vminsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Return the minimum scalar double precision floating-point value between xmm3/mem64 and xmm2.
	fn vminsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the minimum scalar single precision floating-point value between xmm3/mem32 and xmm2.
	fn vminss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Return the minimum scalar single precision floating-point value between xmm3/mem32 and xmm2.
	fn vminss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
	fn vmovapd(&mut self, arg0: M128, arg1: Xmm);

	/// Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.
	fn vmovapd(&mut self, arg0: M256, arg1: Ymm);

	/// Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
	fn vmovapd(&mut self, arg0: Xmm, arg1: M128);

	/// Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
	fn vmovapd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
	void vmovapd_1(const Xmm& arg0, arg1: Xmm);

	/// Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.
	fn vmovapd(&mut self, arg0: Ymm, arg1: M256);

	/// Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.
	fn vmovapd(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.
	void vmovapd_1(const Ymm& arg0, arg1: Ymm);

	/// Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
	fn vmovaps(&mut self, arg0: M128, arg1: Xmm);

	/// Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.
	fn vmovaps(&mut self, arg0: M256, arg1: Ymm);

	/// Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
	fn vmovaps(&mut self, arg0: Xmm, arg1: M128);

	/// Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
	fn vmovaps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
	void vmovaps_1(const Xmm& arg0, arg1: Xmm);

	/// Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.
	fn vmovaps(&mut self, arg0: Ymm, arg1: M256);

	/// Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.
	fn vmovaps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.
	void vmovaps_1(const Ymm& arg0, arg1: Ymm);

	/// Move doubleword from xmm1 register to r/m32.
	fn vmovd(&mut self, arg0: M32, arg1: Xmm);

	/// Move doubleword from xmm1 register to r/m32.
	fn vmovd(&mut self, arg0: R32, arg1: Xmm);

	/// Move doubleword from r/m32 to xmm1.
	fn vmovd(&mut self, arg0: Xmm, arg1: M32);

	/// Move doubleword from r/m32 to xmm1.
	fn vmovd(&mut self, arg0: Xmm, arg1: R32);

	/// Move double-precision floating-point values from xmm2/mem and duplicate into xmm1.
	fn vmovddup(&mut self, arg0: Xmm, arg1: M64);

	/// Move double-precision floating-point values from xmm2/mem and duplicate into xmm1.
	fn vmovddup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move even index double-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovddup(&mut self, arg0: Ymm, arg1: M256);

	/// Move even index double-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovddup(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move aligned packed integer values from xmm1 to xmm2/mem.
	fn vmovdqa(&mut self, arg0: M128, arg1: Xmm);

	/// Move aligned packed integer values from ymm1 to ymm2/mem.
	fn vmovdqa(&mut self, arg0: M256, arg1: Ymm);

	/// Move aligned packed integer values from xmm2/mem to xmm1.
	fn vmovdqa(&mut self, arg0: Xmm, arg1: M128);

	/// Move aligned packed integer values from xmm2/mem to xmm1.
	fn vmovdqa(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move aligned packed integer values from xmm1 to xmm2/mem.
	void vmovdqa_1(const Xmm& arg0, arg1: Xmm);

	/// Move aligned packed integer values from ymm2/mem to ymm1.
	fn vmovdqa(&mut self, arg0: Ymm, arg1: M256);

	/// Move aligned packed integer values from ymm2/mem to ymm1.
	fn vmovdqa(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move aligned packed integer values from ymm1 to ymm2/mem.
	void vmovdqa_1(const Ymm& arg0, arg1: Ymm);

	/// Move unaligned packed integer values from xmm1 to xmm2/mem.
	fn vmovdqu(&mut self, arg0: M128, arg1: Xmm);

	/// Move unaligned packed integer values from ymm1 to ymm2/mem.
	fn vmovdqu(&mut self, arg0: M256, arg1: Ymm);

	/// Move unaligned packed integer values from xmm2/mem to xmm1.
	fn vmovdqu(&mut self, arg0: Xmm, arg1: M128);

	/// Move unaligned packed integer values from xmm2/mem to xmm1.
	fn vmovdqu(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move unaligned packed integer values from xmm1 to xmm2/mem.
	void vmovdqu_1(const Xmm& arg0, arg1: Xmm);

	/// Move unaligned packed integer values from ymm2/mem to ymm1.
	fn vmovdqu(&mut self, arg0: Ymm, arg1: M256);

	/// Move unaligned packed integer values from ymm2/mem to ymm1.
	fn vmovdqu(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move unaligned packed integer values from ymm1 to ymm2/mem.
	void vmovdqu_1(const Ymm& arg0, arg1: Ymm);

	/// Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2.
	fn vmovhlps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Move double-precision floating-point values from high quadword of xmm1 to m64.
	fn vmovhpd(&mut self, arg0: M64, arg1: Xmm);

	/// Merge double-precision floating-point value from m64 and the low quadword of xmm1.
	fn vmovhpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Move two packed single-precision floating-point values from high quadword of xmm1to m64.
	fn vmovhps(&mut self, arg0: M64, arg1: Xmm);

	/// Merge two packed single-precision floating-point values from m64 and the low quadword of xmm1.
	fn vmovhps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2.
	fn vmovlhps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Move double-precision floating-point values from low quadword of xmm1 to m64.
	fn vmovlpd(&mut self, arg0: M64, arg1: Xmm);

	/// Merge double-precision floating-point value from m64 and the high quadword of xmm1.
	fn vmovlpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Move two packed single-precision floating-point values from low quadword of xmm1 to m64.
	fn vmovlps(&mut self, arg0: M64, arg1: Xmm);

	/// Merge two packed single-precision floating-point values from m64 and the high quadword of xmm1.
	fn vmovlps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Extract 2-bit sign mask from xmm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskpd(&mut self, arg0: R32, arg1: Xmm);

	/// Extract 4-bit sign mask from ymm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskpd(&mut self, arg0: R32, arg1: Ymm);

	/// Extract 2-bit sign mask from xmm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskpd(&mut self, arg0: R64, arg1: Xmm);

	/// Extract 4-bit sign mask from ymm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskpd(&mut self, arg0: R64, arg1: Ymm);

	/// Extract 4-bit sign mask from xmm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskps(&mut self, arg0: R32, arg1: Xmm);

	/// Extract 8-bit sign mask from ymm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskps(&mut self, arg0: R32, arg1: Ymm);

	/// Extract 4-bit sign mask from xmm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskps(&mut self, arg0: R64, arg1: Xmm);

	/// Extract 8-bit sign mask from ymm2 and store in reg.
	/// The upper bits of r32 or r64 are zeroed.
	fn vmovmskps(&mut self, arg0: R64, arg1: Ymm);

	/// Move packed integer values in xmm1 to m128 using non-temporal hint.
	fn vmovntdq(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed integer values in ymm1 to m256 using non-temporal hint.
	fn vmovntdq(&mut self, arg0: M256, arg1: Ymm);

	/// Move double quadword from m128 to xmm using non-temporal hint if WC memory type.
	fn vmovntdqa(&mut self, arg0: Xmm, arg1: M128);

	/// Move 256-bit data from m256 to ymm using non-temporal hint if WC memory type.
	fn vmovntdqa(&mut self, arg0: Ymm, arg1: M256);

	/// Move packed double-precision values in xmm1 to m128 using non-temporal hint.
	fn vmovntpd(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed double-precision values in ymm1 to m256 using non-temporal hint.
	fn vmovntpd(&mut self, arg0: M256, arg1: Ymm);

	/// Move packed single-precision values xmm1 to mem using non-temporal hint.
	fn vmovntps(&mut self, arg0: M128, arg1: Xmm);

	/// Move packed single-precision values ymm1 to mem using non-temporal hint.
	fn vmovntps(&mut self, arg0: M256, arg1: Ymm);

	/// Move quadword from xmm1 register to r/m64.
	fn vmovq(&mut self, arg0: M64, arg1: Xmm);

	/// Move quadword from xmm2 register to xmm1/m64.
	void vmovq_1(const M64& arg0, arg1: Xmm);

	/// Move quadword from xmm1 register to r/m64.
	fn vmovq(&mut self, arg0: R64, arg1: Xmm);

	/// Move quadword from r/m64 to xmm1.
	fn vmovq(&mut self, arg0: Xmm, arg1: M64);

	/// Load quadword from m64 to xmm1.
	void vmovq_1(const Xmm& arg0, arg1: M64);

	/// Move quadword from r/m64 to xmm1.
	fn vmovq(&mut self, arg0: Xmm, arg1: R64);

	/// Move quadword from xmm2 to xmm1.
	fn vmovq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move quadword from xmm2 register to xmm1/m64.
	void vmovq_1(const Xmm& arg0, arg1: Xmm);

	/// Move scalar double-precision floating-point value from xmm1 register to m64.
	fn vmovsd(&mut self, arg0: M64, arg1: Xmm);

	/// Load scalar double-precision floating-point value from m64 to xmm1 register.
	fn vmovsd(&mut self, arg0: Xmm, arg1: M64);

	/// Merge scalar double-precision floating-point value from xmm2 and xmm3 to xmm1 register.
	fn vmovsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1.
	void vmovsd_1(const Xmm& arg0, arg1: Xmm, arg2: Xmm);

	/// Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.
	fn vmovshdup(&mut self, arg0: Xmm, arg1: M128);

	/// Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.
	fn vmovshdup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move odd index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovshdup(&mut self, arg0: Ymm, arg1: M256);

	/// Move odd index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovshdup(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.
	fn vmovsldup(&mut self, arg0: Xmm, arg1: M128);

	/// Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.
	fn vmovsldup(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move even index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovsldup(&mut self, arg0: Ymm, arg1: M256);

	/// Move even index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.
	fn vmovsldup(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move scalar single-precision floating-point value from xmm1 register to m32.
	fn vmovss(&mut self, arg0: M32, arg1: Xmm);

	/// Load scalar single-precision floating-point value from m32 to xmm1 register.
	fn vmovss(&mut self, arg0: Xmm, arg1: M32);

	/// Merge scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register.
	fn vmovss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register.
	void vmovss_1(const Xmm& arg0, arg1: Xmm, arg2: Xmm);

	/// Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
	fn vmovupd(&mut self, arg0: M128, arg1: Xmm);

	/// Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.
	fn vmovupd(&mut self, arg0: M256, arg1: Ymm);

	/// Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
	fn vmovupd(&mut self, arg0: Xmm, arg1: M128);

	/// Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
	fn vmovupd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
	void vmovupd_1(const Xmm& arg0, arg1: Xmm);

	/// Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.
	fn vmovupd(&mut self, arg0: Ymm, arg1: M256);

	/// Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.
	fn vmovupd(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.
	void vmovupd_1(const Ymm& arg0, arg1: Ymm);

	/// Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.
	fn vmovups(&mut self, arg0: M128, arg1: Xmm);

	/// Move unaligned packed single-precision floating-point from ymm1 to ymm2/mem.
	fn vmovups(&mut self, arg0: M256, arg1: Ymm);

	/// Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.
	fn vmovups(&mut self, arg0: Xmm, arg1: M128);

	/// Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.
	fn vmovups(&mut self, arg0: Xmm, arg1: Xmm);

	/// Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.
	void vmovups_1(const Xmm& arg0, arg1: Xmm);

	/// Move unaligned packed single-precision floating-point from ymm2/mem to ymm1.
	fn vmovups(&mut self, arg0: Ymm, arg1: M256);

	/// Move unaligned packed single-precision floating-point from ymm2/mem to ymm1.
	fn vmovups(&mut self, arg0: Ymm, arg1: Ymm);

	/// Move unaligned packed single-precision floating-point from ymm1 to ymm2/mem.
	void vmovups_1(const Ymm& arg0, arg1: Ymm);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and xmm3/m128 and writes the results in xmm1.
	/// Starting offsets within xmm2 and xmm3/m128 are determined by imm8.
	fn vmpsadbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and xmm3/m128 and writes the results in xmm1.
	/// Starting offsets within xmm2 and xmm3/m128 are determined by imm8.
	fn vmpsadbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1.
	/// Starting offsets within ymm2 and xmm3/m128 are determined by imm8.
	fn vmpsadbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1.
	/// Starting offsets within ymm2 and xmm3/m128 are determined by imm8.
	fn vmpsadbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Multiply packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vmulpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vmulpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vmulpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vmulpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vmulps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.
	fn vmulps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vmulps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.
	fn vmulps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the low double-precision floating-point value in xmm3/mem64 by low double precision floating-point value in xmm2.
	fn vmulsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Multiply the low double-precision floating-point value in xmm3/mem64 by low double precision floating-point value in xmm2.
	fn vmulsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the low single-precision floating-point value in xmm3/mem by the low single-precision floating-point value in xmm2.
	fn vmulss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Multiply the low single-precision floating-point value in xmm3/mem by the low single-precision floating-point value in xmm2.
	fn vmulss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vorpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vorpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vorpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vorpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vorps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vorps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vorps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vorps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsb(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsb(&mut self, arg0: Ymm, arg1: M256);

	/// Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsb(&mut self, arg0: Ymm, arg1: Ymm);

	/// Compute the absolute value of 32- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsd(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of 32- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsd(&mut self, arg0: Ymm, arg1: M256);

	/// Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsd(&mut self, arg0: Ymm, arg1: Ymm);

	/// Compute the absolute value of 16- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsw(&mut self, arg0: Xmm, arg1: M128);

	/// Compute the absolute value of 16- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
	fn vpabsw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsw(&mut self, arg0: Ymm, arg1: M256);

	/// Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
	fn vpabsw(&mut self, arg0: Ymm, arg1: Ymm);

	/// Converts 4 packed signed doubleword integers from xmm2 and from xmm3/m128 into 8 packed signed word integers in xmm1 using signed saturation.
	fn vpackssdw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Converts 4 packed signed doubleword integers from xmm2 and from xmm3/m128 into 8 packed signed word integers in xmm1 using signed saturation.
	fn vpackssdw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Converts 8 packed signed doubleword integers from ymm2 and from ymm3/m256 into 16 packed signed word integers in ymm1using signed saturation.
	fn vpackssdw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Converts 8 packed signed doubleword integers from ymm2 and from ymm3/m256 into 16 packed signed word integers in ymm1using signed saturation.
	fn vpackssdw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Converts 8 packed signed word integers from xmm2 and from xmm3/m128 into 16 packed signed byte integers in xmm1 using signed saturation.
	fn vpacksswb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Converts 8 packed signed word integers from xmm2 and from xmm3/m128 into 16 packed signed byte integers in xmm1 using signed saturation.
	fn vpacksswb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Converts 16 packed signed word integers from ymm2 and from ymm3/m256 into 32 packed signed byte integers in ymm1 using signed saturation.
	fn vpacksswb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Converts 16 packed signed word integers from ymm2 and from ymm3/m256 into 32 packed signed byte integers in ymm1 using signed saturation.
	fn vpacksswb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Convert 4 packed signed doubleword integers from xmm2 and 4 packed signed doubleword integers from xmm3/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
	fn vpackusdw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Convert 4 packed signed doubleword integers from xmm2 and 4 packed signed doubleword integers from xmm3/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
	fn vpackusdw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Convert 8 packed signed doubleword integers from ymm2 and 8 packed signed doubleword integers from ymm3/m128 into 16 packed unsigned word integers in ymm1 using unsigned saturation.
	fn vpackusdw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Convert 8 packed signed doubleword integers from ymm2 and 8 packed signed doubleword integers from ymm3/m128 into 16 packed unsigned word integers in ymm1 using unsigned saturation.
	fn vpackusdw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Converts 8 signed word integers from xmm2 and 8 signed word integers from xmm3/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
	fn vpackuswb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Converts 8 signed word integers from xmm2 and 8 signed word integers from xmm3/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
	fn vpackuswb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Converts 16 signed word integers from ymm2 And 16 signed word integers from ymm3/m256 into 32 unsigned byte integers in ymm1 using unsigned saturation.
	fn vpackuswb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Converts 16 signed word integers from ymm2 And 16 signed word integers from ymm3/m256 into 32 unsigned byte integers in ymm1 using unsigned saturation.
	fn vpackuswb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed byte integers from xmm3/m128 and xmm2.
	fn vpaddb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed byte integers from xmm3/m128 and xmm2.
	fn vpaddb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1.
	fn vpaddb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1.
	fn vpaddb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed doubleword integers from xmm3/m128 and xmm2.
	fn vpaddd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed doubleword integers from xmm3/m128 and xmm2.
	fn vpaddd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed doubleword integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed doubleword integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed quadword integers xmm3/m128 and xmm2.
	fn vpaddq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed quadword integers xmm3/m128 and xmm2.
	fn vpaddq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed quadword integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed quadword integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed signed byte integers from xmm3/m128 and xmm2 saturate the results.
	fn vpaddsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed signed byte integers from xmm3/m128 and xmm2 saturate the results.
	fn vpaddsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed signed word integers from xmm3/m128 and xmm2 and saturate the results.
	fn vpaddsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed signed word integers from xmm3/m128 and xmm2 and saturate the results.
	fn vpaddsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed unsigned byte integers from xmm3/m128 to xmm2 and saturate the results.
	fn vpaddusb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed unsigned byte integers from xmm3/m128 to xmm2 and saturate the results.
	fn vpaddusb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddusb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddusb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed unsigned word integers from xmm3/m128 to xmm2 and saturate the results.
	fn vpaddusw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed unsigned word integers from xmm3/m128 to xmm2 and saturate the results.
	fn vpaddusw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddusw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
	fn vpaddusw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add packed word integers from xmm3/m128 and xmm2.
	fn vpaddw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add packed word integers from xmm3/m128 and xmm2.
	fn vpaddw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add packed word integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add packed word integers from ymm2, ymm3/m256 and store in ymm1.
	fn vpaddw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Concatenate xmm2 and xmm3/m128, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.
	fn vpalignr(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Concatenate xmm2 and xmm3/m128, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.
	fn vpalignr(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16-byte results are stored in ymm1.
	fn vpalignr(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16-byte results are stored in ymm1.
	fn vpalignr(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Bitwise AND of xmm3/m128 and xmm.
	fn vpand(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Bitwise AND of xmm3/m128 and xmm.
	fn vpand(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Bitwise AND of ymm2, and ymm3/m256 and store result in ymm1.
	fn vpand(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Bitwise AND of ymm2, and ymm3/m256 and store result in ymm1.
	fn vpand(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Bitwise AND NOT of xmm3/m128 and xmm2.
	fn vpandn(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Bitwise AND NOT of xmm3/m128 and xmm2.
	fn vpandn(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Bitwise AND NOT of ymm2, and ymm3/m256 and store result in ymm1.
	fn vpandn(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Bitwise AND NOT of ymm2, and ymm3/m256 and store result in ymm1.
	fn vpandn(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Average packed unsigned byte integers from xmm3/m128 and xmm2 with rounding.
	fn vpavgb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Average packed unsigned byte integers from xmm3/m128 and xmm2 with rounding.
	fn vpavgb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1.
	fn vpavgb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1.
	fn vpavgb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Average packed unsigned word integers from xmm3/m128 and xmm2 with rounding.
	fn vpavgw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Average packed unsigned word integers from xmm3/m128 and xmm2 with rounding.
	fn vpavgw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1.
	fn vpavgw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1.
	fn vpavgw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Select dwords from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.
	fn vpblendd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Select dwords from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.
	fn vpblendd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Select dwords from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.
	fn vpblendd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Select dwords from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.
	fn vpblendd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Select byte values from xmm2 and xmm3/m128 using mask bits in the specified mask register, xmm4, and store the values into xmm1.
	fn vpblendvb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Xmm);

	/// Select byte values from xmm2 and xmm3/m128 using mask bits in the specified mask register, xmm4, and store the values into xmm1.
	fn vpblendvb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Xmm);

	/// Select byte values from ymm2 and ymm3/m256 from mask specified in the high bit of each byte in ymm4 and store the values into ymm1.
	fn vpblendvb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Ymm);

	/// Select byte values from ymm2 and ymm3/m256 from mask specified in the high bit of each byte in ymm4 and store the values into ymm1.
	fn vpblendvb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Ymm);

	/// Select words from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.
	fn vpblendw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Select words from xmm2 and xmm3/m128 from mask specified in imm8 and store the values into xmm1.
	fn vpblendw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Select words from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.
	fn vpblendw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Select words from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1.
	fn vpblendw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Broadcast a byte integer in the source operand to sixteen locations in xmm1.
	fn vpbroadcastb(&mut self, arg0: Xmm, arg1: M8);

	/// Broadcast a byte integer in the source operand to sixteen locations in xmm1.
	fn vpbroadcastb(&mut self, arg0: Xmm, arg1: Xmm);

	/// Broadcast a byte integer in the source operand to thirty two locations in ymm1.
	fn vpbroadcastb(&mut self, arg0: Ymm, arg1: M8);

	/// Broadcast a byte integer in the source operand to thirty two locations in ymm1.
	fn vpbroadcastb(&mut self, arg0: Ymm, arg1: Xmm);

	/// Broadcast a dword integer in the source operand to four locations in xmm1.
	fn vpbroadcastd(&mut self, arg0: Xmm, arg1: M32);

	/// Broadcast a dword integer in the source operand to four locations in xmm1.
	fn vpbroadcastd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Broadcast a dword integer in the source operand to eight locations in ymm1.
	fn vpbroadcastd(&mut self, arg0: Ymm, arg1: M32);

	/// Broadcast a dword integer in the source operand to eight locations in ymm1.
	fn vpbroadcastd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Broadcast a qword element in mem to two locations in xmm1.
	fn vpbroadcastq(&mut self, arg0: Xmm, arg1: M64);

	/// Broadcast a qword element in mem to two locations in xmm1.
	fn vpbroadcastq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Broadcast a qword element in mem to four locations in ymm1.
	fn vpbroadcastq(&mut self, arg0: Ymm, arg1: M64);

	/// Broadcast a qword element in mem to four locations in ymm1.
	fn vpbroadcastq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Broadcast a word integer in the source operand to eight locations in xmm1.
	fn vpbroadcastw(&mut self, arg0: Xmm, arg1: M16);

	/// Broadcast a word integer in the source operand to eight locations in xmm1.
	fn vpbroadcastw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Broadcast a word integer in the source operand to sixteen locations in ymm1.
	fn vpbroadcastw(&mut self, arg0: Ymm, arg1: M16);

	/// Broadcast a word integer in the source operand to sixteen locations in ymm1.
	fn vpbroadcastw(&mut self, arg0: Ymm, arg1: Xmm);

	/// Carry-less multiplication of one quadword of xmm2 by one quadword of xmm3/m128, stores the 128-bit result in xmm1.
	/// The immediate is used to determine which quadwords of xmm2 and xmm3/m128 should be used.
	fn vpclmulqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Carry-less multiplication of one quadword of xmm2 by one quadword of xmm3/m128, stores the 128-bit result in xmm1.
	/// The immediate is used to determine which quadwords of xmm2 and xmm3/m128 should be used.
	fn vpclmulqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Compare packed bytes in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed bytes in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed bytes in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed bytes in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed doublewords in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed doublewords in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed doublewords in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed doublewords in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed quadwords in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed quadwords in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed quadwords in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed quadwords in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed words in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed words in xmm3/m128 and xmm2 for equality.
	fn vpcmpeqw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed words in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed words in ymm3/m256 and ymm2 for equality.
	fn vpcmpeqw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.
	fn vpcmpestri(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.
	fn vpcmpestri(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.
	fn vpcmpestrm(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0.
	fn vpcmpestrm(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed doubleword integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed doubleword integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed doubleword integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed doubleword integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed qwords in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed qwords in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed qwords in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed qwords in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed word integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed word integers in xmm2 and xmm3/m128 for greater than.
	fn vpcmpgtw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed word integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed word integers in ymm2 and ymm3/m256 for greater than.
	fn vpcmpgtw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.
	fn vpcmpistri(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.
	fn vpcmpistri(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating a Mask, and storing the result in XMM0.
	fn vpcmpistrm(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Perform a packed comparison of string data with implicit lengths, generating a Mask, and storing the result in XMM0.
	fn vpcmpistrm(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Permute 128-bit floating-point fields in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
	fn vperm2f128(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Permute 128-bit floating-point fields in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
	fn vperm2f128(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
	fn vperm2i128(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
	fn vperm2i128(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Permute doublewords in ymm3/m256 using indexes in ymm2 and store the result in ymm1.
	fn vpermd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Permute doublewords in ymm3/m256 using indexes in ymm2 and store the result in ymm1.
	fn vpermd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Permute double-precision floating-point values in xmm2/mem using controls from imm8.
	fn vpermilpd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Permute double-precision floating-point values in xmm2/mem using controls from imm8.
	fn vpermilpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Permute double-precision floating-point values in xmm2 using controls from xmm3/mem and store result in xmm1.
	fn vpermilpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Permute double-precision floating-point values in xmm2 using controls from xmm3/mem and store result in xmm1.
	fn vpermilpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Permute double-precision floating-point values in ymm2/mem using controls from imm8.
	fn vpermilpd(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Permute double-precision floating-point values in ymm2/mem using controls from imm8.
	fn vpermilpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Permute double-precision floating-point values in ymm2 using controls from ymm3/mem and store result in ymm1.
	fn vpermilpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Permute double-precision floating-point values in ymm2 using controls from ymm3/mem and store result in ymm1.
	fn vpermilpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Permute single-precision floating-point values in xmm2/mem using controls from imm8 and store result in xmm1.
	fn vpermilps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Permute single-precision floating-point values in xmm2/mem using controls from imm8 and store result in xmm1.
	fn vpermilps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Permute single-precision floating-point values in xmm2 using controls from xmm3/mem and store result in xmm1.
	fn vpermilps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Permute single-precision floating-point values in xmm2 using controls from xmm3/mem and store result in xmm1.
	fn vpermilps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Permute single-precision floating-point values in ymm2/mem using controls from imm8 and store result in ymm1.
	fn vpermilps(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Permute single-precision floating-point values in ymm2/mem using controls from imm8 and store result in ymm1.
	fn vpermilps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Permute single-precision floating-point values in ymm2 using controls from ymm3/mem and store result in ymm1.
	fn vpermilps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Permute single-precision floating-point values in ymm2 using controls from ymm3/mem and store result in ymm1.
	fn vpermilps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Permute double-precision floating-point elements in ymm2/m256 using indexes in imm8 and store the result in ymm1.
	fn vpermpd(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Permute double-precision floating-point elements in ymm2/m256 using indexes in imm8 and store the result in ymm1.
	fn vpermpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Permute single-precision floating-point elements in ymm3/m256 using indexes in ymm2 and store the result in ymm1.
	fn vpermps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Permute single-precision floating-point elements in ymm3/m256 using indexes in ymm2 and store the result in ymm1.
	fn vpermps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Permute qwords in ymm2/m256 using indexes in imm8 and store the result in ymm1.
	fn vpermq(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Permute qwords in ymm2/m256 using indexes in imm8 and store the result in ymm1.
	fn vpermq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8.
	/// The upper bits of r64/r32 is filled with.
	fn vpextrb(&mut self, arg0: M8, arg1: Xmm, arg2: Imm8);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8.
	/// The upper bits of r64/r32 is filled with.
	fn vpextrb(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8.
	/// The upper bits of r64/r32 is filled with.
	fn vpextrb(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
	fn vpextrd(&mut self, arg0: M32, arg1: Xmm, arg2: Imm8);

	/// Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
	fn vpextrd(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
	fn vpextrq(&mut self, arg0: M64, arg1: Xmm, arg2: Imm8);

	/// Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
	fn vpextrq(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16.
	/// The upper bits of r64/r32 is filled with zeros.
	fn vpextrw(&mut self, arg0: M16, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm1 and move it to reg, bits 15:0.
	/// Zero-extend the result.
	/// The upper bits of r64/r32 is filled with zeros.
	fn vpextrw(&mut self, arg0: R32, arg1: Xmm, arg2: Imm8);

	/// Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16.
	/// The upper bits of r64/r32 is filled with zeros.
	void vpextrw_1(const R32& arg0, arg1: Xmm, arg2: Imm8);

	/// Extract the word specified by imm8 from xmm1 and move it to reg, bits 15:0.
	/// Zero-extend the result.
	/// The upper bits of r64/r32 is filled with zeros.
	fn vpextrw(&mut self, arg0: R64, arg1: Xmm, arg2: Imm8);

	/// Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16.
	/// The upper bits of r64/r32 is filled with zeros.
	void vpextrw_1(const R64& arg0, arg1: Xmm, arg2: Imm8);

	/// Using dword indices specified in vm32x, gather dword values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vpgatherdd(&mut self, arg0: Xmm, arg1: M32, arg2: Xmm);

	/// Using dword indices specified in vm32y, gather dword from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vpgatherdd(&mut self, arg0: Ymm, arg1: M32, arg2: Ymm);

	/// Using dword indices specified in vm32x, gather qword values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vpgatherdq(&mut self, arg0: Xmm, arg1: M32, arg2: Xmm);

	/// Using dword indices specified in vm32x, gather qword values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vpgatherdq(&mut self, arg0: Ymm, arg1: M32, arg2: Ymm);

	/// Using qword indices specified in vm64x, gather dword values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vpgatherqd(&mut self, arg0: Xmm, arg1: M64, arg2: Xmm);

	/// Using qword indices specified in vm64y, gather dword values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	void vpgatherqd_1(const Xmm& arg0, arg1: M64, arg2: Xmm);

	/// Using qword indices specified in vm64x, gather qword values from memory conditioned on mask specified by xmm2.
	/// Conditionally gathered elements are merged into xmm1.
	fn vpgatherqq(&mut self, arg0: Xmm, arg1: M64, arg2: Xmm);

	/// Using qword indices specified in vm64y, gather qword values from memory conditioned on mask specified by ymm2.
	/// Conditionally gathered elements are merged into ymm1.
	fn vpgatherqq(&mut self, arg0: Ymm, arg1: M64, arg2: Ymm);

	/// Add 32-bit integers horizontally, pack to xmm1.
	fn vphaddd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add 32-bit integers horizontally, pack to xmm1.
	fn vphaddd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add 32-bit signed integers horizontally, pack to ymm1.
	fn vphaddd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add 32-bit signed integers horizontally, pack to ymm1.
	fn vphaddd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
	fn vphaddsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
	fn vphaddsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add 16-bit signed integers horizontally, pack saturated integers to ymm1.
	fn vphaddsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add 16-bit signed integers horizontally, pack saturated integers to ymm1.
	fn vphaddsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Add 16-bit integers horizontally, pack to xmm1.
	fn vphaddw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Add 16-bit integers horizontally, pack to xmm1.
	fn vphaddw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Add 16-bit signed integers horizontally, pack to ymm1.
	fn vphaddw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Add 16-bit signed integers horizontally, pack to ymm1.
	fn vphaddw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.
	fn vphminposuw(&mut self, arg0: Xmm, arg1: M128);

	/// Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1.
	fn vphminposuw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Subtract 32-bit signed integers horizontally, pack to xmm1.
	fn vphsubd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract 32-bit signed integers horizontally, pack to xmm1.
	fn vphsubd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract 32-bit signed integers horizontally, pack to ymm1.
	fn vphsubd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract 32-bit signed integers horizontally, pack to ymm1.
	fn vphsubd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to xmm1.
	fn vphsubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to xmm1.
	fn vphsubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to ymm1.
	fn vphsubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract 16-bit signed integer horizontally, pack saturated integers to ymm1.
	fn vphsubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract 16-bit signed integers horizontally, pack to xmm1.
	fn vphsubw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract 16-bit signed integers horizontally, pack to xmm1.
	fn vphsubw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract 16-bit signed integers horizontally, pack to ymm1.
	fn vphsubw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract 16-bit signed integers horizontally, pack to ymm1.
	fn vphsubw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
	fn vpinsrb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M8, arg3: Imm8);

	/// Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
	fn vpinsrb(&mut self, arg0: Xmm, arg1: Xmm, arg2: R32, arg3: Imm8);

	/// Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
	fn vpinsrd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32, arg3: Imm8);

	/// Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
	fn vpinsrd(&mut self, arg0: Xmm, arg1: Xmm, arg2: R32, arg3: Imm8);

	/// Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
	fn vpinsrq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64, arg3: Imm8);

	/// Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
	fn vpinsrq(&mut self, arg0: Xmm, arg1: Xmm, arg2: R64, arg3: Imm8);

	/// Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
	fn vpinsrw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M16, arg3: Imm8);

	/// Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
	fn vpinsrw(&mut self, arg0: Xmm, arg1: Xmm, arg2: R32, arg3: Imm8);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1.
	fn vpmaddubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1.
	fn vpmaddubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to ymm1.
	fn vpmaddubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to ymm1.
	fn vpmaddubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the packed word integers in xmm2 by the packed word integers in xmm3/m128, add adjacent doubleword results, and store in xmm1.
	fn vpmaddwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply the packed word integers in xmm2 by the packed word integers in xmm3/m128, add adjacent doubleword results, and store in xmm1.
	fn vpmaddwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the packed word integers in ymm2 by the packed word integers in ymm3/m256, add adjacent doubleword results, and store in ymm1.
	fn vpmaddwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply the packed word integers in ymm2 by the packed word integers in ymm3/m256, add adjacent doubleword results, and store in ymm1.
	fn vpmaddwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Conditionally store dword values from xmm2 using mask in xmm1.
	fn vpmaskmovd(&mut self, arg0: M128, arg1: Xmm, arg2: Xmm);

	/// Conditionally store dword values from ymm2 using mask in ymm1.
	fn vpmaskmovd(&mut self, arg0: M256, arg1: Ymm, arg2: Ymm);

	/// Conditionally load dword values from m128 using mask in xmm2 and store in xmm1.
	fn vpmaskmovd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Conditionally load dword values from m256 using mask in ymm2 and store in ymm1.
	fn vpmaskmovd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Conditionally store qword values from xmm2 using mask in xmm1.
	fn vpmaskmovq(&mut self, arg0: M128, arg1: Xmm, arg2: Xmm);

	/// Conditionally store qword values from ymm2 using mask in ymm1.
	fn vpmaskmovq(&mut self, arg0: M256, arg1: Ymm, arg2: Ymm);

	/// Conditionally load qword values from m128 using mask in xmm2 and store in xmm1.
	fn vpmaskmovq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Conditionally load qword values from m256 using mask in ymm2 and store in ymm1.
	fn vpmaskmovq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed byte integers in ymm2 and ymm3/m128 and store packed maximum values in ymm1.
	fn vpmaxsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed byte integers in ymm2 and ymm3/m128 and store packed maximum values in ymm1.
	fn vpmaxsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed maximum values in ymm1.
	fn vpmaxsd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed maximum values in ymm1.
	fn vpmaxsd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.
	fn vpmaxsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.
	fn vpmaxsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed word integers in ymm3/m128 and ymm2 and store packed maximum values in ymm1.
	fn vpmaxsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed word integers in ymm3/m128 and ymm2 and store packed maximum values in ymm1.
	fn vpmaxsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxub(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxub(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
	fn vpmaxub(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
	fn vpmaxub(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxud(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
	fn vpmaxud(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
	fn vpmaxud(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
	fn vpmaxud(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.
	fn vpmaxuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.
	fn vpmaxuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.
	fn vpmaxuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.
	fn vpmaxuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed minimum values in ymm1.
	fn vpminsd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed minimum values in ymm1.
	fn vpminsd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
	fn vpminsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
	fn vpminsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminub(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminub(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminub(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminub(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminud(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
	fn vpminud(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminud(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
	fn vpminud(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
	fn vpminuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
	fn vpminuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
	fn vpminuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
	fn vpminuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Move a byte mask of xmm1 to reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn vpmovmskb(&mut self, arg0: R32, arg1: Xmm);

	/// Move a 32-bit mask of ymm1 to reg.
	/// The upper bits of r64 are filled with zeros.
	fn vpmovmskb(&mut self, arg0: R32, arg1: Ymm);

	/// Move a byte mask of xmm1 to reg.
	/// The upper bits of r32 or r64 are filled with zeros.
	fn vpmovmskb(&mut self, arg0: R64, arg1: Xmm);

	/// Move a 32-bit mask of ymm1 to reg.
	/// The upper bits of r64 are filled with zeros.
	fn vpmovmskb(&mut self, arg0: R64, arg1: Ymm);

	/// Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn vpmovsxbd(&mut self, arg0: Xmm, arg1: M32);

	/// Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn vpmovsxbd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
	fn vpmovsxbd(&mut self, arg0: Ymm, arg1: M64);

	/// Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
	fn vpmovsxbd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxbq(&mut self, arg0: Xmm, arg1: M16);

	/// Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxbq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxbq(&mut self, arg0: Ymm, arg1: M32);

	/// Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxbq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn vpmovsxbw(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn vpmovsxbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
	fn vpmovsxbw(&mut self, arg0: Ymm, arg1: M128);

	/// Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
	fn vpmovsxbw(&mut self, arg0: Ymm, arg1: Xmm);

	/// Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxdq(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxdq(&mut self, arg0: Ymm, arg1: M128);

	/// Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxdq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn vpmovsxwd(&mut self, arg0: Xmm, arg1: M64);

	/// Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn vpmovsxwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
	fn vpmovsxwd(&mut self, arg0: Ymm, arg1: M128);

	/// Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
	fn vpmovsxwd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxwq(&mut self, arg0: Xmm, arg1: M32);

	/// Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn vpmovsxwq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxwq(&mut self, arg0: Ymm, arg1: M64);

	/// Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.
	fn vpmovsxwq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn vpmovzxbd(&mut self, arg0: Xmm, arg1: M32);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
	fn vpmovzxbd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
	fn vpmovzxbd(&mut self, arg0: Ymm, arg1: M64);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
	fn vpmovzxbd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxbq(&mut self, arg0: Xmm, arg1: M16);

	/// Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxbq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
	fn vpmovzxbq(&mut self, arg0: Ymm, arg1: M32);

	/// Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
	fn vpmovzxbq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn vpmovzxbw(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
	fn vpmovzxbw(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 16-bit integers in ymm1.
	fn vpmovzxbw(&mut self, arg0: Ymm, arg1: M128);

	/// Zero extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 16-bit integers in ymm1.
	fn vpmovzxbw(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxdq(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxdq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
	fn vpmovzxdq(&mut self, arg0: Ymm, arg1: M128);

	/// Zero extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
	fn vpmovzxdq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn vpmovzxwd(&mut self, arg0: Xmm, arg1: M64);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
	fn vpmovzxwd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
	fn vpmovzxwd(&mut self, arg0: Ymm, arg1: M128);

	/// Zero extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
	fn vpmovzxwd(&mut self, arg0: Ymm, arg1: Xmm);

	/// Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxwq(&mut self, arg0: Xmm, arg1: M32);

	/// Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
	fn vpmovzxwq(&mut self, arg0: Xmm, arg1: Xmm);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.
	fn vpmovzxwq(&mut self, arg0: Ymm, arg1: M64);

	/// Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.
	fn vpmovzxwq(&mut self, arg0: Ymm, arg1: Xmm);

	/// Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128, and store the quadword results in xmm1.
	fn vpmuldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128, and store the quadword results in xmm1.
	fn vpmuldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256, and store the quadword results in ymm1.
	fn vpmuldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256, and store the quadword results in ymm1.
	fn vpmuldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1.
	fn vpmulhrsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1.
	fn vpmulhrsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to ymm1.
	fn vpmulhrsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to ymm1.
	fn vpmulhrsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.
	fn vpmulhuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.
	fn vpmulhuw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.
	fn vpmulhuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.
	fn vpmulhuw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.
	fn vpmulhw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1.
	fn vpmulhw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.
	fn vpmulhw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1.
	fn vpmulhw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
	fn vpmulld(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
	fn vpmulld(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the packed dword signed integers in ymm2 and ymm3/m256 and store the low 32 bits of each product in ymm1.
	fn vpmulld(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply the packed dword signed integers in ymm2 and ymm3/m256 and store the low 32 bits of each product in ymm1.
	fn vpmulld(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
	fn vpmullw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
	fn vpmullw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1.
	fn vpmullw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1.
	fn vpmullw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Multiply packed unsigned doubleword integers in xmm2 by packed unsigned doubleword integers in xmm3/m128, and store the quadword results in xmm1.
	fn vpmuludq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Multiply packed unsigned doubleword integers in xmm2 by packed unsigned doubleword integers in xmm3/m128, and store the quadword results in xmm1.
	fn vpmuludq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Multiply packed unsigned doubleword integers in ymm2 by packed unsigned doubleword integers in ymm3/m256, and store the quadword results in ymm1.
	fn vpmuludq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Multiply packed unsigned doubleword integers in ymm2 by packed unsigned doubleword integers in ymm3/m256, and store the quadword results in ymm1.
	fn vpmuludq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Bitwise OR of xmm2/m128 and xmm3.
	fn vpor(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Bitwise OR of xmm2/m128 and xmm3.
	fn vpor(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Bitwise OR of ymm2/m256 and ymm3.
	fn vpor(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Bitwise OR of ymm2/m256 and ymm3.
	fn vpor(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Computes the absolute differences of the packed unsigned byte integers from xmm3 /m128 and xmm2; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.
	fn vpsadbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Computes the absolute differences of the packed unsigned byte integers from xmm3 /m128 and xmm2; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.
	fn vpsadbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Computes the absolute differences of the packed unsigned byte integers from ymm3/m256 and ymm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.
	fn vpsadbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Computes the absolute differences of the packed unsigned byte integers from ymm3/m256 and ymm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.
	fn vpsadbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shuffle bytes in xmm2 according to contents of xmm3/m128.
	fn vpshufb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shuffle bytes in xmm2 according to contents of xmm3/m128.
	fn vpshufb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shuffle bytes in ymm2 according to contents of ymm3/m256.
	fn vpshufb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shuffle bytes in ymm2 according to contents of ymm3/m256.
	fn vpshufb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshufd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshufd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the doublewords in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshufd(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Shuffle the doublewords in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshufd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshufhw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshufhw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the high words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshufhw(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Shuffle the high words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshufhw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshuflw(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
	fn vpshuflw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshuflw(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
	fn vpshuflw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Negate/zero/preserve packed byte integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Negate/zero/preserve packed byte integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Negate/zero/preserve packed doubleword integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Negate/zero/preserve packed doubleword integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Negate/zero/preserve packed word integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Negate/zero/preserve packed word integers in xmm2 depending on the corresponding sign in xmm3/m128.
	fn vpsignw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift doublewords in xmm2 left by imm8 while shifting in 0s.
	fn vpslld(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpslld(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpslld(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift doublewords in ymm2 left by imm8 while shifting in 0s.
	fn vpslld(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpslld(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpslld(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift xmm2 left by imm8 bytes while shifting in 0s and store result in xmm1.
	fn vpslldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift ymm2 left by imm8 bytes while shifting in 0s and store result in ymm1.
	fn vpslldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift quadwords in xmm2 left by imm8 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift quadwords in ymm2 left by imm8 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift bits in doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsllvd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift bits in doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsllvd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift bits in doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsllvd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shift bits in doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsllvd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shift bits in quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsllvq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift bits in quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsllvq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift bits in quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsllvq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shift bits in quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsllvq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shift words in xmm2 left by imm8 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift words in ymm2 left by imm8 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsllw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift doublewords in xmm2 right by imm8 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift doublewords in ymm2 right by imm8 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsrad(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift bits in doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in the sign bits.
	fn vpsravd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift bits in doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in the sign bits.
	fn vpsravd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift bits in doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in the sign bits.
	fn vpsravd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shift bits in doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in the sign bits.
	fn vpsravd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shift words in xmm2 right by imm8 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift words in ymm2 right by imm8 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
	fn vpsraw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift doublewords in xmm2 right by imm8 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift doublewords in ymm2 right by imm8 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrld(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift xmm2 right by imm8 bytes while shifting in 0s.
	fn vpsrldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift ymm1 right by imm8 bytes while shifting in 0s.
	fn vpsrldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift quadwords in xmm2 right by imm8 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift quadwords in ymm2 right by imm8 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Shift bits in doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsrlvd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift bits in doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsrlvd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift bits in doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsrlvd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shift bits in doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsrlvd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shift bits in quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsrlvq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift bits in quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
	fn vpsrlvq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift bits in quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsrlvq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Shift bits in quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
	fn vpsrlvq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Shift words in xmm2 right by imm8 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shift words in ymm2 right by imm8 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M128);

	/// Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
	fn vpsrlw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Xmm);

	/// Subtract packed byte integers in xmm3/m128 from xmm2.
	fn vpsubb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed byte integers in xmm3/m128 from xmm2.
	fn vpsubb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed byte integers in ymm3/m256 from ymm2.
	fn vpsubb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed byte integers in ymm3/m256 from ymm2.
	fn vpsubb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed doubleword integers in xmm3/m128 from xmm2.
	fn vpsubd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed doubleword integers in xmm3/m128 from xmm2.
	fn vpsubd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed doubleword integers in ymm3/m256 from ymm2.
	fn vpsubd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed doubleword integers in ymm3/m256 from ymm2.
	fn vpsubd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed quadword integers in xmm3/m128 from xmm2.
	fn vpsubq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed quadword integers in xmm3/m128 from xmm2.
	fn vpsubq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed quadword integers in ymm3/m256 from ymm2.
	fn vpsubq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed quadword integers in ymm3/m256 from ymm2.
	fn vpsubq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results.
	fn vpsubsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results.
	fn vpsubsb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results.
	fn vpsubsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results.
	fn vpsubsb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results.
	fn vpsubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results.
	fn vpsubsw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results.
	fn vpsubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results.
	fn vpsubsw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2 and saturate result.
	fn vpsubusb(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2 and saturate result.
	fn vpsubusb(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2 and saturate result.
	fn vpsubusb(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2 and saturate result.
	fn vpsubusb(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate result.
	fn vpsubusw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate result.
	fn vpsubusw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2 and saturate result.
	fn vpsubusw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2 and saturate result.
	fn vpsubusw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed word integers in xmm3/m128 from xmm2.
	fn vpsubw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed word integers in xmm3/m128 from xmm2.
	fn vpsubw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed word integers in ymm3/m256 from ymm2.
	fn vpsubw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed word integers in ymm3/m256 from ymm2.
	fn vpsubw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Set ZF and CF depending on bitwise AND and ANDN of sources.
	fn vptest(&mut self, arg0: Xmm, arg1: M128);

	/// Set ZF and CF depending on bitwise AND and ANDN of sources.
	fn vptest(&mut self, arg0: Xmm, arg1: Xmm);

	/// Set ZF and CF depending on bitwise AND and ANDN of sources.
	fn vptest(&mut self, arg0: Ymm, arg1: M256);

	/// Set ZF and CF depending on bitwise AND and ANDN of sources.
	fn vptest(&mut self, arg0: Ymm, arg1: Ymm);

	/// Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave high-order doublewords from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave high-order doublewords from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave high-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave high-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave high-order quadword from xmm2 and xmm3/m128 into xmm1 register.
	fn vpunpckhqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave high-order quadword from xmm2 and xmm3/m128 into xmm1 register.
	fn vpunpckhqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave high-order quadword from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhqdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave high-order quadword from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhqdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave high-order words from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave high-order words from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckhwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckhwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1.
	fn vpunpcklbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1.
	fn vpunpcklbw(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklbw(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave low-order doublewords from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave low-order doublewords from xmm2 and xmm3/m128 into xmm1.
	fn vpunpckldq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave low-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave low-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpckldq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave low-order quadword from xmm2 and xmm3/m128 into xmm1 register.
	fn vpunpcklqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave low-order quadword from xmm2 and xmm3/m128 into xmm1 register.
	fn vpunpcklqdq(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave low-order quadword from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklqdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave low-order quadword from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklqdq(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Interleave low-order words from xmm2 and xmm3/m128 into xmm1.
	fn vpunpcklwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Interleave low-order words from xmm2 and xmm3/m128 into xmm1.
	fn vpunpcklwd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register.
	fn vpunpcklwd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Bitwise XOR of xmm3/m128 and xmm2.
	fn vpxor(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Bitwise XOR of xmm3/m128 and xmm2.
	fn vpxor(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Bitwise XOR of ymm3/m256 and ymm2.
	fn vpxor(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Bitwise XOR of ymm3/m256 and ymm2.
	fn vpxor(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Computes the approximate reciprocals of packed single-precision values in xmm2/mem and stores the results in xmm1.
	fn vrcpps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes the approximate reciprocals of packed single-precision values in xmm2/mem and stores the results in xmm1.
	fn vrcpps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes the approximate reciprocals of packed single-precision values in ymm2/mem and stores the results in ymm1.
	fn vrcpps(&mut self, arg0: Ymm, arg1: M256);

	/// Computes the approximate reciprocals of packed single-precision values in ymm2/mem and stores the results in ymm1.
	fn vrcpps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the result in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vrcpss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the result in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vrcpss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Round packed double-precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn vroundpd(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Round packed double-precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn vroundpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Round packed double-precision floating-point values in ymm2/m256 and place the result in ymm1.
	/// The rounding mode is determined by imm8.
	fn vroundpd(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Round packed double-precision floating-point values in ymm2/m256 and place the result in ymm1.
	/// The rounding mode is determined by imm8.
	fn vroundpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Round packed single-precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn vroundps(&mut self, arg0: Xmm, arg1: M128, arg2: Imm8);

	/// Round packed single-precision floating-point values in xmm2/m128 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	fn vroundps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Imm8);

	/// Round packed single-precision floating-point values in ymm2/m256 and place the result in ymm1.
	/// The rounding mode is determined by imm8.
	fn vroundps(&mut self, arg0: Ymm, arg1: M256, arg2: Imm8);

	/// Round packed single-precision floating-point values in ymm2/m256 and place the result in ymm1.
	/// The rounding mode is determined by imm8.
	fn vroundps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Imm8);

	/// Round the low packed double precision floating-point value in xmm3/m64 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	/// Upper packed double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].
	fn vroundsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64, arg3: Imm8);

	/// Round the low packed double precision floating-point value in xmm3/m64 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	/// Upper packed double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].
	fn vroundsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Round the low packed single precision floating-point value in xmm3/m32 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	/// Also, upper packed single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vroundss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32, arg3: Imm8);

	/// Round the low packed single precision floating-point value in xmm3/m32 and place the result in xmm1.
	/// The rounding mode is determined by imm8.
	/// Also, upper packed single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vroundss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Computes the approximate reciprocals of the square roots of packed single-precision values in xmm2/mem and stores the results in xmm1.
	fn vrsqrtps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes the approximate reciprocals of the square roots of packed single-precision values in xmm2/mem and stores the results in xmm1.
	fn vrsqrtps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes the approximate reciprocals of the square roots of packed single-precision values in ymm2/mem and stores the results in ymm1.
	fn vrsqrtps(&mut self, arg0: Ymm, arg1: M256);

	/// Computes the approximate reciprocals of the square roots of packed single-precision values in ymm2/mem and stores the results in ymm1.
	fn vrsqrtps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Computes the approximate reciprocal of the square root of the low single precision floating-point value in xmm3/m32 and stores the results in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vrsqrtss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Computes the approximate reciprocal of the square root of the low single precision floating-point value in xmm3/m32 and stores the results in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vrsqrtss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Shuffle Packed double-precision floating- point values selected by imm8 from xmm2 and xmm3/mem.
	fn vshufpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Shuffle Packed double-precision floating- point values selected by imm8 from xmm2 and xmm3/mem.
	fn vshufpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Shuffle Packed double-precision floating- point values selected by imm8 from ymm2 and ymm3/mem.
	fn vshufpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Shuffle Packed double-precision floating- point values selected by imm8 from ymm2 and ymm3/mem.
	fn vshufpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Shuffle Packed single-precision floating-point values selected by imm8 from xmm2 and xmm3/mem.
	fn vshufps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128, arg3: Imm8);

	/// Shuffle Packed single-precision floating-point values selected by imm8 from xmm2 and xmm3/mem.
	fn vshufps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm, arg3: Imm8);

	/// Shuffle Packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/mem.
	fn vshufps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256, arg3: Imm8);

	/// Shuffle Packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/mem.
	fn vshufps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm, arg3: Imm8);

	/// Computes Square Roots of the packed double- precision floating-point values in xmm2/m128 and stores the result in xmm1.
	fn vsqrtpd(&mut self, arg0: Xmm, arg1: M128);

	/// Computes Square Roots of the packed double- precision floating-point values in xmm2/m128 and stores the result in xmm1.
	fn vsqrtpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes Square Roots of the packed double- precision floating-point values in ymm2/m256 and stores the result in ymm1.
	fn vsqrtpd(&mut self, arg0: Ymm, arg1: M256);

	/// Computes Square Roots of the packed double- precision floating-point values in ymm2/m256 and stores the result in ymm1.
	fn vsqrtpd(&mut self, arg0: Ymm, arg1: Ymm);

	/// Computes Square Roots of the packed single- precision floating-point values in xmm2/m128 and stores the result in xmm1.
	fn vsqrtps(&mut self, arg0: Xmm, arg1: M128);

	/// Computes Square Roots of the packed single- precision floating-point values in xmm2/m128 and stores the result in xmm1.
	fn vsqrtps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Computes Square Roots of the packed single- precision floating-point values in ymm2/m256 and stores the result in ymm1.
	fn vsqrtps(&mut self, arg0: Ymm, arg1: M256);

	/// Computes Square Roots of the packed single- precision floating-point values in ymm2/m256 and stores the result in ymm1.
	fn vsqrtps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Computes square root of the low double- precision floating point value in xmm3/m64 and stores the results in xmm2.
	/// Also, upper double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].
	fn vsqrtsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Computes square root of the low double- precision floating point value in xmm3/m64 and stores the results in xmm2.
	/// Also, upper double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].
	fn vsqrtsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Computes square root of the low single- precision floating-point value in xmm3/m32 and stores the results in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vsqrtss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Computes square root of the low single- precision floating-point value in xmm3/m32 and stores the results in xmm1.
	/// Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].
	fn vsqrtss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Store contents of MXCSR register to m32.
	fn vstmxcsr(&mut self, arg0: M32);

	/// Subtract packed double-precision floating- point values in xmm3/mem from xmm2 and stores result in xmm1.
	fn vsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed double-precision floating- point values in xmm3/mem from xmm2 and stores result in xmm1.
	fn vsubpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed double-precision floating- point values in ymm3/mem from ymm2 and stores result in ymm1.
	fn vsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed double-precision floating- point values in ymm3/mem from ymm2 and stores result in ymm1.
	fn vsubpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract packed single-precision floating-point values in xmm3/mem from xmm2 and stores result in xmm1.
	fn vsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Subtract packed single-precision floating-point values in xmm3/mem from xmm2 and stores result in xmm1.
	fn vsubps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract packed single-precision floating-point values in ymm3/mem from ymm2 and stores result in ymm1.
	fn vsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Subtract packed single-precision floating-point values in ymm3/mem from ymm2 and stores result in ymm1.
	fn vsubps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Subtract the low double-precision floating- point value in xmm3/mem from xmm2 and store the result in xmm1.
	fn vsubsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M64);

	/// Subtract the low double-precision floating- point value in xmm3/mem from xmm2 and store the result in xmm1.
	fn vsubsd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Subtract the low single-precision floating- point value in xmm3/mem from xmm2 and store the result in xmm1.
	fn vsubss(&mut self, arg0: Xmm, arg1: Xmm, arg2: M32);

	/// Subtract the low single-precision floating- point value in xmm3/mem from xmm2 and store the result in xmm1.
	fn vsubss(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating- point sources.
	fn vtestpd(&mut self, arg0: Xmm, arg1: M128);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating- point sources.
	fn vtestpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating- point sources.
	fn vtestpd(&mut self, arg0: Ymm, arg1: M256);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating- point sources.
	fn vtestpd(&mut self, arg0: Ymm, arg1: Ymm);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating- point sources.
	fn vtestps(&mut self, arg0: Xmm, arg1: M128);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating- point sources.
	fn vtestps(&mut self, arg0: Xmm, arg1: Xmm);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating- point sources.
	fn vtestps(&mut self, arg0: Ymm, arg1: M256);

	/// Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating- point sources.
	fn vtestps(&mut self, arg0: Ymm, arg1: Ymm);

	/// Compare low double precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn vucomisd(&mut self, arg0: Xmm, arg1: M64);

	/// Compare low double precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.
	fn vucomisd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Compare low single precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn vucomiss(&mut self, arg0: Xmm, arg1: M32);

	/// Compare low single precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.
	fn vucomiss(&mut self, arg0: Xmm, arg1: Xmm);

	/// Unpacks and Interleaves double precision floating-point values from high quadwords of xmm2 and xmm3/m128.
	fn vunpckhpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Unpacks and Interleaves double precision floating-point values from high quadwords of xmm2 and xmm3/m128.
	fn vunpckhpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Unpacks and Interleaves double precision floating-point values from high quadwords of ymm2 and ymm3/m256.
	fn vunpckhpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Unpacks and Interleaves double precision floating-point values from high quadwords of ymm2 and ymm3/m256.
	fn vunpckhpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128.
	fn vunpckhps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128.
	fn vunpckhps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256.
	fn vunpckhps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256.
	fn vunpckhps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Unpacks and Interleaves double precision floating-point values low high quadwords of xmm2 and xmm3/m128.
	fn vunpcklpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Unpacks and Interleaves double precision floating-point values low high quadwords of xmm2 and xmm3/m128.
	fn vunpcklpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Unpacks and Interleaves double precision floating-point values low high quadwords of ymm2 and ymm3/m256.
	fn vunpcklpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Unpacks and Interleaves double precision floating-point values low high quadwords of ymm2 and ymm3/m256.
	fn vunpcklpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/m128.
	fn vunpcklps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/m128.
	fn vunpcklps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/m256.
	fn vunpcklps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/m256.
	fn vunpcklps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vxorpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/mem.
	fn vxorpd(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vxorpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/mem.
	fn vxorpd(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vxorps(&mut self, arg0: Xmm, arg1: Xmm, arg2: M128);

	/// Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/mem.
	fn vxorps(&mut self, arg0: Xmm, arg1: Xmm, arg2: Xmm);

	/// Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vxorps(&mut self, arg0: Ymm, arg1: Ymm, arg2: M256);

	/// Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/mem.
	fn vxorps(&mut self, arg0: Ymm, arg1: Ymm, arg2: Ymm);

	/// Zero all YMM registers.
	fn vzeroall(&mut self);

	/// Zero upper 128 bits of all YMM registers.
	fn vzeroupper(&mut self);

	/// Check pending unmasked floating-point exceptions.
	fn wait(&mut self);

	/// Load the FS base address with the 32-bit value in the source register.
	fn wrfsbase(&mut self, arg0: R32);

	/// Load the FS base address with the 64-bit value in the source register.
	fn wrfsbase(&mut self, arg0: R64);

	/// Load the GS base address with the 32-bit value in the source register.
	fn wrgsbase(&mut self, arg0: R32);

	/// Load the GS base address with the 64-bit value in the source register.
	fn wrgsbase(&mut self, arg0: R64);

	/// Causes an RTM abort if in RTM execution.
	fn xabort(&mut self, arg0: Imm8);

	/// A hint used with an "XACQUIRE-enabled" instruction to start lock elision on the instruction memory operand address.
	fn xacquire(&mut self);

	/// Exchange r16 and r/m16; load sum into r/m16.
	fn xadd(&mut self, arg0: M16, arg1: R16);

	/// Exchange r32 and r/m32; load sum into r/m32.
	fn xadd(&mut self, arg0: M32, arg1: R32);

	/// Exchange r64 and r/m64; load sum into r/m64.
	fn xadd(&mut self, arg0: M64, arg1: R64);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: M8, arg1: R8);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: M8, arg1: Rh);

	/// Exchange r16 and r/m16; load sum into r/m16.
	fn xadd(&mut self, arg0: R16, arg1: R16);

	/// Exchange r32 and r/m32; load sum into r/m32.
	fn xadd(&mut self, arg0: R32, arg1: R32);

	/// Exchange r64 and r/m64; load sum into r/m64.
	fn xadd(&mut self, arg0: R64, arg1: R64);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: R8, arg1: R8);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: R8, arg1: Rh);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: Rh, arg1: R8);

	/// Exchange r8 and r/m8; load sum into r/m8.
	fn xadd(&mut self, arg0: Rh, arg1: Rh);

	/// Specifies the start of an RTM region.
	/// Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.
	fn xbegin(&mut self, arg0: Label);

	/// Specifies the start of an RTM region.
	/// Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.
	fn xbegin(&mut self, arg0: Rel32);

	/// Exchange r16 with AX.
	fn xchg(&mut self, arg0: Ax, arg1: R16);

	/// Exchange r32 with EAX.
	fn xchg(&mut self, arg0: Eax, arg1: R32);

	/// Exchange r16 with word from r/m16.
	fn xchg(&mut self, arg0: M16, arg1: R16);

	/// Exchange r32 with doubleword from r/m32.
	fn xchg(&mut self, arg0: M32, arg1: R32);

	/// Exchange r64 with quadword from r/m64.
	fn xchg(&mut self, arg0: M64, arg1: R64);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: M8, arg1: R8);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: M8, arg1: Rh);

	/// Exchange AX with r16.
	fn xchg(&mut self, arg0: R16, arg1: Ax);

	/// Exchange word from r/m16 with r16.
	fn xchg(&mut self, arg0: R16, arg1: M16);

	/// Exchange r16 with word from r/m16.
	fn xchg(&mut self, arg0: R16, arg1: R16);

	/// Exchange word from r/m16 with r16.
	void xchg_1(const R16& arg0, arg1: R16);

	/// Exchange EAX with r32.
	fn xchg(&mut self, arg0: R32, arg1: Eax);

	/// Exchange doubleword from r/m32 with r32.
	fn xchg(&mut self, arg0: R32, arg1: M32);

	/// Exchange r32 with doubleword from r/m32.
	fn xchg(&mut self, arg0: R32, arg1: R32);

	/// Exchange doubleword from r/m32 with r32.
	void xchg_1(const R32& arg0, arg1: R32);

	/// Exchange quadword from r/m64 with r64.
	fn xchg(&mut self, arg0: R64, arg1: M64);

	/// Exchange r64 with quadword from r/m64.
	fn xchg(&mut self, arg0: R64, arg1: R64);

	/// Exchange quadword from r/m64 with r64.
	void xchg_1(const R64& arg0, arg1: R64);

	/// Exchange RAX with r64.
	fn xchg(&mut self, arg0: R64, arg1: Rax);

	/// Exchange byte from r/m8 with r8 (byte register).
	fn xchg(&mut self, arg0: R8, arg1: M8);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: R8, arg1: R8);

	/// Exchange byte from r/m8 with r8 (byte register).
	void xchg_1(const R8& arg0, arg1: R8);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: R8, arg1: Rh);

	/// Exchange byte from r/m8 with r8 (byte register).
	void xchg_1(const R8& arg0, arg1: Rh);

	/// Exchange r64 with RAX.
	fn xchg(&mut self, arg0: Rax, arg1: R64);

	/// Exchange byte from r/m8 with r8 (byte register).
	fn xchg(&mut self, arg0: Rh, arg1: M8);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: Rh, arg1: R8);

	/// Exchange byte from r/m8 with r8 (byte register).
	void xchg_1(const Rh& arg0, arg1: R8);

	/// Exchange r8 (byte register) with byte from r/m8.
	fn xchg(&mut self, arg0: Rh, arg1: Rh);

	/// Exchange byte from r/m8 with r8 (byte register).
	void xchg_1(const Rh& arg0, arg1: Rh);

	/// Specifies the end of an RTM code region.
	fn xend(&mut self);

	/// Reads an XCR specified by ECX into EDX:EAX.
	fn xgetbv(&mut self);

	/// Set AL to memory byte DS:[(E)BX + unsigned AL].
	fn xlat(&mut self, arg0: M8);

	/// Set AL to memory byte DS:[(E)BX + unsigned AL].
	fn xlatb(&mut self);

	/// Set AL to memory byte [RBX + unsigned AL].
	void xlatb_1();

	/// AL XOR imm8.
	void xor_(const Al& arg0, arg1: Imm8);

	/// AX XOR imm16.
	void xor_(const Ax& arg0, arg1: Imm16);

	/// EAX XOR imm32.
	void xor_(const Eax& arg0, arg1: Imm32);

	/// r/m16 XOR imm16.
	void xor_(const M16& arg0, arg1: Imm16);

	/// r/m16 XOR imm8 (sign-extended).
	void xor_(const M16& arg0, arg1: Imm8);

	/// r/m16 XOR r16.
	void xor_(const M16& arg0, arg1: R16);

	/// r/m32 XOR imm32.
	void xor_(const M32& arg0, arg1: Imm32);

	/// r/m32 XOR imm8 (sign-extended).
	void xor_(const M32& arg0, arg1: Imm8);

	/// r/m32 XOR r32.
	void xor_(const M32& arg0, arg1: R32);

	/// r/m64 XOR imm32 (sign-extended).
	void xor_(const M64& arg0, arg1: Imm32);

	/// r/m64 XOR imm8 (sign-extended).
	void xor_(const M64& arg0, arg1: Imm8);

	/// r/m64 XOR r64.
	void xor_(const M64& arg0, arg1: R64);

	/// r/m8 XOR imm8.
	void xor_(const M8& arg0, arg1: Imm8);

	/// r/m8 XOR r8.
	void xor_(const M8& arg0, arg1: R8);

	/// r/m8 XOR r8.
	void xor_(const M8& arg0, arg1: Rh);

	/// r/m16 XOR imm16.
	void xor_(const R16& arg0, arg1: Imm16);

	/// r/m16 XOR imm8 (sign-extended).
	void xor_(const R16& arg0, arg1: Imm8);

	/// r16 XOR r/m16.
	void xor_(const R16& arg0, arg1: M16);

	/// r/m16 XOR r16.
	void xor_(const R16& arg0, arg1: R16);

	/// r16 XOR r/m16.
	void xor__1(const R16& arg0, arg1: R16);

	/// r/m32 XOR imm32.
	void xor_(const R32& arg0, arg1: Imm32);

	/// r/m32 XOR imm8 (sign-extended).
	void xor_(const R32& arg0, arg1: Imm8);

	/// r32 XOR r/m32.
	void xor_(const R32& arg0, arg1: M32);

	/// r/m32 XOR r32.
	void xor_(const R32& arg0, arg1: R32);

	/// r32 XOR r/m32.
	void xor__1(const R32& arg0, arg1: R32);

	/// r/m64 XOR imm32 (sign-extended).
	void xor_(const R64& arg0, arg1: Imm32);

	/// r/m64 XOR imm8 (sign-extended).
	void xor_(const R64& arg0, arg1: Imm8);

	/// r64 XOR r/m64.
	void xor_(const R64& arg0, arg1: M64);

	/// r/m64 XOR r64.
	void xor_(const R64& arg0, arg1: R64);

	/// r64 XOR r/m64.
	void xor__1(const R64& arg0, arg1: R64);

	/// r/m8 XOR imm8.
	void xor_(const R8& arg0, arg1: Imm8);

	/// r8 XOR r/m8.
	void xor_(const R8& arg0, arg1: M8);

	/// r/m8 XOR r8.
	void xor_(const R8& arg0, arg1: R8);

	/// r8 XOR r/m8.
	void xor__1(const R8& arg0, arg1: R8);

	/// r/m8 XOR r8.
	void xor_(const R8& arg0, arg1: Rh);

	/// r8 XOR r/m8.
	void xor__1(const R8& arg0, arg1: Rh);

	/// RAX XOR imm32 (sign-extended).
	void xor_(const Rax& arg0, arg1: Imm32);

	/// r/m8 XOR imm8.
	void xor_(const Rh& arg0, arg1: Imm8);

	/// r8 XOR r/m8.
	void xor_(const Rh& arg0, arg1: M8);

	/// r/m8 XOR r8.
	void xor_(const Rh& arg0, arg1: R8);

	/// r8 XOR r/m8.
	void xor__1(const Rh& arg0, arg1: R8);

	/// r/m8 XOR r8.
	void xor_(const Rh& arg0, arg1: Rh);

	/// r8 XOR r/m8.
	void xor__1(const Rh& arg0, arg1: Rh);

	/// Bitwise exclusive-OR of xmm2/m128 and xmm1.
	fn xorpd(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise exclusive-OR of xmm2/m128 and xmm1.
	fn xorpd(&mut self, arg0: Xmm, arg1: Xmm);

	/// Bitwise exclusive-OR of xmm2/m128 and xmm1.
	fn xorps(&mut self, arg0: Xmm, arg1: M128);

	/// Bitwise exclusive-OR of xmm2/m128 and xmm1.
	fn xorps(&mut self, arg0: Xmm, arg1: Xmm);

	/// A hint used with an "XRELEASE-enabled" instruction to end lock elision on the instruction memory operand address.
	fn xrelease(&mut self);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor(&mut self, arg0: M16);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor(&mut self, arg0: M32);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor(&mut self, arg0: M64);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor64(&mut self, arg0: M16);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor64(&mut self, arg0: M32);

	/// Restore processor extended states from memory.
	/// The states are specified by EDX:EAX.
	fn xrstor64(&mut self, arg0: M64);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave(&mut self, arg0: M16);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave(&mut self, arg0: M32);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave(&mut self, arg0: M64);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave64(&mut self, arg0: M16);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave64(&mut self, arg0: M32);

	/// Save processor extended states to memory.
	/// The states are specified by EDX:EAX.
	fn xsave64(&mut self, arg0: M64);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt(&mut self, arg0: M16);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt(&mut self, arg0: M32);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt(&mut self, arg0: M64);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt64(&mut self, arg0: M16);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt64(&mut self, arg0: M32);

	/// Save processor extended states specified in EDX:EAX to memory, optimizing the state save operation if possible.
	fn xsaveopt64(&mut self, arg0: M64);

	/// Test if executing in a transactional region.
	fn xtest(&mut self);